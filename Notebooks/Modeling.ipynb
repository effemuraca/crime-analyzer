{"cells":[{"cell_type":"markdown","id":"0890abf3","metadata":{"id":"0890abf3"},"source":["# Modeling Phase\n","\n","## Introduction\n","\n","This notebook performs the modeling phase using the preprocessed data and pipelines defined in `AlternativePreprocessing.ipynb`. All feature engineering and label engineering operations (including the creation of `RISK_LEVEL` via STKDE) are performed in a leakage-free manner, i.e., only after the train/test split and within each cross-validation fold.\n","\n","**Dependencies:**\n","- Loading artifacts from `Classification (Preprocessing)` (data, pipelines, STKDE parameters, scoring_dict)\n","- Use of custom transformers and modular pipelines defined in `custom_transformers.py`\n","\n","**Objectives:**\n","- Select the best model via cross-validation\n","- Perform hyperparameter tuning\n","- Evaluate generalization on the test set"]},{"cell_type":"markdown","id":"276296db","metadata":{"id":"276296db"},"source":["# Setup\n","\n","Import libraries, define paths, and load preprocessed data. All custom functions are imported from `custom_transformers.py` to ensure modularity and reusability."]},{"cell_type":"markdown","id":"b7f49aec","metadata":{"id":"b7f49aec"},"source":["## Run on Google Colab (optional)\n","\n","If working locally, this cell can be ignored."]},{"cell_type":"code","execution_count":1,"id":"f508ec24","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f508ec24","outputId":"95f6ff87-3c99-4ae0-81e1-1baba0113116","executionInfo":{"status":"ok","timestamp":1747491944153,"user_tz":-120,"elapsed":2572,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}],"source":["# Run on Google Colab (optional)\n","from google.colab import drive\n","drive.mount('/drive', force_remount=True)"]},{"cell_type":"markdown","id":"1c631771","metadata":{"id":"1c631771"},"source":["## Import libraries\n","\n","Import all libraries needed for modeling and visualization. Custom functions are imported from `custom_transformers.py`."]},{"cell_type":"code","execution_count":2,"id":"b6fd20df","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6fd20df","outputId":"7ef36419-8505-494c-d3e0-523c50f67275","executionInfo":{"status":"ok","timestamp":1747491951819,"user_tz":-120,"elapsed":7671,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n"]}],"source":["!pip install xgboost\n","!pip install lightgbm\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","import joblib\n","import json\n","import glob\n","import sys\n","\n","from sklearn.model_selection import StratifiedKFold, cross_validate, RandomizedSearchCV, GroupKFold, TimeSeriesSplit\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, average_precision_score, matthews_corrcoef, classification_report, PrecisionRecallDisplay\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","project_path = '/drive/MyDrive/Data Mining and Machine Learning/Progetto'\n","os.chdir(project_path)\n","sys.path.append(project_path)\n","\n","# Import custom transformers\n","from custom_transformers import cyclical_transform, BinarizeSinCosTransformer, STKDEAndRiskLabelTransformer, TargetEngineeringPipeline\n","\n","from scipy.stats import ttest_rel\n","import random\n","\n","random.seed(42)\n","np.random.seed(42)\n","#warnings.filterwarnings('ignore')\n","sns.set_style('whitegrid')"]},{"cell_type":"markdown","id":"2c5223af","metadata":{"id":"2c5223af"},"source":["## Define paths\n","\n","Define paths for loading preprocessed data and saving modeling results (models, metrics, plots)."]},{"cell_type":"code","execution_count":3,"id":"f1c38cc3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1c38cc3","outputId":"e3e48060-2654-4ee7-deb5-7ab88beb1964","executionInfo":{"status":"ok","timestamp":1747491951836,"user_tz":-120,"elapsed":14,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing artifacts will be loaded from: /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Preprocessing)\n","Modeling results will be saved to: /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Modeling)\n"]}],"source":["base_dir = \"/drive/MyDrive/Data Mining and Machine Learning/Progetto\"\n","\n","preprocessing_dir = os.path.join(base_dir, \"Classification (Preprocessing)\")\n","modeling_results_dir = os.path.join(base_dir, \"Classification (Modeling)\")\n","os.makedirs(modeling_results_dir, exist_ok=True)\n","print(f\"Preprocessing artifacts will be loaded from: {preprocessing_dir}\")\n","print(f\"Modeling results will be saved to: {modeling_results_dir}\")"]},{"cell_type":"markdown","id":"aa0b1d59","metadata":{"id":"aa0b1d59"},"source":["## Load data and pipelines\n","\n","Load the unprocessed data splits (`X_train`, `y_train`, `X_test`, `y_test`), the unfitted preprocessing pipelines, the feature names, and the scoring dictionary saved by `AlternativePreprocessing.ipynb`."]},{"cell_type":"code","execution_count":4,"id":"OrQEsN0WRIMQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OrQEsN0WRIMQ","outputId":"44ba9c8c-2bcb-40b0-9845-979b8403de0c","executionInfo":{"status":"ok","timestamp":1747491953371,"user_tz":-120,"elapsed":1532,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Loading data and pipelines ===\n","Loaded unprocessed data: X_train (362070, 27), X_test (113574, 27), y_train (362070,), y_test (113574,)\n","Loaded preprocessing pipelines: general, trees, bernoulli\n","Loaded scoring dictionary: ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr_weighted', 'pr_auc_ovr_weighted', 'mcc', 'neg_log_loss']\n"]}],"source":["print(\"=== Loading data and pipelines ===\")\n","\n","X_train = np.load(os.path.join(preprocessing_dir, 'X_train.npy'), allow_pickle=True)\n","y_train = np.load(os.path.join(preprocessing_dir, 'y_train.npy'))\n","X_test = np.load(os.path.join(preprocessing_dir, 'X_test.npy'), allow_pickle=True)\n","y_test = np.load(os.path.join(preprocessing_dir, 'y_test.npy'))\n","feature_names = joblib.load(os.path.join(preprocessing_dir, 'X_feature_names.joblib'))\n","\n","X_train = pd.DataFrame(X_train, columns=feature_names)\n","X_test = pd.DataFrame(X_test, columns=feature_names)\n","\n","preprocessing_pipeline_general = joblib.load(os.path.join(preprocessing_dir, 'preprocessing_pipeline_general.joblib'))\n","preprocessing_pipeline_trees = joblib.load(os.path.join(preprocessing_dir, 'preprocessing_pipeline_trees.joblib'))\n","preprocessing_pipeline_bernoulli = joblib.load(os.path.join(preprocessing_dir, 'preprocessing_pipeline_bernoulli.joblib'))\n","\n","scoring = joblib.load(os.path.join(preprocessing_dir, 'scoring_dict.joblib'))\n","\n","print(f\"Loaded unprocessed data: X_train {X_train.shape}, X_test {X_test.shape}, y_train {y_train.shape}, y_test {y_test.shape}\")\n","print(f\"Loaded preprocessing pipelines: general, trees, bernoulli\")\n","print(f\"Loaded scoring dictionary: {list(scoring.keys())}\")"]},{"cell_type":"markdown","id":"3548506e","metadata":{"id":"3548506e"},"source":["## Target variable selection\n","\n","Select the target variable for classification. In this notebook, the target variable `RISK_LEVEL` is *engineered* via STKDE within the leakage-free pipeline."]},{"cell_type":"markdown","id":"_5TmHqaYlkfP","metadata":{"id":"_5TmHqaYlkfP"},"source":["## Update Scoring with Ordinal Metrics"]},{"cell_type":"code","execution_count":5,"id":"HmC7ZBqplmGS","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmC7ZBqplmGS","outputId":"f9303027-e324-49ff-8229-33a75ef8443c","executionInfo":{"status":"ok","timestamp":1747491953411,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated scoring dictionary with ordinal metrics and MCC: ['accuracy', 'f1_weighted', 'f1_macro', 'precision_weighted', 'recall_weighted', 'mcc', 'ordinal_mae', 'severe_error', 'roc_auc_ovr_weighted', 'pr_auc_ovr_weighted', 'neg_log_loss']\n"]}],"source":["# Update the scoring dictionary\n","from sklearn.metrics import log_loss, roc_auc_score, average_precision_score, accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef, make_scorer\n","\n","# Ensure ordinal metrics are defined (copied from earlier cell)\n","def ordinal_mae(y_true, y_pred):\n","    return np.mean(np.abs(y_true - y_pred))\n","\n","def severe_error_rate(y_true, y_pred):\n","    return np.mean(np.abs(y_true - y_pred) == 2)\n","\n","ordinal_mae_scorer = make_scorer(ordinal_mae, greater_is_better=False)\n","severe_error_scorer = make_scorer(severe_error_rate, greater_is_better=False)\n","\n","\n","# Define the scoring dictionary with appropriate averages for multiclass\n","scoring = {\n","    'accuracy': make_scorer(accuracy_score),\n","    # Explicitly set average for multiclass metrics\n","    'f1_weighted': make_scorer(f1_score, average='weighted'),\n","    'f1_macro': make_scorer(f1_score, average='macro'), # Added f1_macro for better insight\n","    'precision_weighted': make_scorer(precision_score, average='weighted', zero_division=0),\n","    'recall_weighted': make_scorer(recall_score, average='weighted', zero_division=0),\n","    'mcc': make_scorer(matthews_corrcoef), # MCC handles multiclass natively\n","\n","    # Ordinal metrics\n","    'ordinal_mae': ordinal_mae_scorer, # Already defined above\n","    'severe_error': severe_error_scorer, # Already defined above\n","\n","    # Probability-based metrics for multiclass\n","    'roc_auc_ovr_weighted': make_scorer(\n","        roc_auc_score,\n","        multi_class='ovr',\n","        average='weighted',\n","        needs_proba=True\n","    ),\n","    'pr_auc_ovr_weighted': make_scorer(\n","        average_precision_score,\n","        average='weighted',\n","        needs_proba=True\n","    ),\n","    'neg_log_loss': make_scorer(\n","        log_loss,\n","        greater_is_better=False,\n","        needs_proba=True\n","    )\n","}\n","\n","print(f\"Updated scoring dictionary with ordinal metrics and MCC: {list(scoring.keys())}\")"]},{"cell_type":"markdown","id":"b90b675f","metadata":{"id":"b90b675f"},"source":["## Data verification\n","\n","Check the dimensions and class distribution of the loaded data."]},{"cell_type":"code","execution_count":6,"id":"cfd939f6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfd939f6","outputId":"095875fb-dd20-4801-a174-64d60ab13446","executionInfo":{"status":"ok","timestamp":1747491953465,"user_tz":-120,"elapsed":51,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Data verification ===\n","X_train shape: (362070, 27)\n","y_train shape: (362070,)\n","X_test shape: (113574, 27)\n","y_test shape: (113574,)\n","Scoring dict: {'accuracy': make_scorer(accuracy_score, response_method='predict'), 'f1_weighted': make_scorer(f1_score, response_method='predict', average=weighted), 'f1_macro': make_scorer(f1_score, response_method='predict', average=macro), 'precision_weighted': make_scorer(precision_score, response_method='predict', average=weighted, zero_division=0), 'recall_weighted': make_scorer(recall_score, response_method='predict', average=weighted, zero_division=0), 'mcc': make_scorer(matthews_corrcoef, response_method='predict'), 'ordinal_mae': make_scorer(ordinal_mae, greater_is_better=False, response_method='predict'), 'severe_error': make_scorer(severe_error_rate, greater_is_better=False, response_method='predict'), 'roc_auc_ovr_weighted': make_scorer(roc_auc_score, response_method='predict', multi_class=ovr, average=weighted, needs_proba=True), 'pr_auc_ovr_weighted': make_scorer(average_precision_score, response_method='predict', average=weighted, needs_proba=True), 'neg_log_loss': make_scorer(log_loss, greater_is_better=False, response_method='predict', needs_proba=True)}\n","\n","Class distribution in y_train (dummy, the real label will be engineered in the pipeline):\n","{np.int64(0): np.int64(362070)}\n","Proportions:\n","{np.int64(0): np.float64(1.0)}\n","\n","Note: the real target variable will be created in the modeling pipeline.\n"]}],"source":["print(\"=== Data verification ===\")\n","print(f\"X_train shape: {X_train.shape}\")\n","print(f\"y_train shape: {y_train.shape}\")\n","print(f\"X_test shape: {X_test.shape}\")\n","print(f\"y_test shape: {y_test.shape}\")\n","print(f\"Scoring dict: {scoring}\")\n","\n","print(\"\\nClass distribution in y_train (dummy, the real label will be engineered in the pipeline):\")\n","unique, counts = np.unique(y_train, return_counts=True)\n","print(dict(zip(unique, counts)))\n","print(\"Proportions:\")\n","print(dict(zip(unique, counts / len(y_train))))\n","print(\"\\nNote: the real target variable will be created in the modeling pipeline.\")"]},{"cell_type":"markdown","id":"dcc089b0","metadata":{"id":"dcc089b0"},"source":["## Pipelines and tuning for XGBoost/LightGBM\n","\n","Definition of pipelines and placeholders for advanced models (XGBoost, LightGBM)."]},{"cell_type":"markdown","id":"6d98802b","metadata":{"id":"6d98802b"},"source":["### Definition of models to compare\n","\n","Definition of a dictionary with the classification models to be evaluated. Each model will be placed in a pipeline that includes preprocessing steps."]},{"cell_type":"code","execution_count":7,"id":"ae17f4d1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae17f4d1","outputId":"e347ff20-a43d-4770-89c2-24f930079d39","executionInfo":{"status":"ok","timestamp":1747491959070,"user_tz":-120,"elapsed":5602,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Defined models: ['Dummy', 'LogisticRegression', 'KNN', 'SVC_linear', 'GaussianNB', 'BernoulliNB', 'DecisionTree', 'RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM']\n"]}],"source":["models_to_evaluate = {\n","    # --- Baseline ---\n","    'Dummy': DummyClassifier(strategy='stratified', random_state=42),\n","\n","    # --- Linear Models ---\n","    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced', n_jobs=-1),\n","\n","    # --- K-Nearest Neighbors ---\n","    'KNN': KNeighborsClassifier(n_jobs=-1),\n","\n","    # --- Support Vector Machines ---\n","    #'SVC_rbf': SVC(random_state=42, class_weight='balanced', probability=True, kernel='rbf'),\n","    'SVC_linear': SVC(random_state=42, class_weight='balanced', probability=True, kernel='linear'),\n","\n","    # --- Naive Bayes ---\n","    'GaussianNB': GaussianNB(), # For comparison\n","    'BernoulliNB': BernoulliNB(), # Added\n","\n","    # --- Tree-Based Models ---\n","    'DecisionTree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n","\n","    # --- Ensemble Methods ---\n","    'RandomForest': RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n","    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n","}\n","\n","models_to_evaluate.update({\n","    'XGBoost': None,  # Placeholder for XGBoost model\n","    'LightGBM': None  # Placeholder for LightGBM model\n","})\n","try:\n","    from xgboost import XGBClassifier\n","    models_to_evaluate['XGBoost'] = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","except ImportError:\n","    print(\"XGBoost not installed. Skipping.\")\n","\n","try:\n","    from lightgbm import LGBMClassifier\n","    models_to_evaluate['LightGBM'] = LGBMClassifier(random_state=42)\n","except ImportError:\n","    print(\"LightGBM not installed. Skipping.\")\n","\n","print(f\"Defined models: {list(models_to_evaluate.keys())}\")"]},{"cell_type":"markdown","id":"87c41f89","metadata":{"id":"87c41f89"},"source":["### Model selection via cross-validation\n","\n","Each model is evaluated using leakage-free cross-validation (GroupKFold on YEAR+MONTH if available, otherwise StratifiedKFold). The average metric results are saved for comparison."]},{"cell_type":"code","execution_count":8,"id":"9a3cb30e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"9a3cb30e","outputId":"c82c83bd-1a89-471d-859d-ad32efcc2073","executionInfo":{"status":"error","timestamp":1747492001661,"user_tz":-120,"elapsed":42587,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Starting model evaluation with Cross-Validation ===\n","Loaded optimal STKDE parameters: hs=150, ht=45\n","Using TimeSeriesSplit with 5 splits for time-aware cross-validation.\n","\n","--- Processing Dummy ---\n","Not all split metric files found for Dummy. Training required for missing splits.\n","No preprocessing for Dummy (using passthrough in pipeline)\n","Split 1: metrics already computed, loading from /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Modeling)/Dummy_cv_split_1.json\n","Split 2: metrics already computed, loading from /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Modeling)/Dummy_cv_split_2.json\n","Split 3: metrics already computed, loading from /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Modeling)/Dummy_cv_split_3.json\n","Split 4: metrics already computed, loading from /drive/MyDrive/Data Mining and Machine Learning/Progetto/Classification (Modeling)/Dummy_cv_split_4.json\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-225640e875ec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mlabel_col_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RISK_LEVEL_fold_engineered'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 )\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mstkde_label_generator_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0mX_train_fold_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstkde_label_generator_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mX_val_fold_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstkde_label_generator_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/drive/MyDrive/Data Mining and Machine Learning/Progetto/custom_transformers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# 3. Calculate STKDE intensities for this training data (X_train) using itself as reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m#    This is crucial: fit uses X_train to calculate intensities on X_train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         train_stkde_intensities = self._calculate_stkde_for_set(\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mtarget_coords_rad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_reference_coords_rad_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mtarget_datetime_np\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_reference_datetime_np_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/drive/MyDrive/Data Mining and Machine Learning/Progetto/custom_transformers.py\u001b[0m in \u001b[0;36m_calculate_stkde_for_set\u001b[0;34m(self, target_coords_rad, target_datetime_np, reference_coords_rad, reference_datetime_np, reference_balltree)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcurrent_stkde_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         stkde_intensities = Parallel(n_jobs=self.n_jobs, verbose=0)(\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_process_single_target_event\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_target_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2071\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 ):\n\u001b[0;32m-> 1799\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["print(\"=== Starting model evaluation with Cross-Validation ===\")\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","# --- Load optimal STKDE parameters ---\n","optimal_stkde_params_path = os.path.join(preprocessing_dir, 'stkde_optimal_params.json')\n","hs_optimal = 200.0  # Default\n","ht_optimal = 60.0   # Default\n","try:\n","    with open(optimal_stkde_params_path, 'r') as f:\n","        params = json.load(f)\n","        hs_optimal = params.get('hs_opt', hs_optimal)\n","        ht_optimal = params.get('ht_opt', ht_optimal)\n","    print(f\"Loaded optimal STKDE parameters: hs={hs_optimal}, ht={ht_optimal}\")\n","except FileNotFoundError:\n","    print(f\"Optimal STKDE parameters file not found: {optimal_stkde_params_path}. Using default values hs={hs_optimal}, ht={ht_optimal}.\")\n","except Exception as e:\n","    print(f\"Error loading STKDE parameters: {e}. Using default values hs={hs_optimal}, ht={ht_optimal}.\")\n","# --- End loading optimal STKDE parameters ---\n","\n","cv_results_all_models = {}\n","\n","# --- TimeSeriesSplit logic ---\n","# Ensure 'YEAR', 'MONTH', 'DAY', 'HOUR' are numeric for sorting\n","for col in ['YEAR', 'MONTH', 'DAY', 'HOUR']:\n","    if col in X_train.columns:\n","        X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n","    if col in X_test.columns:\n","        X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n","\n","# Sort X_train by time for proper TimeSeriesSplit\n","X_train_sorted = X_train.sort_values(['YEAR', 'MONTH', 'DAY', 'HOUR']).reset_index(drop=True)\n","y_train_sorted = y_train[X_train_sorted.index]\n","\n","n_splits = 5\n","cv_strategy = TimeSeriesSplit(n_splits=n_splits)\n","print(f\"Using TimeSeriesSplit with {n_splits} splits for time-aware cross-validation.\")\n","\n","# Directory for cached splits with engineered labels\n","split_cache_dir = os.path.join(modeling_results_dir, \"split_label_cache\")\n","os.makedirs(split_cache_dir, exist_ok=True)\n","\n","for model_name, model_instance in models_to_evaluate.items():\n","    if model_instance is None:\n","        print(f\"Skipping {model_name} as it is not available.\")\n","        if model_name not in cv_results_all_models:\n","             cv_results_all_models[model_name] = {metric: np.nan for metric in scoring.keys()}\n","        continue\n","\n","    print(f\"\\n--- Processing {model_name} ---\")\n","    n_splits = 5\n","    split_metric_files = [\n","        os.path.join(modeling_results_dir, f\"{model_name}_cv_split_{i+1}.json\")\n","        for i in range(n_splits)\n","    ]\n","    all_splits_exist = all(os.path.exists(f) for f in split_metric_files)\n","    train_model_cv = not all_splits_exist\n","\n","    if all_splits_exist:\n","        print(f\"All split metric files found for {model_name}. Loading per-split results.\")\n","        split_scores = []\n","        for split_file in split_metric_files:\n","            with open(split_file, 'r') as f:\n","                split_scores.append(json.load(f))\n","        # Aggregate metrics across all folds\n","        avg_scores = {}\n","        for metric in scoring.keys():\n","            metric_values = [s.get(metric, np.nan) for s in split_scores]\n","            avg_scores[metric] = float(np.nanmean(metric_values))\n","        cv_results_all_models[model_name] = avg_scores\n","        print(f\"Aggregated CV results for {model_name}:\")\n","        for metric_key_loaded, score_loaded in avg_scores.items():\n","            print(f\"    {metric_key_loaded}: {score_loaded:.4f}\")\n","    else:\n","        print(f\"Not all split metric files found for {model_name}. Training required for missing splits.\")\n","        # --- Setup pipeline as before ---\n","        current_preprocessing_pipeline_obj = None\n","        if model_name == 'Dummy':\n","            current_preprocessing_pipeline_obj = 'passthrough'\n","            print(\"No preprocessing for Dummy (using passthrough in pipeline)\")\n","        elif model_name in ['DecisionTree', 'RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM']:\n","            current_preprocessing_pipeline_obj = preprocessing_pipeline_trees\n","            print(f\"Using tree-optimized pipeline for {model_name}\")\n","        elif model_name == 'BernoulliNB':\n","            current_preprocessing_pipeline_obj = preprocessing_pipeline_bernoulli\n","            print(f\"Using BernoulliNB-optimized pipeline for {model_name}\")\n","        else:\n","            current_preprocessing_pipeline_obj = preprocessing_pipeline_general\n","            print(f\"Using general preprocessing pipeline for {model_name}\")\n","\n","        # --- Define STKDE and label engineering step ---\n","        stkde_label_generator = STKDEAndRiskLabelTransformer(\n","            hs=hs_optimal, ht=ht_optimal, n_classes=3, n_jobs=-1, random_state=42,\n","            intensity_col_name='stkde_intensity_fold',\n","            label_col_name='RISK_LEVEL_fold_engineered'\n","        )\n","\n","        # --- Define feature processing and classification pipeline ---\n","        feature_processing_and_classifier_pipeline = Pipeline([\n","            (\"feature_preprocessor\", current_preprocessing_pipeline_obj),\n","            (\"classifier\", model_instance)\n","        ])\n","\n","        # --- Combine into TargetEngineeringPipeline ---\n","        full_model_pipeline_for_cv = TargetEngineeringPipeline(\n","            target_engineer=stkde_label_generator,\n","            feature_pipeline=feature_processing_and_classifier_pipeline\n","        )\n","\n","        # --- Custom cross-validation loop with label caching ---\n","        cv_scores = {f'test_{metric}': [] for metric in scoring.keys()}\n","        split_idx = 0\n","        for train_idx, val_idx in cv_strategy.split(X_train_sorted):\n","            split_idx += 1\n","            split_metric_path = os.path.join(modeling_results_dir, f\"{model_name}_cv_split_{split_idx}.json\")\n","            split_cache_path = os.path.join(split_cache_dir, f\"split_{split_idx}_with_labels.csv\")\n","            if os.path.exists(split_metric_path):\n","                print(f\"Split {split_idx}: metrics already computed, loading from {split_metric_path}\")\n","                with open(split_metric_path, 'r') as f:\n","                    split_metrics = json.load(f)\n","                for metric in scoring.keys():\n","                    cv_scores[f'test_{metric}'].append(split_metrics.get(metric, np.nan))\n","                continue\n","\n","            # Prepare train/val splits and check for cached labels\n","            if os.path.exists(split_cache_path):\n","                print(f\"Loading cached split with engineered labels: {split_cache_path}\")\n","                split_df = pd.read_csv(split_cache_path)\n","                X_train_fold = split_df.loc[split_df['split'] == 'train'].drop(['split', 'engineered_label'], axis=1)\n","                y_train_fold = split_df.loc[split_df['split'] == 'train', 'engineered_label']\n","                X_val_fold = split_df.loc[split_df['split'] == 'val'].drop(['split', 'engineered_label'], axis=1)\n","                y_val_fold = split_df.loc[split_df['split'] == 'val', 'engineered_label']\n","            else:\n","                X_train_fold = X_train_sorted.iloc[train_idx].copy()\n","                X_val_fold = X_train_sorted.iloc[val_idx].copy()\n","                # Fit label engineer on train, transform both\n","                stkde_label_generator_fold = STKDEAndRiskLabelTransformer(\n","                    hs=hs_optimal, ht=ht_optimal, n_classes=3, n_jobs=-1, random_state=42,\n","                    intensity_col_name='stkde_intensity_fold',\n","                    label_col_name='RISK_LEVEL_fold_engineered'\n","                )\n","                stkde_label_generator_fold.fit(X_train_fold)\n","                X_train_fold_aug = stkde_label_generator_fold.transform(X_train_fold)\n","                X_val_fold_aug = stkde_label_generator_fold.transform(X_val_fold)\n","                y_train_fold = X_train_fold_aug['RISK_LEVEL_fold_engineered']\n","                y_val_fold = X_val_fold_aug['RISK_LEVEL_fold_engineered']\n","                # Save split with engineered labels for reuse\n","                train_fold_save = X_train_fold.copy()\n","                train_fold_save['split'] = 'train'\n","                train_fold_save['engineered_label'] = y_train_fold.values\n","                val_fold_save = X_val_fold.copy()\n","                val_fold_save['split'] = 'val'\n","                val_fold_save['engineered_label'] = y_val_fold.values\n","                split_df = pd.concat([train_fold_save, val_fold_save], axis=0)\n","                split_df.to_csv(split_cache_path, index=False)\n","                print(f\"Saved split with engineered labels: {split_cache_path}\")\n","\n","            # Fit model on train fold, evaluate on val fold\n","            feature_pipeline_fold = Pipeline([\n","                (\"feature_preprocessor\", current_preprocessing_pipeline_obj),\n","                (\"classifier\", model_instance)\n","            ])\n","            feature_pipeline_fold.fit(X_train_fold, y_train_fold)\n","            y_val_pred = feature_pipeline_fold.predict(X_val_fold)\n","            y_val_proba = None\n","            # Check if predict_proba exists and is callable\n","            if hasattr(feature_pipeline_fold, \"predict_proba\") and callable(feature_pipeline_fold.predict_proba):\n","                try:\n","                    y_val_proba = feature_pipeline_fold.predict_proba(X_val_fold)\n","                except Exception as e:\n","                    print(f\"Warning: Could not get probabilities for {model_name}: {e}\")\n","                    y_val_proba = None\n","\n","            # Compute metrics\n","            split_metrics = {}\n","            for metric_name, scorer in scoring.items():\n","                score = np.nan # Default to NaN if computation fails or proba needed but not available\n","                try:\n","                    if metric_name == 'accuracy':\n","                        score = accuracy_score(y_val_fold, y_val_pred)\n","                    elif metric_name == 'f1_weighted':\n","                        score = f1_score(y_val_fold, y_val_pred, average='weighted', zero_division=0)\n","                    elif metric_name == 'f1_macro':\n","                        score = f1_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n","                    elif metric_name == 'precision_weighted':\n","                        score = precision_score(y_val_fold, y_val_pred, average='weighted', zero_division=0)\n","                    elif metric_name == 'recall_weighted':\n","                        score = recall_score(y_val_fold, y_val_pred, average='weighted', zero_division=0)\n","                    elif metric_name == 'mcc':\n","                        score = matthews_corrcoef(y_val_fold, y_val_pred)\n","                    elif metric_name == 'ordinal_mae':\n","# Ensure ordinal_mae function is available\n","                        if 'ordinal_mae' in globals() and callable(globals()['ordinal_mae']):\n","                            score = ordinal_mae(y_val_fold, y_val_pred)\n","                        else:\n","                            print(f\"Warning: ordinal_mae function not found for metric {metric_name}\")\n","                            score = np.nan\n","                    elif metric_name == 'severe_error':\n","# Ensure severe_error_rate function is available\n","                        if 'severe_error_rate' in globals() and callable(globals()['severe_error_rate']):\n","                            score = severe_error_rate(y_val_fold, y_val_pred)\n","                        else:\n","                            print(f\"Warning: severe_error_rate function not found for metric {metric_name}\")\n","                            score = np.nan\n","                    elif metric_name == 'roc_auc_ovr_weighted':\n","                        if y_val_proba is not None and len(np.unique(y_val_fold)) > 1: # Check for multiple classes\n","                            try:\n","                                score = roc_auc_score(y_val_fold, y_val_proba, multi_class='ovr', average='weighted')\n","                            except ValueError as e:\n","                                print(f\"Warning: Could not compute ROC AUC for {model_name}, split {split_idx}: {e}\")\n","                                score = np.nan\n","                        else:\n","                            score = np.nan # Not applicable or probas not available\n","                    elif metric_name == 'pr_auc_ovr_weighted':\n","                        if y_val_proba is not None and len(np.unique(y_val_fold)) > 1: # Check for multiple classes\n","                            try:\n","                                score = average_precision_score(y_val_fold, y_val_proba, average='weighted')\n","                            except ValueError as e:\n","                                print(f\"Warning: Could not compute PR AUC for {model_name}, split {split_idx}: {e}\")\n","                                score = np.nan\n","                        else:\n","                            score = np.nan # Not applicable or probas not available\n","                    elif metric_name == 'neg_log_loss':\n","                        if y_val_proba is not None and len(np.unique(y_val_fold)) > 1: # Check for multiple classes\n","                            try:\n","# log_loss expects positive values, scorer has greater_is_better=False,\n","                                # so store the negative log loss directly.\n","                                score = log_loss(y_val_fold, y_val_proba)\n","                            except ValueError as e:\n","                                print(f\"Warning: Could not compute log loss for {model_name}, split {split_idx}: {e}\")\n","                                score = np.nan\n","                        else:\n","                            score = np.nan # Not applicable or probas not available\n","                    else:\n","                        # Fallback for any other scorers defined\n","                        # This re-introduces potential issues if the scorer's _score_func\n","                        # doesn't handle multiclass correctly without explicit args.\n","                        # A more robust approach would be to add more elif blocks\n","                        # for other specific scorers if needed.\n","                        if hasattr(scorer, '_score_func'):\n","                            needs_proba = getattr(scorer, 'kwargs', {}).get('needs_proba', False)\n","                            if needs_proba:\n","                                if y_val_proba is not None:\n","                                    score = scorer._score_func(y_val_fold, y_val_proba)\n","                                else:\n","                                    score = np.nan # Probas needed but not available\n","                            else:\n","                                score = scorer._score_func(y_val_fold, y_val_pred)\n","                        else:\n","                            print(f\"Warning: Scorer object for '{metric_name}' does not have _score_func or known type.\")\n","                            score = np.nan\n","\n","                except Exception as e:\n","                    print(f\"Error computing metric '{metric_name}' for {model_name}, split {split_idx}: {e}\")\n","                    import traceback\n","                    traceback.print_exc()\n","                    score = np.nan # Ensure NaN is stored if computation fails\n","\n","                cv_scores[f'test_{metric_name}'].append(score)\n","                split_metrics[metric_name] = score\n","\n","            # Save metrics for this split\n","            with open(split_metric_path, 'w') as f:\n","                json.dump(split_metrics, f, indent=4)\n","            print(f\"Saved metrics for split {split_idx} to {split_metric_path}\")\n","\n","        # Aggregate metrics across all folds\n","        avg_scores_calculated = {}\n","        print(f\"  CV Scores for {model_name}:\")\n","        for metric in scoring.keys():\n","            test_metric_key = f'test_{metric}'\n","            if test_metric_key in cv_scores:\n","                mean_score = np.nanmean(cv_scores[test_metric_key])\n","                std_score = np.nanstd(cv_scores[test_metric_key])\n","                avg_scores_calculated[metric] = mean_score\n","                print(f\"    {metric}: {mean_score:.4f} +/- {std_score:.4f}\")\n","            else:\n","                avg_scores_calculated[metric] = np.nan\n","                print(f\"    {metric}: Not computed (NaN)\")\n","        cv_results_all_models[model_name] = avg_scores_calculated\n","\n","        json_path = os.path.join(modeling_results_dir, f\"{model_name}_cv_results.json\")\n","        with open(json_path, 'w') as f:\n","            json.dump(avg_scores_calculated, f, indent=4)\n","        print(f\"CV results saved to: {json_path}\")"]},{"cell_type":"code","execution_count":null,"id":"dddcf1f2","metadata":{"id":"dddcf1f2","executionInfo":{"status":"aborted","timestamp":1747492001642,"user_tz":-120,"elapsed":60232,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[],"source":["# Cross-validation results visualization\n","\n","print(\"\\n=== Aggregated cross-validation results ===\")\n","if 'cv_results_all_models' in locals() and cv_results_all_models:\n","    cv_results_df = pd.DataFrame.from_dict(cv_results_all_models, orient='index')\n","    expected_metric_keys = list(scoring.keys())\n","    for metric_key in expected_metric_keys:\n","        if metric_key not in cv_results_df.columns:\n","            cv_results_df[metric_key] = np.nan\n","    print(\"\\nCross-validation results summary (means):\")\n","    if 'f1_weighted' in cv_results_df.columns:\n","        display(cv_results_df.sort_values(by='f1_weighted', ascending=False))\n","        plt.figure(figsize=(12, 8))\n","        sorted_df_plot = cv_results_df.sort_values(by='f1_weighted', ascending=False)\n","        sns.barplot(x=sorted_df_plot['f1_weighted'], y=sorted_df_plot.index)\n","        plt.title('Mean F1-Weighted (Cross-Validation)')\n","        plt.xlabel('F1-Weighted')\n","        plt.ylabel('Model')\n","        plt.tight_layout()\n","        plt.show()\n","    else:\n","        print(\"Displaying results without sorting by f1_weighted.\")\n","        display(cv_results_df)\n","else:\n","    print(\"No cross-validation results available.\")\n","    cv_results_df = pd.DataFrame()"]},{"cell_type":"markdown","id":"1fd814d2","metadata":{"id":"1fd814d2"},"source":["### Hyperparameter tuning\n","\n","The best model is selected and tuned via RandomizedSearchCV. The best model is chosen based on the main metric (f1_weighted, mcc, or accuracy)."]},{"cell_type":"code","execution_count":null,"id":"31a66b51","metadata":{"id":"31a66b51","executionInfo":{"status":"aborted","timestamp":1747492001644,"user_tz":-120,"elapsed":60234,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[],"source":["cv_results_df = pd.DataFrame(cv_results_all_models).T # Ensure cv_results_df is created\n","\n","if cv_results_df.empty or not any(col in cv_results_df.columns for col in ['f1_weighted', 'mcc', 'accuracy']) or cv_results_df[[col for col in ['f1_weighted', 'mcc', 'accuracy'] if col in cv_results_df.columns]].isnull().all().all():\n","    print(\"CV results are empty or key metrics (f1_weighted, mcc, accuracy) are missing/all NaN. Unable to select the best model for tuning.\")\n","    best_model_name_for_tuning = None\n","    best_tuned_full_pipeline = None\n","else:\n","    primary_metric_to_sort = None\n","    if 'f1_weighted' in cv_results_df.columns and not cv_results_df['f1_weighted'].isnull().all():\n","        primary_metric_to_sort = 'f1_weighted'\n","    elif 'mcc' in cv_results_df.columns and not cv_results_df['mcc'].isnull().all():\n","        primary_metric_to_sort = 'mcc'\n","    elif 'accuracy' in cv_results_df.columns and not cv_results_df['accuracy'].isnull().all():\n","        primary_metric_to_sort = 'accuracy'\n","\n","    if primary_metric_to_sort:\n","        best_model_name_for_tuning = cv_results_df[primary_metric_to_sort].idxmax()\n","        print(f\"Model selected for tuning based on {primary_metric_to_sort}: {best_model_name_for_tuning}\")\n","    else:\n","        print(\"Unable to determine a primary metric to sort models. Skipping tuning.\")\n","        best_model_name_for_tuning = None\n","        best_tuned_full_pipeline = None\n","\n","    # --- Load optimal STKDE parameters (as in the CV cell) ---\n","    optimal_stkde_params_path_tuning = os.path.join(preprocessing_dir, 'stkde_optimal_params.json')\n","    hs_optimal_tuning = 200.0  # Default\n","    ht_optimal_tuning = 60.0   # Default\n","    try:\n","        with open(optimal_stkde_params_path_tuning, 'r') as f:\n","            params_tuning = json.load(f)\n","            hs_optimal_tuning = params_tuning.get('hs_opt', hs_optimal_tuning)\n","            ht_optimal_tuning = params_tuning.get('ht_opt', ht_optimal_tuning)\n","        print(f\"Optimal STKDE parameters loaded for tuning: hs={hs_optimal_tuning}, ht={ht_optimal_tuning}\")\n","    except FileNotFoundError:\n","        print(f\"Optimal STKDE parameters file not found for tuning. Using default values hs={hs_optimal_tuning}, ht={ht_optimal_tuning}.\")\n","    except Exception as e:\n","        print(f\"Error loading STKDE parameters for tuning: {e}. Using default values hs={hs_optimal_tuning}, ht={ht_optimal_tuning}.\")\n","    # --- End loading optimal STKDE parameters ---\n","\n","    # Determine the correct preprocessing pipeline for the selected model\n","    tuning_feature_preprocessor_obj = None\n","    if best_model_name_for_tuning:\n","        if best_model_name_for_tuning in ['DecisionTree', 'RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM']:\n","            tuning_feature_preprocessor_obj = preprocessing_pipeline_trees\n","        elif best_model_name_for_tuning == 'BernoulliNB':\n","            tuning_feature_preprocessor_obj = preprocessing_pipeline_bernoulli\n","        elif best_model_name_for_tuning == 'Dummy':\n","            tuning_feature_preprocessor_obj = 'passthrough'\n","        else: # For LogisticRegression, KNN, SVC_rbf, SVC_linear, GaussianNB\n","            tuning_feature_preprocessor_obj = preprocessing_pipeline_general\n","        print(f\"Using {type(tuning_feature_preprocessor_obj).__name__ if tuning_feature_preprocessor_obj != 'passthrough' else 'passthrough'} for feature preprocessing during tuning of {best_model_name_for_tuning}\")\n","\n","    best_tuned_full_pipeline = None\n","    loaded_model_successfully = False\n","    if best_model_name_for_tuning and models_to_evaluate.get(best_model_name_for_tuning) is not None:\n","        best_tuned_model_path = os.path.join(modeling_results_dir, f'{best_model_name_for_tuning}_best_tuned_model.joblib')\n","        if os.path.exists(best_tuned_model_path):\n","            print(f\"\\nOptimized model found for {best_model_name_for_tuning} in: {best_tuned_model_path}\")\n","            try:\n","                best_tuned_full_pipeline = joblib.load(best_tuned_model_path)\n","                print(f\"Existing optimized model loaded successfully for {best_model_name_for_tuning}.\")\n","                loaded_model_successfully = True\n","            except Exception as e:\n","                print(f\"Error loading optimized model for {best_model_name_for_tuning}: {e}. Proceeding with tuning.\")\n","                best_tuned_full_pipeline = None\n","\n","    if not loaded_model_successfully and best_model_name_for_tuning and models_to_evaluate.get(best_model_name_for_tuning) is not None and tuning_feature_preprocessor_obj is not None:\n","        print(f\"\\nProceeding with tuning for {best_model_name_for_tuning}.\")\n","\n","        # Define parameter grids with correct prefixes for TargetEngineeringPipeline\n","        param_dist_rf = {\n","            'feature_pipeline__classifier__n_estimators': [100, 200, 300, 500],\n","            'feature_pipeline__classifier__max_features': ['sqrt', 'log2', 0.5],\n","            'feature_pipeline__classifier__max_depth': [10, 20, 30, None],\n","            'feature_pipeline__classifier__min_samples_split': [2, 5, 10],\n","            'feature_pipeline__classifier__min_samples_leaf': [1, 2, 4],\n","            'feature_pipeline__classifier__class_weight': ['balanced', 'balanced_subsample', None]\n","        }\n","        param_dist_gb = {\n","            'feature_pipeline__classifier__n_estimators': [100, 200, 300],\n","            'feature_pipeline__classifier__learning_rate': [0.01, 0.05, 0.1],\n","            'feature_pipeline__classifier__max_depth': [3, 5, 7]\n","        }\n","        param_dist_lr = {\n","            'feature_pipeline__classifier__C': np.logspace(-3, 3, 10),\n","            'feature_pipeline__classifier__penalty': ['l1', 'l2'],\n","            'feature_pipeline__classifier__solver': ['liblinear', 'saga']\n","        }\n","        param_dist_svc = {\n","            'feature_pipeline__classifier__C': np.logspace(-3, 2, 7),\n","            'feature_pipeline__classifier__kernel': ['linear', 'rbf'],\n","            'feature_pipeline__classifier__gamma': np.logspace(-3, 2, 7) # For rbf\n","        }\n","        param_dist_xgb = {\n","            'feature_pipeline__classifier__n_estimators': [100, 200, 300],\n","            'feature_pipeline__classifier__learning_rate': [0.01, 0.05, 0.1],\n","            'feature_pipeline__classifier__max_depth': [3, 5, 7]\n","        }\n","        param_dist_lgbm = {\n","            'feature_pipeline__classifier__n_estimators': [100, 200, 300],\n","            'feature_pipeline__classifier__learning_rate': [0.01, 0.05, 0.1],\n","            'feature_pipeline__classifier__num_leaves': [31, 50, 70]\n","        }\n","\n","        current_param_dist = None\n","        if best_model_name_for_tuning == 'RandomForest': current_param_dist = param_dist_rf\n","        elif best_model_name_for_tuning == 'GradientBoosting': current_param_dist = param_dist_gb\n","        elif best_model_name_for_tuning == 'LogisticRegression': current_param_dist = param_dist_lr\n","        elif best_model_name_for_tuning and best_model_name_for_tuning.startswith('SVC'): current_param_dist = param_dist_svc\n","        elif best_model_name_for_tuning == 'XGBoost': current_param_dist = param_dist_xgb\n","        elif best_model_name_for_tuning == 'LightGBM': current_param_dist = param_dist_lgbm\n","\n","        if current_param_dist:\n","            # --- Define STKDE and label engineering step for tuning ---\n","            stkde_label_generator_tuning = STKDEAndRiskLabelTransformer(\n","                hs=hs_optimal_tuning, ht=ht_optimal_tuning, n_classes=3, n_jobs=-1, random_state=42,\n","                intensity_col_name='stkde_intensity_tune',\n","                label_col_name='RISK_LEVEL_tune_engineered'\n","            )\n","\n","            # --- Define preprocessing and classification pipeline for tuning ---\n","            base_classifier_instance_tuning = models_to_evaluate[best_model_name_for_tuning]\n","            feature_processing_pipeline_tuning = Pipeline([\n","                (\"feature_preprocessor\", tuning_feature_preprocessor_obj),\n","                (\"classifier\", base_classifier_instance_tuning)\n","            ])\n","\n","            # --- Compose into TargetEngineeringPipeline for tuning ---\n","            pipeline_for_tuning_estimator = TargetEngineeringPipeline(\n","                target_engineer=stkde_label_generator_tuning,\n","                feature_pipeline=feature_processing_pipeline_tuning\n","            )\n","\n","            # Setup RandomizedSearchCV\n","            if 'cv_strategy' not in locals() or ('groups' not in locals() and isinstance(cv_strategy, GroupKFold)):\n","                 print(\"Warning: cv_strategy or groups for GroupKFold not found. Re-initializing for tuning.\")\n","                 if 'YEAR' in X_train.columns and 'MONTH' in X_train.columns:\n","                     dt_tune = pd.to_datetime(dict(year=X_train['YEAR'], month=X_train['MONTH'], day=1))\n","                     groups_tune = dt_tune.dt.to_period('M').astype(int)\n","                     cv_strategy_tune = GroupKFold(n_splits=5)\n","                 else:\n","                     groups_tune = None\n","                     cv_strategy_tune = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","            else:\n","                 cv_strategy_tune = cv_strategy\n","                 groups_tune = groups if 'groups' in locals() else None\n","\n","            refit_metric_tuning = None\n","            if 'f1_weighted' in scoring: refit_metric_tuning = 'f1_weighted'\n","            elif 'mcc' in scoring: refit_metric_tuning = 'mcc'\n","            elif 'accuracy' in scoring: refit_metric_tuning = 'accuracy'\n","            else:\n","                refit_metric_tuning = list(scoring.keys())[0]\n","                print(f\"Warning: defaulting RandomizedSearch refit metric to {refit_metric_tuning}\")\n","\n","\n","            random_search = RandomizedSearchCV(\n","                estimator=pipeline_for_tuning_estimator,\n","                param_distributions=current_param_dist,\n","                n_iter=20, # Reduced for speed, increase for thoroughness (50-100)\n","                cv=cv_strategy_tune,\n","                scoring=scoring,\n","                refit=refit_metric_tuning,\n","                n_jobs=-1,\n","                random_state=42,\n","                verbose=1,\n","                error_score=np.nan\n","            )\n","\n","            print(f\"\\nStarting RandomizedSearch CV for {best_model_name_for_tuning}...\")\n","            random_search.fit(X_train, y_train, groups=groups_tune if groups_tune is not None else None)\n","\n","            print(\"\\nBest parameters found:\")\n","            print(random_search.best_params_)\n","            print(f\"\\nBest {refit_metric_tuning} score during search: {random_search.best_score_:.4f}\")\n","\n","            best_tuned_full_pipeline = random_search.best_estimator_\n","            joblib.dump(best_tuned_full_pipeline, best_tuned_model_path)\n","            print(f\"\\nBest optimized model saved in: {best_tuned_model_path}\")\n","\n","            search_results_path = os.path.join(modeling_results_dir, f'{best_model_name_for_tuning}_random_search_results.joblib')\n","            joblib.dump(random_search.cv_results_, search_results_path)\n","            print(f\"RandomizedSearch results saved in: {search_results_path}\")\n","        else:\n","            print(f\"No specific hyperparameter grid for {best_model_name_for_tuning}, or model not typically tuned (e.g., Dummy). Fitting the base model.\")\n","            stkde_label_generator_base = STKDEAndRiskLabelTransformer(\n","                hs=hs_optimal_tuning, ht=ht_optimal_tuning, n_classes=3, n_jobs=-1, random_state=42\n","            )\n","            base_classifier_instance = models_to_evaluate[best_model_name_for_tuning]\n","            feature_processing_pipeline_base = Pipeline([\n","                (\"feature_preprocessor\", tuning_feature_preprocessor_obj),\n","                (\"classifier\", base_classifier_instance)\n","            ])\n","            best_tuned_full_pipeline = TargetEngineeringPipeline(\n","                target_engineer=stkde_label_generator_base,\n","                feature_pipeline=feature_processing_pipeline_base\n","            )\n","            print(f\"Fitting the base pipeline for {best_model_name_for_tuning} on the full training data...\")\n","            best_tuned_full_pipeline.fit(X_train, y_train)\n","            joblib.dump(best_tuned_full_pipeline, best_tuned_model_path)\n","            print(f\"Base model fitted and saved in: {best_tuned_model_path}\")\n","\n","    elif not best_model_name_for_tuning:\n","        print(\"Skipping tuning, no best model determined.\")\n","        best_tuned_full_pipeline = None\n","    else:\n","        print(f\"\\nUsing the pre-loaded optimized model for {best_model_name_for_tuning}. Skipping tuning/fitting.\")"]},{"cell_type":"code","execution_count":null,"id":"9f20d1e5","metadata":{"id":"9f20d1e5","executionInfo":{"status":"aborted","timestamp":1747492001646,"user_tz":-120,"elapsed":60236,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[],"source":["# Final evaluation on the test set\n","\n","# The variable from the previous cell should be 'best_tuned_full_pipeline'\n","if 'best_tuned_full_pipeline' in locals() and best_tuned_full_pipeline is not None:\n","    final_model_name_eval = \"TunedModel\"\n","    try:\n","        final_classifier_step = best_tuned_full_pipeline.feature_pipeline_.named_steps.get('classifier')\n","        if final_classifier_step:\n","            final_model_name_eval = final_classifier_step.__class__.__name__\n","        if 'best_model_name_for_tuning' in locals() and best_model_name_for_tuning:\n","            final_model_name_eval = best_model_name_for_tuning\n","    except AttributeError:\n","        pass # Default name\n","\n","    print(f\"\\n=== Final evaluation of {final_model_name_eval} (from TargetEngineeringPipeline) on the test set ===\")\n","\n","    y_pred_test_engineered = best_tuned_full_pipeline.predict(X_test)\n","\n","    y_proba_test_engineered = None\n","    if hasattr(best_tuned_full_pipeline, \"predict_proba\"):\n","        try:\n","            y_proba_test_engineered = best_tuned_full_pipeline.predict_proba(X_test)\n","        except Exception as e:\n","            print(f\"Unable to obtain probabilities from best_tuned_full_pipeline: {e}\")\n","\n","    # --- Generate true engineered labels for the test set ---\n","    try:\n","        stkde_transformer_fitted_on_full_train = best_tuned_full_pipeline.target_engineer_\n","        if not isinstance(X_test, pd.DataFrame):\n","            if 'feature_names' in locals() and feature_names is not None:\n","                X_test_df_eval = pd.DataFrame(X_test, columns=feature_names)\n","            else:\n","                 raise ValueError(\"X_test is not a DataFrame and feature_names are not available to reconstruct it.\")\n","        else:\n","            X_test_df_eval = X_test\n","\n","        X_test_transformed_by_stkde = stkde_transformer_fitted_on_full_train.transform(X_test_df_eval)\n","        true_label_col_name = stkde_transformer_fitted_on_full_train.label_col_name\n","        y_test_engineered_true = X_test_transformed_by_stkde[true_label_col_name]\n","        print(f\"Engineered true labels for the test set generated successfully: {true_label_col_name}\")\n","        print(f\"Class counts for y_test_engineered_true:\\n{y_test_engineered_true.value_counts().sort_index()}\")\n","        print(f\"Class counts for y_pred_test_engineered:\\n{pd.Series(y_pred_test_engineered).value_counts().sort_index()}\")\n","\n","    except Exception as e:\n","        print(f\"Error generating true labels for the test set: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        print(\"CRITICAL WARNING: Using original y_test for evaluation, metrics may be incorrect.\")\n","        y_test_engineered_true = y_test\n","\n","    # --- Compute and print metrics with y_test_engineered_true and y_pred_test_engineered ---\n","    test_metrics = {}\n","    print(\"\\n--- Test set metrics (engineered target) ---\")\n","\n","    test_metrics['accuracy'] = accuracy_score(y_test_engineered_true, y_pred_test_engineered)\n","    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n","\n","    test_metrics['f1_weighted'] = f1_score(y_test_engineered_true, y_pred_test_engineered, average='weighted', zero_division=0)\n","    print(f\"F1-Weighted: {test_metrics['f1_weighted']:.4f}\")\n","    test_metrics['f1_macro'] = f1_score(y_test_engineered_true, y_pred_test_engineered, average='macro', zero_division=0)\n","    print(f\"F1-Macro: {test_metrics['f1_macro']:.4f}\")\n","\n","    test_metrics['precision_weighted'] = precision_score(y_test_engineered_true, y_pred_test_engineered, average='weighted', zero_division=0)\n","    print(f\"Precision-Weighted: {test_metrics['precision_weighted']:.4f}\")\n","    test_metrics['recall_weighted'] = recall_score(y_test_engineered_true, y_pred_test_engineered, average='weighted', zero_division=0)\n","    print(f\"Recall-Weighted: {test_metrics['recall_weighted']:.4f}\")\n","\n","    if y_proba_test_engineered is not None:\n","        num_classes_engineered = len(np.unique(y_test_engineered_true))\n","        if num_classes_engineered == 2:\n","            test_metrics['roc_auc'] = roc_auc_score(y_test_engineered_true, y_proba_test_engineered[:, 1])\n","            print(f\"ROC AUC: {test_metrics['roc_auc']:.4f}\")\n","        elif num_classes_engineered > 2:\n","            try:\n","                test_metrics['roc_auc_ovr_weighted'] = roc_auc_score(y_test_engineered_true, y_proba_test_engineered, multi_class='ovr', average='weighted')\n","                print(f\"ROC AUC (OvR Weighted): {test_metrics['roc_auc_ovr_weighted']:.4f}\")\n","            except ValueError as e:\n","                print(f\"Unable to compute ROC AUC for multiclass: {e}. Probas shape: {y_proba_test_engineered.shape}, Unique true labels: {np.unique(y_test_engineered_true)}\")\n","        else:\n","             print(\"ROC AUC not applicable, only one class in y_test_engineered_true.\")\n","\n","    if 'ordinal_mae' in scoring:\n","        mae = ordinal_mae(y_test_engineered_true, y_pred_test_engineered)\n","        test_metrics['ordinal_mae'] = mae\n","        print(f\"Ordinal MAE: {mae:.4f}\")\n","    if 'severe_error' in scoring:\n","        ser = severe_error_rate(y_test_engineered_true, y_pred_test_engineered)\n","        test_metrics['severe_error'] = ser\n","        print(f\"Severe Error Rate (2-tier): {ser:.4f}\")\n","\n","    test_metrics['mcc'] = matthews_corrcoef(y_test_engineered_true, y_pred_test_engineered)\n","    print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n","\n","    print(\"\\n--- Classification report (Test Set - Engineered Target) ---\")\n","    unique_engineered_labels = np.unique(y_test_engineered_true)\n","    class_labels_engineered = [str(lbl) for lbl in sorted(unique_engineered_labels)]\n","    print(classification_report(y_test_engineered_true, y_pred_test_engineered, target_names=class_labels_engineered, zero_division=0))\n","\n","    print(\"\\n--- Confusion matrix (Test Set - Engineered Target) ---\")\n","    cm = confusion_matrix(y_test_engineered_true, y_pred_test_engineered, labels=sorted(unique_engineered_labels))\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels_engineered)\n","    disp.plot(cmap=plt.cm.Blues)\n","    plt.title(f'Confusion Matrix for {final_model_name_eval} (Engineered Target)')\n","    plt.show()\n","\n","    print('\\n--- Ordinal error analysis (Test Set - Engineered Target) ---')\n","    if 'ordinal_error_analysis' in locals():\n","         ordinal_error_analysis(y_test_engineered_true, y_pred_test_engineered)\n","    else:\n","        print(\"Warning: ordinal_error_analysis function not found.\")\n","\n","    test_metrics_path = os.path.join(modeling_results_dir, f'{final_model_name_eval}_engineered_test_set_metrics.json')\n","    with open(test_metrics_path, 'w') as f:\n","        json.dump(test_metrics, f, indent=4)\n","    print(f\"\\nTest set metrics saved in: {test_metrics_path}\")\n","\n","else:\n","    print(\"Skipping final evaluation on the test set: 'best_tuned_full_pipeline' is not defined or None.\")"]},{"cell_type":"markdown","id":"93caa2e8","metadata":{"id":"93caa2e8"},"source":["## Obsolete section: previous use of STKDE Transformer\n","\n","This section is obsolete: the generation of STKDE intensity and the RISK_LEVEL label is now performed in a leakage-free way via custom transformers and the dedicated pipeline."]},{"cell_type":"markdown","id":"c795a4ba","metadata":{"id":"c795a4ba"},"source":["# Leakage-free STKDE and label engineering\n","\n","All feature/label engineering operations are performed only after the split and within each cross-validation fold, to prevent any form of leakage."]},{"cell_type":"code","execution_count":null,"id":"1b74c4b3","metadata":{"id":"1b74c4b3","executionInfo":{"status":"aborted","timestamp":1747492001646,"user_tz":-120,"elapsed":60236,"user":{"displayName":"Ferdinando Muraca","userId":"08570199584316918220"}}},"outputs":[],"source":["# (remove useless placeholder cells, move explanations to markdown)"]},{"cell_type":"markdown","id":"53382044","metadata":{"id":"53382044"},"source":["**Conceptual usage example:**\n","\n","The leakage-free pipeline combines STKDEAndRiskLabelTransformer and TargetEngineeringPipeline to ensure that the label is always generated only on the training data of each fold."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":5}