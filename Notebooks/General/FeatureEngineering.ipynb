{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2Hj0Iuf1MyZ"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This section covers the initial setup, including library imports, path definitions, and mounting Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41DtTmv71Myi"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2510,
     "status": "ok",
     "timestamp": 1748178712046,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "Tuu7pkI9UfzG",
    "outputId": "4946fc35-bf52-44c3-98e6-975637ac92d7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sSfOzCv1Myp"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3007,
     "status": "ok",
     "timestamp": 1748178715066,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "1LacEnEqU9Le",
    "outputId": "a887bf07-3312-4cdc-8f12-7c1a2dd03052"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "# !pip install openpyxl\n",
    "import openpyxl\n",
    "# !pip install holidays\n",
    "import holidays\n",
    "from datetime import datetime\n",
    "\n",
    "# Enhanced ML imports for better preprocessing pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKclXTRD1Mys"
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1748178715118,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "TiQNMfDG1Myt",
    "outputId": "10b92807-ca09-4996-8a5b-c9efbe9a4357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\ferdi\\Documents\\GitHub\\crime-analyzer\\JupyterOutputs\n",
      "Feature engineering output directory: C:\\Users\\ferdi\\Documents\\GitHub\\crime-analyzer\\JupyterOutputs\\FeatureEngineered\n",
      "Looking for cleaned integrated data at: C:\\Users\\ferdi\\Documents\\GitHub\\crime-analyzer\\JupyterOutputs\\DataIntegrated\\cleaned_integrated_crime_data.csv\n",
      "Looking for PD codes file at: C:\\Users\\ferdi\\Documents\\GitHub\\crime-analyzer\\JupyterOutputs\\..\\Documents\\PDCode_PenalLaw.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Path variables\n",
    "# base_dir = \"/drive/MyDrive/Data Mining and Machine Learning/Progetto\"\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"JupyterOutputs\"))\n",
    "cleaned_integrated_dir = os.path.join(base_dir, \"DataIntegrated\")\n",
    "cleaned_integrated_data_file = os.path.join(cleaned_integrated_dir, \"cleaned_integrated_crime_data.csv\")\n",
    "feature_engineering_dir = os.path.join(base_dir, \"FeatureEngineered\")\n",
    "feature_engineered_file_path = os.path.join(feature_engineering_dir, \"feature_engineered_crime_data.csv\")\n",
    "pd_codes_file = os.path.join(os.path.dirname(os.path.dirname(base_dir)), \"Documents\", \"PDCode_PenalLaw.xlsx\")\n",
    "\n",
    "# Check if pd_codes_file exists\n",
    "if not os.path.exists(pd_codes_file):\n",
    "    raise FileNotFoundError(f\"PD codes file not found at: {pd_codes_file}\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(feature_engineering_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {base_dir}\")\n",
    "print(f\"Feature engineering output directory: {feature_engineering_dir}\")\n",
    "print(f\"Looking for cleaned integrated data at: {cleaned_integrated_data_file}\")\n",
    "print(f\"Looking for PD codes file at: {pd_codes_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4o_3FSAu1Myv"
   },
   "source": [
    "# Load Integrated Data\n",
    "\n",
    "Load the dataset produced by the Data Integration phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12966,
     "status": "ok",
     "timestamp": 1748178728085,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "hQa_cHI51Myw",
    "outputId": "0445f303-999a-4007-814f-8f66325564f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Integrated Data ===\n",
      "Dataset loaded successfully: 2496759 rows and 34 columns\n",
      "Columns in the dataset: ['BORO_NM', 'CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'KY_CD', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PARKS_NM', 'PD_CD', 'PREM_TYP_DESC', 'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX', 'Latitude', 'Longitude', 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'METRO_DISTANCE', 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE', 'TOTAL_POI_COUNT', 'POI_DIVERSITY', 'POI_DENSITY_SCORE']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"=== Loading Integrated Data ===\")\n",
    "try:\n",
    "    if os.path.exists(cleaned_integrated_data_file):\n",
    "        df = pd.read_csv(cleaned_integrated_data_file)\n",
    "        initial_rows = len(df)\n",
    "        print(f\"Dataset loaded successfully: {initial_rows} rows and {df.shape[1]} columns\")\n",
    "        print(f\"Columns in the dataset: {df.columns.tolist()}\")\n",
    "\n",
    "        # Basic validation\n",
    "        if initial_rows == 0:\n",
    "            raise ValueError(\"Dataset is empty\")\n",
    "        if df.shape[1] < 5:\n",
    "            raise ValueError(\"Dataset has insufficient columns\")\n",
    "\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find cleaned integrated dataset at: {cleaned_integrated_data_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    raise RuntimeError(f\"Failed to load required dataset for feature engineering: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-YTL1oE1Myy"
   },
   "source": [
    "## Initial Data Overview\n",
    "\n",
    "Display basic information, summary statistics, and a sample of the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1765,
     "status": "ok",
     "timestamp": 1748178729879,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "h2oYsWIX1Myy",
    "outputId": "562f587f-ea73-4be6-f2e2-0332525a1cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Overview ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2496759 entries, 0 to 2496758\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   BORO_NM             object \n",
      " 1   CMPLNT_FR_DT        object \n",
      " 2   CMPLNT_FR_TM        object \n",
      " 3   KY_CD               int64  \n",
      " 4   LAW_CAT_CD          object \n",
      " 5   LOC_OF_OCCUR_DESC   object \n",
      " 6   OFNS_DESC           object \n",
      " 7   PARKS_NM            object \n",
      " 8   PD_CD               int64  \n",
      " 9   PREM_TYP_DESC       object \n",
      " 10  SUSP_AGE_GROUP      object \n",
      " 11  SUSP_RACE           object \n",
      " 12  SUSP_SEX            object \n",
      " 13  VIC_AGE_GROUP       object \n",
      " 14  VIC_RACE            object \n",
      " 15  VIC_SEX             object \n",
      " 16  Latitude            float64\n",
      " 17  Longitude           float64\n",
      " 18  BAR_DISTANCE        float64\n",
      " 19  NIGHTCLUB_DISTANCE  float64\n",
      " 20  ATM_DISTANCE        float64\n",
      " 21  ATMS_COUNT          float64\n",
      " 22  BARS_COUNT          float64\n",
      " 23  BUS_STOPS_COUNT     float64\n",
      " 24  METROS_COUNT        float64\n",
      " 25  NIGHTCLUBS_COUNT    float64\n",
      " 26  SCHOOLS_COUNT       float64\n",
      " 27  METRO_DISTANCE      float64\n",
      " 28  MIN_POI_DISTANCE    float64\n",
      " 29  AVG_POI_DISTANCE    float64\n",
      " 30  MAX_POI_DISTANCE    float64\n",
      " 31  TOTAL_POI_COUNT     float64\n",
      " 32  POI_DIVERSITY       int64  \n",
      " 33  POI_DENSITY_SCORE   float64\n",
      "dtypes: float64(17), int64(3), object(14)\n",
      "memory usage: 647.7+ MB\n",
      "None\n",
      "\n",
      "=== Summary Statistics ===\n",
      "              KY_CD         PD_CD      Latitude     Longitude  BAR_DISTANCE  \\\n",
      "count  2.496759e+06  2.496759e+06  2.496759e+06  2.496759e+06  2.496759e+06   \n",
      "mean   3.025155e+02  4.084761e+02  4.073661e+01 -7.392281e+01  9.304923e+02   \n",
      "std    1.595039e+02  2.211384e+02  1.344466e-01  2.077602e-01  3.581217e+04   \n",
      "min    1.020000e+02  1.000000e+02  0.000000e+00 -7.425474e+01  4.102764e+00   \n",
      "25%    1.170000e+02  2.540000e+02  4.067561e+01 -7.397274e+01  2.132541e+02   \n",
      "50%    3.410000e+02  3.520000e+02  4.073495e+01 -7.392571e+01  5.848092e+02   \n",
      "75%    3.510000e+02  6.380000e+02  4.081194e+01 -7.387948e+01  1.180303e+03   \n",
      "max    8.810000e+02  9.690000e+02  4.091271e+01  0.000000e+00  1.372163e+07   \n",
      "\n",
      "       NIGHTCLUB_DISTANCE  ATM_DISTANCE    ATMS_COUNT    BARS_COUNT  \\\n",
      "count        2.496759e+06  2.496759e+06  2.496742e+06  2.496742e+06   \n",
      "mean         2.115418e+03  1.444943e+03  1.463507e-02  6.523982e-02   \n",
      "std          3.584537e+04  3.582254e+04  1.318330e-01  3.305598e-01   \n",
      "min          5.889870e+00  9.675179e+00  0.000000e+00  0.000000e+00   \n",
      "25%          7.718525e+02  4.615127e+02  0.000000e+00  0.000000e+00   \n",
      "50%          1.524675e+03  1.065681e+03  0.000000e+00  0.000000e+00   \n",
      "75%          2.537621e+03  1.878874e+03  0.000000e+00  0.000000e+00   \n",
      "max          1.372083e+07  1.372270e+07  5.000000e+00  6.000000e+00   \n",
      "\n",
      "       BUS_STOPS_COUNT  METROS_COUNT  NIGHTCLUBS_COUNT  SCHOOLS_COUNT  \\\n",
      "count     2.496742e+06  2.496742e+06      2.496742e+06   2.496742e+06   \n",
      "mean      4.109676e-01  5.793270e-02      4.794648e-03   2.806698e-02   \n",
      "std       7.815628e-01  2.529411e-01      7.512655e-02   2.069132e-01   \n",
      "min       0.000000e+00  0.000000e+00      0.000000e+00   0.000000e+00   \n",
      "25%       0.000000e+00  0.000000e+00      0.000000e+00   0.000000e+00   \n",
      "50%       0.000000e+00  0.000000e+00      0.000000e+00   0.000000e+00   \n",
      "75%       1.000000e+00  0.000000e+00      0.000000e+00   0.000000e+00   \n",
      "max       6.000000e+00  2.000000e+00      2.000000e+00   7.000000e+00   \n",
      "\n",
      "       METRO_DISTANCE  MIN_POI_DISTANCE  AVG_POI_DISTANCE  MAX_POI_DISTANCE  \\\n",
      "count    2.496759e+06      2.496759e+06      2.496759e+06      2.496759e+06   \n",
      "mean     6.870371e+02      4.815086e+02      1.294473e+03      2.450955e+03   \n",
      "std      3.580790e+04      3.580184e+04      3.581097e+04      3.584812e+04   \n",
      "min      1.336284e-01      1.336284e-01      4.315403e+01      7.243958e+01   \n",
      "25%      1.926433e+02      1.212059e+02      5.940558e+02      1.178856e+03   \n",
      "50%      3.482616e+02      2.584415e+02      9.681934e+02      1.878874e+03   \n",
      "75%      6.627598e+02      4.907645e+02      1.593445e+03      2.938993e+03   \n",
      "max      1.372000e+07      1.372000e+07      1.372129e+07      1.372270e+07   \n",
      "\n",
      "       TOTAL_POI_COUNT  POI_DIVERSITY  POI_DENSITY_SCORE  \n",
      "count     2.496759e+06   2.496759e+06       2.496759e+06  \n",
      "mean      5.816328e-01   4.172161e-01       6.462587e-02  \n",
      "std       1.009304e+00   6.428944e-01       1.121449e-01  \n",
      "min       0.000000e+00   0.000000e+00       0.000000e+00  \n",
      "25%       0.000000e+00   0.000000e+00       0.000000e+00  \n",
      "50%       0.000000e+00   0.000000e+00       0.000000e+00  \n",
      "75%       1.000000e+00   1.000000e+00       1.111111e-01  \n",
      "max       9.000000e+00   4.000000e+00       1.000000e+00  \n",
      "\n",
      "=== Sample Row ===\n",
      "        BORO_NM CMPLNT_FR_DT  CMPLNT_FR_TM  KY_CD LAW_CAT_CD  \\\n",
      "2085206  QUEENS   2022/03/15  06:30:00.000    578  VIOLATION   \n",
      "\n",
      "        LOC_OF_OCCUR_DESC      OFNS_DESC PARKS_NM  PD_CD  \\\n",
      "2085206            INSIDE  HARRASSMENT 2   (NULL)    637   \n",
      "\n",
      "                  PREM_TYP_DESC  ... METROS_COUNT NIGHTCLUBS_COUNT  \\\n",
      "2085206  RESIDENCE - APT. HOUSE  ...          0.0              0.0   \n",
      "\n",
      "        SCHOOLS_COUNT METRO_DISTANCE MIN_POI_DISTANCE AVG_POI_DISTANCE  \\\n",
      "2085206           0.0    1158.635538       988.785484      1585.535707   \n",
      "\n",
      "         MAX_POI_DISTANCE  TOTAL_POI_COUNT  POI_DIVERSITY  POI_DENSITY_SCORE  \n",
      "2085206       2907.344456              0.0              0                0.0  \n",
      "\n",
      "[1 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display basic dataset overview\n",
    "print(\"\\n=== Dataset Overview ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(df.describe())\n",
    "print(\"\\n=== Sample Row ===\")\n",
    "print(df.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiEUP0bl1Myz"
   },
   "source": [
    "# Load External PD Codes\n",
    "\n",
    "Load the external Excel file containing mappings between PD codes and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1748178730498,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "9GFR487mVSuk",
    "outputId": "7189dc67-8bcf-4cdf-8b3a-49ebff3a6317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading External PD Codes ===\n",
      "PD Codes dataset loaded successfully: 4671 rows and 5 columns\n",
      "Columns in the codes dataset: ['PDCODE_VALUE', 'LAW_NYS', 'CATEGORY', 'LIT_LONG', 'LIT_SHORT']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Loading External PD Codes ===\")\n",
    "try:\n",
    "    if os.path.exists(pd_codes_file):\n",
    "        df_codes = pd.read_excel(pd_codes_file)\n",
    "        initial_rows = len(df_codes)\n",
    "        print(f\"PD Codes dataset loaded successfully: {initial_rows} rows and {df_codes.shape[1]} columns\")\n",
    "        print(f\"Columns in the codes dataset: {df_codes.columns.tolist()}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find PD codes dataset at: {pd_codes_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PD codes dataset: {e}\")\n",
    "    # Instead of exit(1), print the error and continue\n",
    "    print(f\"Error details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiG2vYHD1My1"
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This section focuses on creating new features and refining existing ones based on domain knowledge and data characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBOSQZPJ1My1"
   },
   "source": [
    "## 1. Impute Missing `OFNS_DESC`\n",
    "\n",
    "Fill missing offense descriptions (`OFNS_DESC`) using the mapping from `PD_CD` to `LIT_SHORT` found in the external codes file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1436,
     "status": "ok",
     "timestamp": 1748178731941,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "tIIijAchmG0T",
    "outputId": "1b8a2c88-d318-402d-db36-6f91f4083fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Imputing OFNS_DESC ===\n",
      "OFNS_DESC missing before imputation: 44\n",
      "OFNS_DESC missing after imputation:  0\n",
      "Number of values filled: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Imputing OFNS_DESC ===\")\n",
    "# Ensure both codes are of type string\n",
    "df['PD_CD'] = df['PD_CD'].astype(str)\n",
    "df_codes['PDCODE_VALUE'] = df_codes['PDCODE_VALUE'].astype(str)\n",
    "\n",
    "# Create a mapping dictionary from the first occurrence of each code\n",
    "code_to_lit_short = df_codes.drop_duplicates(subset='PDCODE_VALUE').set_index('PDCODE_VALUE')['LIT_SHORT'].to_dict()\n",
    "\n",
    "# Fill OFNS_DESC where it's '(null)' using the mapping\n",
    "null_mask = df['OFNS_DESC'] == '(null)'\n",
    "initial_nulls = df['OFNS_DESC'].isin(['(null)', None, np.nan]).sum()\n",
    "df.loc[null_mask, 'OFNS_DESC'] = (\n",
    "    df.loc[null_mask, 'PD_CD'].map(code_to_lit_short)\n",
    "    .str.strip()\n",
    "    .fillna(df.loc[null_mask, 'OFNS_DESC']) # Keep original if map fails\n",
    ")\n",
    "\n",
    "# count missing after imputation\n",
    "final_nulls = df['OFNS_DESC'].isin(['(null)', None, np.nan]).sum()\n",
    "\n",
    "# print summary\n",
    "print(f\"OFNS_DESC missing before imputation: {initial_nulls}\")\n",
    "print(f\"OFNS_DESC missing after imputation:  {final_nulls}\")\n",
    "print(f\"Number of values filled: {initial_nulls - final_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj6cDf2-1My2"
   },
   "source": [
    "## 2. Create Temporal Features\n",
    "\n",
    "Extract time-based features from the complaint date and time:\n",
    "- `HOUR`: Hour of the day (0-23)\n",
    "- `WEEKDAY`: Name of the day (e.g., MONDAY)\n",
    "- `IS_WEEKEND`: Binary flag (1 for Saturday/Sunday, 0 otherwise)\n",
    "- `MONTH`: Month of the year (1-12)\n",
    "- `SEASON`: Categorical season (WINTER, SPRING, SUMMER, AUTUMN)\n",
    "- `TIME_BUCKET`: Categorical time of day (NIGHT, MORNING, AFTERNOON, EVENING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5281,
     "status": "ok",
     "timestamp": 1748178737233,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "ZlJflmjWRDb0",
    "outputId": "74faa24a-8b28-4180-d099-752777246fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Temporal Features ===\n",
      "Created temporal features: HOUR, DAY, WEEKDAY, IS_WEEKEND, MONTH, YEAR, SEASON, TIME_BUCKET\n",
      "Columns after adding temporal features: ['BORO_NM', 'KY_CD', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PARKS_NM', 'PD_CD', 'PREM_TYP_DESC', 'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX', 'Latitude', 'Longitude', 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'METRO_DISTANCE', 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE', 'TOTAL_POI_COUNT', 'POI_DIVERSITY', 'POI_DENSITY_SCORE', 'HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Temporal Features ===\")\n",
    "# 1) Unified timestamp (temporary)\n",
    "df['TIMESTAMP'] = pd.to_datetime(\n",
    "    df['CMPLNT_FR_DT'] + ' ' + df['CMPLNT_FR_TM'],\n",
    "    format='%Y/%m/%d %H:%M:%S.%f', # Adjusted format based on previous steps\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Handle potential coercion errors (if any)\n",
    "invalid_timestamps = df['TIMESTAMP'].isna().sum()\n",
    "if invalid_timestamps > 0:\n",
    "    print(f\"Warning: {invalid_timestamps} rows had invalid date/time formats and resulted in NaT timestamps.\")\n",
    "\n",
    "# 2) Hour of the day\n",
    "df['HOUR'] = df['TIMESTAMP'].dt.hour\n",
    "\n",
    "# 3) Day\n",
    "df['DAY'] = df['TIMESTAMP'].dt.day\n",
    "\n",
    "# 4) Weekday\n",
    "df['WEEKDAY'] = df['TIMESTAMP'].dt.day_name().str.upper()\n",
    "\n",
    "# 5) Flag weekend (1 = Saturday/Sunday)\n",
    "df['IS_WEEKEND'] = df['WEEKDAY'].isin(['SATURDAY', 'SUNDAY']).astype(int)\n",
    "\n",
    "# 6) Month\n",
    "df['MONTH'] = df['TIMESTAMP'].dt.month\n",
    "\n",
    "# 7) Year\n",
    "df['YEAR'] = df['TIMESTAMP'].dt.year\n",
    "\n",
    "# 8) Season\n",
    "def map_season(month):\n",
    "    if pd.isna(month): return 'UNKNOWN' # Handle potential NaNs from NaT timestamps\n",
    "    if month in [12, 1, 2]: return 'WINTER'\n",
    "    elif month in [3, 4, 5]: return 'SPRING'\n",
    "    elif month in [6, 7, 8]: return 'SUMMER'\n",
    "    else: return 'AUTUMN'\n",
    "df['SEASON'] = df['MONTH'].apply(map_season)\n",
    "\n",
    "# 9) Time Bucket\n",
    "def time_bucket(hour):\n",
    "    if pd.isna(hour): return 'UNKNOWN' # Handle potential NaNs\n",
    "    if hour < 6: return 'NIGHT'\n",
    "    elif hour < 12: return 'MORNING'\n",
    "    elif hour < 18: return 'AFTERNOON'\n",
    "    else: return 'EVENING'\n",
    "df['TIME_BUCKET'] = df['HOUR'].apply(time_bucket)\n",
    "\n",
    "# Drop intermediate and original time columns\n",
    "df = df.drop(columns=['CMPLNT_FR_TM', 'CMPLNT_FR_DT', 'TIMESTAMP'])\n",
    "print(\"Created temporal features: HOUR, DAY, WEEKDAY, IS_WEEKEND, MONTH, YEAR, SEASON, TIME_BUCKET\")\n",
    "print(f\"Columns after adding temporal features: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yz8JIr4zLXfo"
   },
   "source": [
    "## 2.1. Create Holiday and Payday Features\n",
    "\n",
    "Create binary flags for holidays and assumed paydays to capture potential temporal patterns related to these events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8731,
     "status": "ok",
     "timestamp": 1748178745966,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "7zLOtg-xLXfo",
    "outputId": "3f8f7a53-44e5-4df2-fe2b-1512d05ab0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Holiday and Payday Features ===\n",
      "Created IS_HOLIDAY feature. 82010 instances on a holiday.\n",
      "Created IS_PAYDAY feature. 180576 instances on an assumed payday.\n",
      "Columns after adding holiday/payday features: ['BORO_NM', 'KY_CD', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PARKS_NM', 'PD_CD', 'PREM_TYP_DESC', 'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX', 'Latitude', 'Longitude', 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'METRO_DISTANCE', 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE', 'TOTAL_POI_COUNT', 'POI_DIVERSITY', 'POI_DENSITY_SCORE', 'HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Holiday and Payday Features ===\")\n",
    "# Recreate a datetime series from YEAR, MONTH, DAY for holiday and payday checking\n",
    "# Ensure YEAR, MONTH, DAY are present and are not NaN before attempting conversion\n",
    "if 'YEAR' in df.columns and 'MONTH' in df.columns and 'DAY' in df.columns:\n",
    "    # Create a temporary date column, handling potential errors by setting to NaT\n",
    "    # This is crucial if YEAR, MONTH, DAY could form invalid dates (e.g., Feb 30)\n",
    "    # However, pd.to_datetime will handle standard invalid dates by raising errors if not coerced.\n",
    "    # For safety, let's ensure components are integer and handle NaNs that might arise from prior steps.\n",
    "    date_components = df[['YEAR', 'MONTH', 'DAY']].dropna()\n",
    "    df_dates = pd.to_datetime(date_components, errors='coerce')\n",
    "\n",
    "    # Initialize US holidays\n",
    "    us_holidays = holidays.US(years=df_dates.dt.year.unique())\n",
    "\n",
    "    # Create IS_HOLIDAY column\n",
    "    # Apply to the original df index to ensure alignment\n",
    "    df['IS_HOLIDAY'] = 0\n",
    "    df.loc[df_dates.index, 'IS_HOLIDAY'] = df_dates.dt.date.apply(lambda date: 1 if date in us_holidays else 0).astype(int)\n",
    "    print(f\"Created IS_HOLIDAY feature. {df['IS_HOLIDAY'].sum()} instances on a holiday.\")\n",
    "\n",
    "    # Create IS_PAYDAY column (assuming 1st and 15th of the month)\n",
    "    df['IS_PAYDAY'] = 0\n",
    "    df.loc[df_dates.index, 'IS_PAYDAY'] = df_dates.apply(lambda x: 1 if x.day == 1 or x.day == 15 else 0).astype(int)\n",
    "    print(f\"Created IS_PAYDAY feature. {df['IS_PAYDAY'].sum()} instances on an assumed payday.\")\n",
    "else:\n",
    "    print(\"Warning: YEAR, MONTH, or DAY column not found. Skipping IS_HOLIDAY and IS_PAYDAY creation.\")\n",
    "\n",
    "print(f\"Columns after adding holiday/payday features: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSKpGluI1My4"
   },
   "source": [
    "## 3. Refine Location Features\n",
    "\n",
    "Improve location-related features using imputation and rule-based logic:\n",
    "- Impute missing `PREM_TYP_DESC` based on proximity to POIs (Bar, Nightclub, ATM, Metro) and offense type (`OFNS_DESC`).\n",
    "- Group `PARKS_NM` entries into `PREM_TYP_DESC` as 'PARK/PLAYGROUND'.\n",
    "- Impute missing `LOC_OF_OCCUR_DESC` based on `PREM_TYP_DESC` and `OFNS_DESC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lno3XGwD1My4"
   },
   "source": [
    "### 3.1 Impute `PREM_TYP_DESC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3925,
     "status": "ok",
     "timestamp": 1748178749979,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "sicU4WxF1My4",
    "outputId": "afae5e07-85cc-4609-9d87-f43721abbfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Refining Location Features - Impute PREM_TYP_DESC ===\n",
      "Initial missing/placeholder PREM_TYP_DESC: 35590\n",
      "Imputed 2225 PREM_TYP_DESC based on POI proximity (<= 30m).\n",
      "Imputed 12816 PREM_TYP_DESC as 'STREET' based on OFNS_DESC.\n",
      "Filled remaining 20549 missing PREM_TYP_DESC with 'OTHER'.\n",
      "PREM_TYP_DESC missing/placeholders after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Refining Location Features - Impute PREM_TYP_DESC ===\")\n",
    "# 1) Identify rows where PREM_TYP_DESC is missing or placeholder\n",
    "missing_prem_placeholders = ['(NULL)', None, np.nan, 'UNKNOWN'] # Include UNKNOWN from previous cleaning\n",
    "mask_null_prem = df['PREM_TYP_DESC'].isin(missing_prem_placeholders)\n",
    "initial_missing_prem = mask_null_prem.sum()\n",
    "print(f\"Initial missing/placeholder PREM_TYP_DESC: {initial_missing_prem}\")\n",
    "\n",
    "# 2) Compute nearest POI and its distance (helper columns)\n",
    "poi_cols = ['BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE']\n",
    "df['NEAREST_POI_DIST'] = df[poi_cols].min(axis=1)\n",
    "df['NEAREST_POI_TYPE'] = df[poi_cols].idxmin(axis=1)\n",
    "\n",
    "# Mapping from distance column name to PREM_TYP_DESC value\n",
    "distance_to_prem = {\n",
    "    'BAR_DISTANCE': 'BAR/NIGHT CLUB',\n",
    "    'NIGHTCLUB_DISTANCE': 'BAR/NIGHT CLUB',\n",
    "    'ATM_DISTANCE': 'ATM',\n",
    "    'METRO_DISTANCE': 'TRANSIT - NYC SUBWAY'\n",
    "}\n",
    "\n",
    "# 3) Distance-based imputation: only if nearest POI is within 30 meters\n",
    "mask_impute_by_dist = mask_null_prem & (df['NEAREST_POI_DIST'] <= 30)\n",
    "df.loc[mask_impute_by_dist, 'PREM_TYP_DESC'] = df.loc[mask_impute_by_dist, 'NEAREST_POI_TYPE'].map(distance_to_prem)\n",
    "imputed_by_dist_count = mask_impute_by_dist.sum()\n",
    "print(f\"Imputed {imputed_by_dist_count} PREM_TYP_DESC based on POI proximity (<= 30m).\")\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=['NEAREST_POI_DIST', 'NEAREST_POI_TYPE'], inplace=True)\n",
    "\n",
    "# 4) Fallback using OFNS_DESC for street-related crimes\n",
    "mask_still_null_prem = df['PREM_TYP_DESC'].isin(missing_prem_placeholders)\n",
    "street_crime_keywords = ['BURGLARY', 'ROBBERY', 'ASSAULT', 'GRAND LARCENY', 'PETIT LARCENY', 'UNAUTHORIZED USE OF A VEHICLE']\n",
    "mask_impute_by_offense = mask_still_null_prem & df['OFNS_DESC'].str.contains('|'.join(street_crime_keywords), na=False, case=False)\n",
    "df.loc[mask_impute_by_offense, 'PREM_TYP_DESC'] = 'STREET'\n",
    "imputed_by_offense_count = mask_impute_by_offense.sum()\n",
    "print(f\"Imputed {imputed_by_offense_count} PREM_TYP_DESC as 'STREET' based on OFNS_DESC.\")\n",
    "\n",
    "# 5) Final default for any remaining missing values\n",
    "mask_final_null_prem = df['PREM_TYP_DESC'].isin(missing_prem_placeholders)\n",
    "final_default_count = mask_final_null_prem.sum()\n",
    "df.loc[mask_final_null_prem, 'PREM_TYP_DESC'] = 'OTHER'\n",
    "print(f\"Filled remaining {final_default_count} missing PREM_TYP_DESC with 'OTHER'.\")\n",
    "\n",
    "# Final check\n",
    "final_missing_prem = df['PREM_TYP_DESC'].isin(missing_prem_placeholders).sum()\n",
    "print(f\"PREM_TYP_DESC missing/placeholders after imputation: {final_missing_prem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah5Cdf0o1My5"
   },
   "source": [
    "### 3.2 Consolidate Park Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1748178751012,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "IbvIjHx81My5",
    "outputId": "1fcd2dcf-c2c1-4444-da03-b52bab6260f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Refining Location Features - Consolidate Park Info ===\n",
      "Updated 15739 PREM_TYP_DESC entries to 'PARK/PLAYGROUND' based on PARKS_NM.\n",
      "Dropped PARKS_NM column.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Refining Location Features - Consolidate Park Info ===\")\n",
    "# Group PARKS_NM into PREM_TYP_DESC\n",
    "if 'PARKS_NM' in df.columns:\n",
    "    park_mask = df['PARKS_NM'].notna() & (df['PARKS_NM'] != '(NULL)') & (df['PARKS_NM'] != 'UNKNOWN')\n",
    "    park_update_count = park_mask.sum()\n",
    "    df.loc[park_mask, 'PREM_TYP_DESC'] = 'PARK/PLAYGROUND'\n",
    "    print(f\"Updated {park_update_count} PREM_TYP_DESC entries to 'PARK/PLAYGROUND' based on PARKS_NM.\")\n",
    "    # Drop the original PARKS_NM column as it's now consolidated\n",
    "    df.drop(columns=['PARKS_NM'], inplace=True)\n",
    "    print(\"Dropped PARKS_NM column.\")\n",
    "else:\n",
    "    print(\"PARKS_NM column not found, skipping consolidation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gwV91q31My6"
   },
   "source": [
    "### 3.3 Impute `LOC_OF_OCCUR_DESC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2488,
     "status": "ok",
     "timestamp": 1748178753532,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "zn8gKULH1My6",
    "outputId": "4ca0fb87-58d1-44d4-98e7-6a2e78a495c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Refining Location Features - Impute LOC_OF_OCCUR_DESC ===\n",
      "Initial missing/placeholder LOC_OF_OCCUR_DESC: 464374\n",
      "Imputed 378151 LOC_OF_OCCUR_DESC based on PREM_TYP_DESC mapping.\n",
      "Imputed 15240 LOC_OF_OCCUR_DESC as 'INSIDE' based on OFNS_DESC.\n",
      "Filled remaining 70983 missing LOC_OF_OCCUR_DESC with 'UNKNOWN'.\n",
      "LOC_OF_OCCUR_DESC missing/placeholders after imputation: 70983\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Refining Location Features - Impute LOC_OF_OCCUR_DESC ===\")\n",
    "# 1) Identify missing/placeholder values\n",
    "missing_loc_placeholders = ['(NULL)', None, np.nan, 'UNKNOWN']\n",
    "mask_null_loc = df['LOC_OF_OCCUR_DESC'].isin(missing_loc_placeholders)\n",
    "initial_missing_loc = mask_null_loc.sum()\n",
    "print(f\"Initial missing/placeholder LOC_OF_OCCUR_DESC: {initial_missing_loc}\")\n",
    "\n",
    "# 2) Rule-based mapping from PREM_TYP_DESC to LOC_OF_OCCUR_DESC\n",
    "prem_to_loc = {\n",
    "    # indoor locations\n",
    "    'GROCERY/BODEGA':                     'INSIDE',\n",
    "    'RESIDENCE - APT. HOUSE':             'INSIDE',\n",
    "    'RESIDENCE-HOUSE':                    'INSIDE',\n",
    "    'RESIDENCE - PUBLIC HOUSING':         'INSIDE',\n",
    "    'DEPARTMENT STORE':                   'INSIDE',\n",
    "    'CHAIN STORE':                        'INSIDE',\n",
    "    'DRUG STORE':                         'INSIDE',\n",
    "    'FOOD SUPERMARKET':                   'INSIDE',\n",
    "    'COMMERCIAL BUILDING':                'INSIDE',\n",
    "    'BANK':                               'INSIDE',\n",
    "    'PUBLIC BUILDING':                    'INSIDE',\n",
    "    'HOTEL/MOTEL':                        'INSIDE',\n",
    "    'HOMELESS SHELTER':                   'INSIDE',\n",
    "    'PUBLIC SCHOOL':                      'INSIDE',\n",
    "    'PRIVATE/PAROCHIAL SCHOOL':           'INSIDE',\n",
    "    'COLLEGE/UNIVERSITY':                 'INSIDE',\n",
    "    'HOSPITAL':                           'INSIDE',\n",
    "    'DOCTOR/DENTIST OFFICE':              'INSIDE',\n",
    "    'GYM/FITNESS FACILITY':               'INSIDE',\n",
    "    'BAR/NIGHT CLUB':                     'INSIDE',\n",
    "    'RESTAURANT/DINER':                   'INSIDE',\n",
    "    'FAST FOOD':                          'INSIDE',\n",
    "    'DRY CLEANER/LAUNDRY':                'INSIDE',\n",
    "    'BEAUTY & NAIL SALON':                'INSIDE',\n",
    "    'CLOTHING/BOUTIQUE':                  'INSIDE',\n",
    "    'JEWELRY':                            'INSIDE',\n",
    "    'PHOTO/COPY':                         'INSIDE',\n",
    "    'VIDEO STORE':                        'INSIDE',\n",
    "    'STORE UNCLASSIFIED':                 'INSIDE',\n",
    "    'SMALL MERCHANT':                     'INSIDE',\n",
    "    'CANDY STORE':                        'INSIDE',\n",
    "    'VARIETY STORE':                      'INSIDE',\n",
    "    'SHOE':                               'INSIDE',\n",
    "    'CHECK CASHING BUSINESS':             'INSIDE',\n",
    "    'STORAGE FACILITY':                   'INSIDE',\n",
    "    'REAL ESTATE':                        'INSIDE',\n",
    "    'SOCIAL CLUB/POLICY':                 'INSIDE',\n",
    "    'OTHER HOUSE OF WORSHIP':             'INSIDE',\n",
    "    'CHURCH':                             'INSIDE',\n",
    "    'SYNAGOGUE':                          'INSIDE',\n",
    "    'MOSQUE':                             'INSIDE',\n",
    "    'DAYCARE FACILITY':                   'INSIDE',\n",
    "    'ABANDONED BUILDING':                 'INSIDE',\n",
    "    'LOAN COMPANY':                       'INSIDE',\n",
    "    'TAXI (YELLOW LICENSED)':             'INSIDE',\n",
    "    'TAXI (LIVERY LICENSED)':             'INSIDE',\n",
    "    'TAXI/LIVERY (UNLICENSED)':           'INSIDE',\n",
    "    'BUS (NYC TRANSIT)':                  'INSIDE',\n",
    "    'BUS (OTHER)':                        'INSIDE',\n",
    "    'TRANSIT FACILITY (OTHER)':           'INSIDE',\n",
    "    'AIRPORT TERMINAL':                   'INSIDE',\n",
    "    'FERRY/FERRY TERMINAL':               'INSIDE',\n",
    "\n",
    "    # outdoor or semi‐outdoor locations\n",
    "    'STREET':                             'REAR',\n",
    "    'HIGHWAY/PARKWAY':                    'REAR',\n",
    "    'TUNNEL':                             'REAR',\n",
    "    'PARK/PLAYGROUND':                    'REAR',\n",
    "    'OPEN AREAS (OPEN LOTS)':             'REAR',\n",
    "    'PARKING LOT/GARAGE (PUBLIC)':        'REAR',\n",
    "    'PARKING LOT/GARAGE (PRIVATE)':       'REAR',\n",
    "    'GAS STATION':                        'REAR',\n",
    "    'ATM':                                'REAR',\n",
    "    'BUS STOP':                           'REAR',\n",
    "    'BUS TERMINAL':                       'REAR',\n",
    "    'TRAMWAY':                            'REAR',\n",
    "    'BRIDGE':                             'REAR',\n",
    "    'MARINA/PIER':                        'REAR',\n",
    "    'CEMETERY':                           'REAR',\n",
    "    'CONSTRUCTION SITE':                  'REAR',\n",
    "    'MOBILE FOOD':                        'REAR',\n",
    "    'FERRY/FERRY TERMINAL':               'REAR',  # also treated as terminal interior above\n",
    "\n",
    "    # catch-all for others\n",
    "    'OTHER':                              'UNKNOWN',\n",
    "    'STORE UNCLASSIFIED':                 'UNKNOWN',\n",
    "    'TRANSIT - NYC SUBWAY':               'UNKNOWN' # Can be inside station, on platform, or on train\n",
    "}\n",
    "\n",
    "# Apply the mapping to fill missing LOC_OF_OCCUR_DESC\n",
    "df.loc[mask_null_loc, 'LOC_OF_OCCUR_DESC'] = df.loc[mask_null_loc, 'PREM_TYP_DESC'].map(prem_to_loc)\n",
    "imputed_by_prem_count = mask_null_loc.sum() - df['LOC_OF_OCCUR_DESC'].isin(missing_loc_placeholders).sum()\n",
    "print(f\"Imputed {imputed_by_prem_count} LOC_OF_OCCUR_DESC based on PREM_TYP_DESC mapping.\")\n",
    "\n",
    "# 3) Refinement using OFNS_DESC for potential inside crimes\n",
    "mask_still_null_loc = df['LOC_OF_OCCUR_DESC'].isin(missing_loc_placeholders)\n",
    "inside_crime_keywords = ['BURGLARY', 'TRESPASS', 'ROBBERY', 'ASSAULT'] # Keywords suggesting inside location\n",
    "mask_impute_by_offense_loc = mask_still_null_loc & df['OFNS_DESC'].str.contains('|'.join(inside_crime_keywords), na=False, case=False)\n",
    "df.loc[mask_impute_by_offense_loc, 'LOC_OF_OCCUR_DESC'] = 'INSIDE'\n",
    "imputed_by_offense_loc_count = mask_impute_by_offense_loc.sum()\n",
    "print(f\"Imputed {imputed_by_offense_loc_count} LOC_OF_OCCUR_DESC as 'INSIDE' based on OFNS_DESC.\")\n",
    "\n",
    "# 4) Final default for any remaining missing values\n",
    "mask_final_null_loc = df['LOC_OF_OCCUR_DESC'].isin(missing_loc_placeholders)\n",
    "final_default_loc_count = mask_final_null_loc.sum()\n",
    "df.loc[mask_final_null_loc, 'LOC_OF_OCCUR_DESC'] = 'UNKNOWN'\n",
    "print(f\"Filled remaining {final_default_loc_count} missing LOC_OF_OCCUR_DESC with 'UNKNOWN'.\")\n",
    "\n",
    "# Final check\n",
    "final_missing_loc = df['LOC_OF_OCCUR_DESC'].isin(missing_loc_placeholders).sum()\n",
    "print(f\"LOC_OF_OCCUR_DESC missing/placeholders after imputation: {final_missing_loc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPL1WSeHfQ70"
   },
   "source": [
    "## 5. Create Demographic Interaction Features\n",
    "\n",
    "Generate features indicating whether the suspect and victim share the same demographic characteristics:\n",
    "- `SAME_AGE_GROUP`: 1 if suspect and victim age groups match, 0 otherwise.\n",
    "- `SAME_SEX`: 1 if suspect and victim sexes match, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1748178754397,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "KGyrhN7V1My8",
    "outputId": "3677c43c-2f94-4ca2-a3e0-bf712db9f6f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: Demographic Interaction Features ===\n",
      "Created SAME_AGE_GROUP feature. 388596 instances where age groups match.\n",
      "Created SAME_SEX feature. 515461 instances where sexes match.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: Demographic Interaction Features ===\")\n",
    "# 1) SAME_AGE_GROUP: 1 if suspect and victim share the same age group, else 0\n",
    "df['SAME_AGE_GROUP'] = 0\n",
    "# Define valid (non-null, non-placeholder) age-group rows\n",
    "valid_age_placeholders = ['UNKNOWN', '(NULL)', None, np.nan]\n",
    "age_valid = (~df['SUSP_AGE_GROUP'].isin(valid_age_placeholders)) & (~df['VIC_AGE_GROUP'].isin(valid_age_placeholders))\n",
    "# Set flag where age groups match\n",
    "df.loc[age_valid & (df['SUSP_AGE_GROUP'] == df['VIC_AGE_GROUP']), 'SAME_AGE_GROUP'] = 1\n",
    "print(f\"Created SAME_AGE_GROUP feature. {df['SAME_AGE_GROUP'].sum()} instances where age groups match.\")\n",
    "\n",
    "# 2) SAME_SEX: 1 if suspect and victim have the same sex, else 0\n",
    "df['SAME_SEX'] = 0\n",
    "# Define valid (non-null, non-placeholder) sex rows\n",
    "valid_sex_placeholders = ['U', 'UNKNOWN', '(NULL)', None, np.nan] # 'U' often means Unknown\n",
    "sex_valid = (~df['SUSP_SEX'].isin(valid_sex_placeholders)) & (~df['VIC_SEX'].isin(valid_sex_placeholders))\n",
    "# Set flag where sexes match\n",
    "df.loc[sex_valid & (df['SUSP_SEX'] == df['VIC_SEX']), 'SAME_SEX'] = 1\n",
    "print(f\"Created SAME_SEX feature. {df['SAME_SEX'].sum()} instances where sexes match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1748178754492,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "TrrxSdbY1My9",
    "outputId": "cb162e4c-4676-4523-e53d-c4b6a4396831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Engineering: TO_CHECK_CITIZENS Feature ===\n",
      "Created TO_CHECK_CITIZENS feature. 2270901 instances flagged.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Feature Engineering: TO_CHECK_CITIZENS Feature ===\")\n",
    "# List of offense descriptions that trigger the flag\n",
    "to_check_citizens_list = [\n",
    "    'CRIMINAL TRESPASS', 'CRIMINAL MISCHIEF & RELATED OF', 'HARRASSMENT 2',\n",
    "    'GRAND LARCENY OF MOTOR VEHICLE', 'PETIT LARCENY', 'GRAND LARCENY',\n",
    "    'INTOXICATED & IMPAIRED DRIVING', 'FRAUDS', 'THEFT-FRAUD',\n",
    "    'OFF. AGNST PUB ORD SENSBLTY &', 'BURGLARY', 'ROBBERY', 'FELONY ASSAULT',\n",
    "    'ASSAULT 3 & RELATED OFFENSES', 'DANGEROUS DRUGS', 'RAPE', 'SEX CRIMES',\n",
    "    'DANGEROUS WEAPONS', 'ARSON', 'POSSESSION OF STOLEN PROPERTY',\n",
    "    'UNAUTHORIZED USE OF A VEHICLE', 'FORGERY', 'ENDAN WELFARE INCOMP',\n",
    "    'OTHER OFFENSES RELATED TO THEF', 'AGRICULTURE & MRKTS LAW-UNCLASSIFIED',\n",
    "    'KIDNAPPING & RELATED OFFENSES', 'OTHER OFFENSES RELATED TO THEFT', # Duplicate, keep one\n",
    "    'OFFENSES RELATED TO CHILDREN', 'BURGLAR\\S TOOLS', 'ESCAPE 3',\n",
    "    'CANNABIS RELATED OFFENSES', 'PETIT LARCENY OF MOTOR VEHICLE',\n",
    "    'FELONY SEX CRIMES', 'PROSTITUTION & RELATED OFFENSES', 'JOSTLING',\n",
    "    'KIDNAPPING', 'DISORDERLY CONDUCT', 'INTOXICATED/IMPAIRED DRIVING',\n",
    "    'DISRUPTION OF A RELIGIOUS SERV', 'FRAUDULENT ACCOSTING', 'THEFT OF SERVICES',\n",
    "    'UNRSNBLE NOISE', 'OTHER TRAFFIC INFRACTION', 'LOITERING/GAMBLING (CARDS, DIC',\n",
    "    'UNLAWFUL POSS. WEAP. ON SCHOOL', 'FORTUNE TELLING', 'LOITERING',\n",
    "    'FAIL RPT WOUNDS'\n",
    "]\n",
    "# Remove duplicates from the list\n",
    "to_check_citizens_list = list(dict.fromkeys(to_check_citizens_list))\n",
    "\n",
    "# Create the boolean column based on the condition\n",
    "df['TO_CHECK_CITIZENS'] = df['OFNS_DESC'].isin(to_check_citizens_list).astype(int)\n",
    "print(f\"Created TO_CHECK_CITIZENS feature. {df['TO_CHECK_CITIZENS'].sum()} instances flagged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1748178770730,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "oG9DLJLtkwgk",
    "outputId": "e1b96931-030e-4c94-a1e0-9060a135d9df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dropping Rows with NaN values ===\n",
      "Initial number of rows: 2496759\n",
      "Number of rows after dropping NaNs: 2496742\n",
      "Number of rows dropped: 17\n",
      "Current DataFrame shape: (2496742, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Dropping Rows with NaN values ===\")\n",
    "initial_rows = len(df)\n",
    "print(f\"Initial number of rows: {initial_rows}\")\n",
    "\n",
    "# Drop rows that contain any NaN value\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "final_rows = len(df_cleaned)\n",
    "rows_dropped = initial_rows - final_rows\n",
    "\n",
    "print(f\"Number of rows after dropping NaNs: {final_rows}\")\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "\n",
    "# Update the main DataFrame reference to the cleaned one\n",
    "df = df_cleaned\n",
    "\n",
    "print(f\"Current DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65943,
     "status": "ok",
     "timestamp": 1748179011283,
     "user": {
      "displayName": "Ferdinando Muraca",
      "userId": "08570199584316918220"
     },
     "user_tz": -120
    },
    "id": "Bg9rAWr8lXox",
    "outputId": "d7e787a6-a618-496e-f0f1-8dac1bbfe3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Saving Feature Engineered Dataset (Before Scaling/PCA) ===\n",
      "Feature engineered dataset (before scaling/PCA) saved successfully to: C:\\Users\\ferdi\\Documents\\GitHub\\crime-analyzer\\JupyterOutputs\\FeatureEngineered\\feature_engineered_crime_data.csv\n",
      "Dataset shape: (2496742, 44)\n",
      "Columns in the dataset: ['BORO_NM', 'KY_CD', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PD_CD', 'PREM_TYP_DESC', 'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX', 'Latitude', 'Longitude', 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'METRO_DISTANCE', 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE', 'TOTAL_POI_COUNT', 'POI_DIVERSITY', 'POI_DENSITY_SCORE', 'HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY', 'SAME_AGE_GROUP', 'SAME_SEX', 'TO_CHECK_CITIZENS']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Saving Feature Engineered Dataset (Before Scaling/PCA) ===\")\n",
    "# Ensure feature_engineering_dir and feature_engineered_file_path are defined\n",
    "\n",
    "if 'df' in globals() and 'feature_engineered_file_path' in globals() and 'os' in globals():\n",
    "    try:\n",
    "        df.to_csv(feature_engineered_file_path, index=False)\n",
    "        print(f\"Feature engineered dataset (before scaling/PCA) saved successfully to: {feature_engineered_file_path}\")\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Columns in the dataset: {df.columns.tolist()}\")\n",
    "    except NameError as ne:\n",
    "        print(f\"A NameError occurred while trying to save: {ne}. Ensure 'df' and path variables are correctly defined.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving feature engineered dataset (before scaling/PCA): {e}\")\n",
    "else:\n",
    "    print(\"Error: 'df' or 'feature_engineered_file_path' or 'os' not found in globals. Cannot save the intermediate DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGk4xFeu1MzA"
   },
   "source": [
    "## Appendix: Feature Classification and Encoding\n",
    "\n",
    "### Attribute Type Classification\n",
    "\n",
    "Below is a classification of each column in the final feature-engineered dataset according to its data type and semantic meaning, *before* encoding and transformation. This helps guide the next steps in the Data Reduction and Transformation phase.\n",
    "\n",
    "| Column                | Data Type                     | Details/Notes                                  | Transformation Needed | Encoding Type (if needed) |\n",
    "|-----------------------|-------------------------------|------------------------------------------------|-----------------------|---------------------------|\n",
    "| BORO_NM               | Categorical (nominal)         | Borough name                                   | Encoding              | One-Hot               |         |\n",
    "| KY_CD            | Categorical (nominal)         | Crime classification code | Encoding              | One-Hot                   |       |\n",
    "| LAW_CAT_CD            | Categorical (ordinal)         | Crime level (FELONY > MISDEMEANOR > VIOLATION) | Encoding              | Ordinal                   |       |\n",
    "| LOC_OF_OCCUR_DESC     | Categorical (nominal)         | Location description (INSIDE, FRONT, etc.)     | Encoding              | One-Hot                   |\n",
    "| OFNS_DESC             | Categorical (nominal)         | Offense description                            | Encoding              | One-Hot (High Cardinality)|\n",
    "| PD_CD                 | Categorical (nominal)         | Detailed police code                           | Encoding              | One-Hot (High Cardinality)|\n",
    "| PREM_TYP_DESC         | Categorical (nominal)         | Premises type description                      | Encoding              | One-Hot (High Cardinality)|\n",
    "| SUSP_AGE_GROUP        | Categorical (ordinal)         | Age group (e.g., '<18', '18-24', 'UNKNOWN')    | Encoding              | Ordinal                   |\n",
    "| SUSP_RACE             | Categorical (nominal)         | Suspect race                                   | Encoding              | One-Hot                   |\n",
    "| SUSP_SEX              | Categorical (nominal)         | Suspect sex (M/F/U)                            | Encoding              | One-Hot                   |\n",
    "| VIC_AGE_GROUP         | Categorical (ordinal)         | Age group (e.g., '<18', '18-24', 'UNKNOWN')    | Encoding              | Ordinal                   |\n",
    "| VIC_RACE              | Categorical (nominal)         | Victim race                                    | Encoding              | One-Hot                   |\n",
    "| VIC_SEX               | Categorical (nominal)         | Victim sex (M/F/D/E/U)                         | Encoding              | One-Hot                   |\n",
    "| LATITUDE              | Numeric (continuous)          | Geographic coordinate                          | Scaling               | -                         |\n",
    "| LONGITUDE             | Numeric (continuous)          | Geographic coordinate                          | Scaling               | -                         |\n",
    "| BAR_DISTANCE          | Numeric (continuous)          | Distance to nearest bar (meters)               | Scaling               | -                         |\n",
    "| NIGHTCLUB_DISTANCE    | Numeric (continuous)          | Distance to nearest nightclub (meters)         | Scaling               | -                         |\n",
    "| ATM_DISTANCE          | Numeric (continuous)          | Distance to nearest ATM (meters)               | Scaling               | -                         |\n",
    "| METRO_DISTANCE        | Numeric (continuous)          | Distance to nearest metro station (meters)     | Scaling               | -                         |\n",
    "| ATMS_COUNT            | Numeric (discrete)            | Count of ATMs nearby                           | Scaling               | -                         |\n",
    "| BARS_COUNT            | Numeric (discrete)            | Count of bars nearby                           | Scaling               | -                         |\n",
    "| BUS_STOPS_COUNT       | Numeric (discrete)            | Count of bus stops nearby                      | Scaling               | -                         |\n",
    "| METROS_COUNT | Numeric (discrete)            | Count of metro stations nearby                 | Scaling               | -                         |\n",
    "| NIGHTCLUBS_COUNT      | Numeric (discrete)            | Count of nightclubs nearby                     | Scaling               | -                         |\n",
    "| SCHOOLS_COUNT         | Numeric (discrete)            | Count of schools nearby                        | Scaling               | -                         |\n",
    "| HOUR                  | Numeric (cyclical)            | Hour of the day (0-23)                         | Encoding              | Cyclical (Sine/Cosine)    |\n",
    "| DAY                   | Numeric (cyclical)            | Day of the month (1-31)                        | Encoding              | Cyclical (Sine/Cosine)    |\n",
    "| WEEKDAY               | Categorical (cyclical)        | Day of the week (MON-SUN)                      | Encoding              | Cyclical (Sine/Cosine)    |\n",
    "| IS_WEEKEND            | Binary                        | 0 = weekday, 1 = weekend                       | None                  | -                         |\n",
    "| MONTH                 | Numeric (cyclical)            | Month of the year (1-12)                       | Encoding              | Cyclical (Sine/Cosine)    |\n",
    "| SEASON                | Categorical (nominal)         | Season (WINTER, SPRING, SUMMER, AUTUMN)        | Encoding              | One-Hot                   |\n",
    "| TIME_BUCKET           | Categorical (nominal)         | Time of day (NIGHT, MORNING, AFTERNOON, EVENING) | Encoding              | One-Hot                   |\n",
    "| YEAR                  | Numeric (discrete)            | Year of the event                              | Scaling               | -                         |\n",
    "| IS_HOLIDAY            | Binary                        | 0 = not a holiday, 1 = holiday                 | None                  | -                         |\n",
    "| IS_PAYDAY             | Binary                        | 0 = not a payday, 1 = payday (1st or 15th)     | None                  | -                         |\n",
    "| SAME_AGE_GROUP        | Binary                        | 1 if suspect/victim age groups match, else 0   | None                  | -                         |\n",
    "| SAME_SEX              | Binary                        | 1 if suspect/victim sexes match, else 0        | None                  | -                         |\n",
    "| TO_CHECK_CITIZENS     | Binary                        | 1 if offense is relevant for citizens, else 0 | None                  | -                         |\n",
    "| TOTAL_POI_COUNT       | Numeric (discrete)            | Sum of all POI counts  | Scaling               | -                         |\n",
    "| POI_DIVERSITY         | Numeric (discrete)            | Number of different POI types present          | Scaling               | -                         |\n",
    "| POI_DENSITY_SCORE      | Numeric (continuous)           | Density score                           | Scaling                  | -                             |\n",
    "| MIN_POI_DISTANCE      | Numeric (continuous)          | Distance to closest POI of any type            | Scaling               | -                         |\n",
    "| AVG_POI_DISTANCE      | Numeric (continuous)          | Average distance to POIs                       | Scaling               | -                         |\n",
    "| MAX_POI_DISTANCE       | Numeric (continuous)           | Maximum distance to POIs                       | Scaling                  | -                             |\n",
    "\n",
    "### Reasons for Cyclical/Ordinal Encoding\n",
    "\n",
    "Cyclical and Ordinal encoding are valuable techniques for representing categorical features while preserving inherent relationships and limiting dimensionality increase compared to One-Hot encoding.\n",
    "- **Cyclical Encoding:** This is particularly useful for features where the end of the sequence connects back to the beginning, such as time-related attributes (`HOUR`, `DAY`, `WEEKDAY`, `MONTH`). For example, hour 23 is conceptually close to hour 0, December is close to January. Cyclical encoding (often using sine and cosine transformations) captures this wrap-around nature, preventing the model from incorrectly interpreting these values as distant.\n",
    "- **Ordinal Encoding:** This method is suitable for features with a clear, inherent order or ranking (`LAW_CAT_CD`, `SUSP_AGE_GROUP`, `VIC_AGE_GROUP`). Assigning sequential integers (e.g., 0, 1, 2...) allows the model to understand the relative magnitude or progression between categories (e.g., 'FELONY' > 'MISDEMEANOR', '<18' < '18-24').\n",
    "\n",
    "### Reasons for One-Hot Encoding\n",
    "\n",
    "One-Hot encoding is applied to nominal categorical features where there is no inherent order or ranking among the categories (`BORO_NM`, `KY_CD`, `LOC_OF_OCCUR_DESC`, `OFNS_DESC`, `PD_CD`, `PREM_TYP_DESC`, `SUSP_RACE`, `SUSP_SEX`, `VIC_RACE`, `VIC_SEX`, `SEASON`, `TIME_BUCKET`). It creates new binary (0 or 1) columns for each unique category in the original feature. This prevents the model from assuming any ordinal relationship between categories that doesn't exist. While it can significantly increase the number of features (especially for high-cardinality columns like `OFNS_DESC`), it ensures that each category is treated independently.\n",
    "\n",
    "### Reasons for Scaling\n",
    "\n",
    "Scaling is essential for numeric features (`Latitude`, `Longitude`, distance columns, count columns, `YEAR`) that have different ranges or units. Many machine learning algorithms (especially those based on distance calculations like k-NN or SVM, or those using gradient descent like linear regression and neural networks) are sensitive to the scale of input features. Features with larger values might disproportionately influence the model's learning process. Scaling methods like Standardization (Z-score normalization) or Min-Max scaling transform the data to a common scale (e.g., mean 0 and standard deviation 1, or range [0, 1]), ensuring that all features contribute more equally to the model's outcome."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
