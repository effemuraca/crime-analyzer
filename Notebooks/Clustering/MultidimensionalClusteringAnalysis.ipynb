{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf931be",
   "metadata": {},
   "source": [
    "# Multidimensional Clustering Analysis\n",
    "\n",
    "Purpose\n",
    "- Discover meaningful crime patterns from categorical and mixed features.\n",
    "- Compare three unsupervised methods: K-Modes, Categorical Dimensionality Reduction + KMeans, and Spectral Clustering.\n",
    "- Produce concise artifacts for analysis and operational intelligence.\n",
    "\n",
    "Inputs\n",
    "- DataFrame `base_df` prepared from project data (see preprocessing cells):\n",
    "  - Temporal, spatial context, social, count/score feature groups (configured via lists like `TEMPORAL_FEATURES`, `SPATIAL_CONTEXT_FEATURES`, etc.).\n",
    "  - Optional binned context features via `ColumnBinner` with `binner_config`.\n",
    "- Hyperparameter grids:\n",
    "  - `kmodes_param_grid`, `cat_dimred_param_grid`, `spectral_param_grid`.\n",
    "- Reproducibility settings: `RANDOM_STATE`, sampling flags (`USE_FULL_DATA`, `N_SAMPLE`).\n",
    "\n",
    "Outputs\n",
    "- Model comparison (JSON): `JupyterOutputs/Clustering (MultidimensionalClusteringAnalysis)/pipeline_methods_comparison.json`.\n",
    "- Executive summary (JSON): `JupyterOutputs/Clustering (MultidimensionalClusteringAnalysis)/executive_crime_summary.json`.\n",
    "- Optional enriched artifacts (if enabled downstream):\n",
    "  - `.../executive_crime_summary_enriched.json`\n",
    "  - `.../police_operational_intelligence_enriched.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63940ca4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Setup\n",
    "\n",
    "This section handles the initial setup, including importing necessary libraries, defining file paths, and configuring the environment for clustering analysis. Custom transformers for spatial feature engineering are imported from our utilities module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d04a1",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import all libraries required for data manipulation, clustering algorithms, and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bacb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core data manipulation and computation\n",
    "import pandas as pd, json, os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from statistics import mean\n",
    "\n",
    "# Machine learning and clustering\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# custom transformers\n",
    "from Utilities.clustering_transformers import (\n",
    "    CategoricalPreprocessor,\n",
    "    ColumnBinner,\n",
    "    CategoricalDimensionalityReducer,\n",
    "    GroupBalancedOneHotEncoder\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from collections.abc import Mapping\n",
    "from itertools import product\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce085c0",
   "metadata": {},
   "source": [
    "## Configure Paths and Custom Utilities\n",
    "\n",
    "Set up file paths and import custom clustering utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb3d40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\n",
      "Data directory: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\Data\n",
      "Output directory: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n"
     ]
    }
   ],
   "source": [
    "# Configure working directory and paths\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '../..'))\n",
    "data_dir = os.path.join(project_root, 'Data')\n",
    "output_dir = os.path.join(project_root, 'JupyterOutputs', 'Clustering (MultidimensionalClusteringAnalysis)')\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Add utilities to Python path\n",
    "utilities_path = os.path.join(os.getcwd(), 'Utilities')\n",
    "if utilities_path not in sys.path:\n",
    "    sys.path.append(utilities_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d4450",
   "metadata": {},
   "source": [
    "## Configure Analysis Parameters\n",
    "\n",
    "Define key parameters for the clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00eda05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis parameters configured successfully!\n",
      "Primary spatial features: ['Latitude', 'Longitude']\n",
      "Primary temporal features: ['HOUR', 'WEEKDAY', 'MONTH']\n",
      "Primary categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
      "Available spatial context features: 16 POI-based features\n",
      "Available extended temporal features: 10 temporal features\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Feature columns for spatial analysis (aligned with actual dataset)\n",
    "SPATIAL_FEATURES = ['Latitude', 'Longitude']\n",
    "\n",
    "# Primary temporal features for clustering\n",
    "TEMPORAL_FEATURES = ['HOUR', 'WEEKDAY', 'MONTH']\n",
    "\n",
    "# Extended temporal features available in dataset\n",
    "EXTENDED_TEMPORAL_FEATURES = [\n",
    "    'HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', \n",
    "    'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY'\n",
    "]\n",
    "\n",
    "# Categorical features\n",
    "CATEGORICAL_FEATURES = ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
    "\n",
    "# Extended categorical features available\n",
    "EXTENDED_CATEGORICAL_FEATURES = [\n",
    "    'BORO_NM', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PREM_TYP_DESC',\n",
    "    'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX'\n",
    "]\n",
    "\n",
    "# Spatial context features (POI-based features for enhanced spatial analysis)\n",
    "SPATIAL_CONTEXT_FEATURES = [\n",
    "    'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE',\n",
    "    'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE',\n",
    "    'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', \n",
    "    'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'TOTAL_POI_COUNT',\n",
    "    'POI_DIVERSITY', 'POI_DENSITY_SCORE'\n",
    "]\n",
    "\n",
    "# Social features \n",
    "SOCIAL_FEATURES = ['SAME_AGE_GROUP', 'SAME_SEX']\n",
    "\n",
    "print(\"Analysis parameters configured successfully!\")\n",
    "print(f\"Primary spatial features: {SPATIAL_FEATURES}\")\n",
    "print(f\"Primary temporal features: {TEMPORAL_FEATURES}\")\n",
    "print(f\"Primary categorical features: {CATEGORICAL_FEATURES}\")\n",
    "print(f\"Available spatial context features: {len(SPATIAL_CONTEXT_FEATURES)} POI-based features\")\n",
    "print(f\"Available extended temporal features: {len(EXTENDED_TEMPORAL_FEATURES)} temporal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40acbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Loading & Feature Preparation\n",
    "\n",
    "This section loads the preprocessed crime dataset and prepares features specifically for clustering analysis. We validate coordinate accuracy, assess feature completeness, and prepare the data for various clustering algorithms.\n",
    "\n",
    "## Load Preprocessed Crime Dataset\n",
    "\n",
    "Load and validate the preprocessed crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2d3684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\Data\\final_crime_data.csv\n",
      "Dataset loaded successfully.\n",
      "Shape: (2493835, 44)\n",
      "Memory usage: 2453.35 MB\n",
      "\n",
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "Total records: 2,493,835\n",
      "Total features: 44\n"
     ]
    }
   ],
   "source": [
    "# Define data file path\n",
    "data_file = os.path.join(data_dir, 'final_crime_data.csv')\n",
    "\n",
    "# Check if data file exists\n",
    "if not os.path.exists(data_file):\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_file}\")\n",
    "\n",
    "print(f\"Loading data from: {data_file}\")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Display basic dataset information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985352a",
   "metadata": {},
   "source": [
    "## Data Cleaning and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4cb832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE VALIDATION\n",
      "============================================================\n",
      "Feature availability:\n",
      "------------------------------\n",
      "Spatial features: ['Latitude', 'Longitude'] (2/2)\n",
      "Temporal features: ['HOUR', 'WEEKDAY', 'MONTH'] (3/3)\n",
      "Categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC'] (3/3)\n",
      "\n",
      "============================================================\n",
      "TEMPORAL FILTERING FOR CLUSTERING\n",
      "============================================================\n",
      "Original dataset years: [np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Total records before temporal filter: 2,493,835\n",
      "Year-Month distribution in original dataset:\n",
      "  202001: 38,695 records\n",
      "  202002: 35,446 records\n",
      "  202003: 32,679 records\n",
      "  202004: 24,907 records\n",
      "  202005: 32,023 records\n",
      "  202006: 32,604 records\n",
      "  202007: 35,531 records\n",
      "  202008: 37,524 records\n",
      "  202009: 35,983 records\n",
      "  202010: 37,403 records\n",
      "  202011: 35,148 records\n",
      "  202012: 33,516 records\n",
      "  202101: 33,217 records\n",
      "  202102: 28,332 records\n",
      "  202103: 34,612 records\n",
      "  202104: 32,619 records\n",
      "  202105: 36,711 records\n",
      "  202106: 37,516 records\n",
      "  202107: 39,402 records\n",
      "  202108: 38,945 records\n",
      "  202109: 39,906 records\n",
      "  202110: 42,994 records\n",
      "  202111: 41,346 records\n",
      "  202112: 40,867 records\n",
      "  202201: 38,353 records\n",
      "  202202: 37,375 records\n",
      "  202203: 43,490 records\n",
      "  202204: 42,508 records\n",
      "  202205: 45,910 records\n",
      "  202206: 47,001 records\n",
      "  202207: 47,372 records\n",
      "  202208: 46,725 records\n",
      "  202209: 45,251 records\n",
      "  202210: 46,394 records\n",
      "  202211: 44,264 records\n",
      "  202212: 42,026 records\n",
      "  202301: 44,708 records\n",
      "  202302: 39,552 records\n",
      "  202303: 44,804 records\n",
      "  202304: 43,964 records\n",
      "  202305: 48,408 records\n",
      "  202306: 47,341 records\n",
      "  202307: 48,413 records\n",
      "  202308: 48,049 records\n",
      "  202309: 45,104 records\n",
      "  202310: 48,281 records\n",
      "  202311: 44,798 records\n",
      "  202312: 44,998 records\n",
      "  202401: 45,803 records\n",
      "  202402: 43,186 records\n",
      "  202403: 45,948 records\n",
      "  202404: 45,040 records\n",
      "  202405: 49,493 records\n",
      "  202406: 49,021 records\n",
      "  202407: 49,961 records\n",
      "  202408: 49,280 records\n",
      "  202409: 47,853 records\n",
      "  202410: 49,267 records\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "\n",
      "Filtering for clustering analysis with period:\n",
      "Using YearMonth >= 202411\n",
      "Records after temporal filter: 85,968 (3.4% of original)\n",
      "Filtered dataset year-months:\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "\n",
      "Using filtered dataset for clustering analysis.\n",
      "\n",
      "Preparing dataset for spatial clustering...\n",
      "Records with valid coordinates: 85,968 (100.00%)\n",
      "Records within NYC bounds: 85,968\n",
      "\n",
      "Final dataset for clustering:\n",
      "Shape: (85968, 44)\n",
      "Coordinate coverage: 85,968 records\n",
      "Time range: 2024 - 2024\n",
      "Memory usage: 85.29 MB\n",
      "\n",
      "Extended features availability:\n",
      "----------------------------------------\n",
      "Spatial context features: 16/16 available\n",
      "  Available: ['BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE', 'MIN_POI_DISTANCE']...\n",
      "Extended temporal features: 10/10 available\n",
      "  Available: ['HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY']\n",
      "Extended categorical features: 11/11 available\n",
      "  Available: ['BORO_NM', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PREM_TYP_DESC']...\n",
      "Social features: 2/2 available\n",
      "  Available: ['SAME_AGE_GROUP', 'SAME_SEX']\n",
      "\n",
      "Temporal distribution in filtered dataset:\n",
      "----------------------------------------\n",
      "  2024: 85,968 records\n",
      "\n",
      "Monthly distribution for 2024:\n",
      "----------------------------------------\n",
      "  Month 11: 45,568 records\n",
      "  Month 12: 40,400 records\n",
      "\n",
      "============================================================\n",
      "CLUSTERING DATASET SUMMARY\n",
      "============================================================\n",
      "Dataset period: Nov 2024 onwards\n",
      "Total records for clustering: 85,968\n",
      "Geographic validity: NYC coordinate bounds enforced\n"
     ]
    }
   ],
   "source": [
    "# Validate feature availability\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check spatial features\n",
    "spatial_available = [col for col in SPATIAL_FEATURES if col in df.columns]\n",
    "temporal_available = [col for col in TEMPORAL_FEATURES if col in df.columns]\n",
    "categorical_available = [col for col in CATEGORICAL_FEATURES if col in df.columns]\n",
    "\n",
    "print(\"Feature availability:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Spatial features: {spatial_available} ({len(spatial_available)}/{len(SPATIAL_FEATURES)})\")\n",
    "print(f\"Temporal features: {temporal_available} ({len(temporal_available)}/{len(TEMPORAL_FEATURES)})\")\n",
    "print(f\"Categorical features: {categorical_available} ({len(categorical_available)}/{len(CATEGORICAL_FEATURES)})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TEMPORAL FILTERING FOR CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'YEAR' in df.columns and 'MONTH' in df.columns:\n",
    "    print(f\"Original dataset years: {sorted(df['YEAR'].unique())}\")\n",
    "    print(f\"Total records before temporal filter: {len(df):,}\")\n",
    "    \n",
    "    # Create YearMonth for filtering\n",
    "    df['YearMonth'] = df['YEAR'] * 100 + df['MONTH']\n",
    "    print(f\"Year-Month distribution in original dataset:\")\n",
    "    ym_counts = df['YearMonth'].value_counts().sort_index()\n",
    "    for ym, count in ym_counts.items():\n",
    "        print(f\"  {ym}: {count:,} records\")\n",
    "\n",
    "    # Use the temporal split point for 2024\n",
    "    test_set_start_ym = 202411  # November 2024\n",
    "    print(f\"\\nFiltering for clustering analysis with period:\")\n",
    "    print(f\"Using YearMonth >= {test_set_start_ym}\")\n",
    "    \n",
    "    # Apply filter\n",
    "    df_filtered = df[df['YearMonth'] >= test_set_start_ym].copy()\n",
    "    \n",
    "    print(f\"Records after temporal filter: {len(df_filtered):,} ({(len(df_filtered)/len(df))*100:.1f}% of original)\")\n",
    "    \n",
    "    if len(df_filtered) > 0:\n",
    "        print(f\"Filtered dataset year-months:\")\n",
    "        filtered_ym_counts = df_filtered['YearMonth'].value_counts().sort_index()\n",
    "        for ym, count in filtered_ym_counts.items():\n",
    "            print(f\"  {ym}: {count:,} records\")\n",
    "        \n",
    "        # Drop the temporary YearMonth column\n",
    "        df_filtered.drop(columns=['YearMonth'], inplace=True)\n",
    "        df.drop(columns=['YearMonth'], inplace=True)\n",
    "        \n",
    "        # Use filtered data for clustering\n",
    "        df = df_filtered\n",
    "        print(f\"\\nUsing filtered dataset for clustering analysis.\")\n",
    "    else:\n",
    "        print(f\"Warning: No data found for YearMonth >= {test_set_start_ym}\")\n",
    "        print(\"Falling back to recent years filter (YEAR >= 2023)\")\n",
    "        # Fallback to the previous approach\n",
    "        recent_years_threshold = 2023\n",
    "        df_filtered = df[df['YEAR'] >= recent_years_threshold].copy()\n",
    "        df = df_filtered\n",
    "        df.drop(columns=['YearMonth'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: YEAR or MONTH column not found. Skipping temporal filtering.\")\n",
    "    print(\"Using full dataset for clustering analysis.\")\n",
    "\n",
    "# Create clean dataset for spatial analysis\n",
    "print(f\"\\nPreparing dataset for spatial clustering...\")\n",
    "\n",
    "# Filter for valid coordinates\n",
    "if len(spatial_available) >= 2:\n",
    "    # Remove rows with missing coordinates\n",
    "    valid_coords_mask = df[spatial_available].notna().all(axis=1)\n",
    "    df_spatial = df[valid_coords_mask].copy()\n",
    "    \n",
    "    print(f\"Records with valid coordinates: {len(df_spatial):,} ({(len(df_spatial)/len(df))*100:.2f}%)\")\n",
    "    \n",
    "    # Additional coordinate validation\n",
    "    lat_col = 'Latitude'\n",
    "    lon_col = 'Longitude'\n",
    "    \n",
    "    if lat_col in df_spatial.columns and lon_col in df_spatial.columns:\n",
    "        # NYC coordinate bounds\n",
    "        nyc_bounds_mask = (\n",
    "            df_spatial[lat_col].between(40.4774, 40.9176) &\n",
    "            df_spatial[lon_col].between(-74.2591, -73.7004)\n",
    "        )\n",
    "        df_spatial = df_spatial[nyc_bounds_mask].copy()\n",
    "        \n",
    "        print(f\"Records within NYC bounds: {len(df_spatial):,}\")\n",
    "    else:\n",
    "        print(f\"Warning: Coordinate columns {lat_col}/{lon_col} not found for geographic filtering\")\n",
    "else:\n",
    "    raise ValueError(\"Insufficient spatial features for clustering analysis\")\n",
    "\n",
    "# Display final dataset summary\n",
    "print(f\"\\nFinal dataset for clustering:\")\n",
    "print(f\"Shape: {df_spatial.shape}\")\n",
    "print(f\"Coordinate coverage: {len(df_spatial):,} records\")\n",
    "print(f\"Time range: {df_spatial['YEAR'].min()} - {df_spatial['YEAR'].max()}\")\n",
    "print(f\"Memory usage: {df_spatial.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check availability of extended features\n",
    "print(f\"\\nExtended features availability:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check spatial context features (POI-based)\n",
    "spatial_context_available = [col for col in SPATIAL_CONTEXT_FEATURES if col in df.columns]\n",
    "print(f\"Spatial context features: {len(spatial_context_available)}/{len(SPATIAL_CONTEXT_FEATURES)} available\")\n",
    "if spatial_context_available:\n",
    "    print(f\"  Available: {spatial_context_available[:5]}...\")  # Show first 5\n",
    "\n",
    "# Check extended temporal features\n",
    "extended_temporal_available = [col for col in EXTENDED_TEMPORAL_FEATURES if col in df.columns]\n",
    "print(f\"Extended temporal features: {len(extended_temporal_available)}/{len(EXTENDED_TEMPORAL_FEATURES)} available\")\n",
    "if extended_temporal_available:\n",
    "    print(f\"  Available: {extended_temporal_available}\")\n",
    "\n",
    "# Check extended categorical features\n",
    "extended_categorical_available = [col for col in EXTENDED_CATEGORICAL_FEATURES if col in df.columns]\n",
    "print(f\"Extended categorical features: {len(extended_categorical_available)}/{len(EXTENDED_CATEGORICAL_FEATURES)} available\")\n",
    "if extended_categorical_available:\n",
    "    print(f\"  Available: {extended_categorical_available[:5]}...\")  # Show first 5\n",
    "\n",
    "# Check social features\n",
    "social_available = [col for col in SOCIAL_FEATURES if col in df.columns]\n",
    "print(f\"Social features: {len(social_available)}/{len(SOCIAL_FEATURES)} available\")\n",
    "if social_available:\n",
    "    print(f\"  Available: {social_available}\")\n",
    "\n",
    "# Display temporal distribution after filtering\n",
    "if 'YEAR' in df_spatial.columns and 'MONTH' in df_spatial.columns:\n",
    "    print(f\"\\nTemporal distribution in filtered dataset:\")\n",
    "    print(\"-\" * 40)\n",
    "    yearly_counts = df_spatial['YEAR'].value_counts().sort_index()\n",
    "    for year, count in yearly_counts.items():\n",
    "        print(f\"  {year}: {count:,} records\")\n",
    "    \n",
    "    # Show monthly distribution for each year in the filtered data\n",
    "    years_in_data = sorted(df_spatial['YEAR'].unique())\n",
    "    for year in years_in_data:\n",
    "        monthly_counts = df_spatial[df_spatial['YEAR'] == year]['MONTH'].value_counts().sort_index()\n",
    "        print(f\"\\nMonthly distribution for {year}:\")\n",
    "        print(\"-\" * 40)\n",
    "        for month, count in monthly_counts.items():\n",
    "            print(f\"  Month {month:2d}: {count:,} records\")\n",
    "\n",
    "# Final clustering dataset summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"CLUSTERING DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset period: Nov 2024 onwards\")\n",
    "print(f\"Total records for clustering: {len(df_spatial):,}\")\n",
    "print(f\"Geographic validity: NYC coordinate bounds enforced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "873345a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stratified sample by BORO_NM: 10,000 rows out of 85,968 total\n",
      "Stratum distribution (sample):\n",
      "  BRONX: 2,230 (0.223)\n",
      "  BROOKLYN: 2,747 (0.275)\n",
      "  MANHATTAN: 2,447 (0.245)\n",
      "  QUEENS: 2,160 (0.216)\n",
      "  STATEN ISLAND: 416 (0.042)\n",
      "Dataset created: 10000 rows out of 85968 total\n",
      "     BORO_NM  KY_CD   LAW_CAT_CD LOC_OF_OCCUR_DESC  \\\n",
      "0  MANHATTAN    344  MISDEMEANOR            INSIDE   \n",
      "\n",
      "                      OFNS_DESC  PD_CD           PREM_TYP_DESC SUSP_AGE_GROUP  \\\n",
      "0  ASSAULT 3 & RELATED OFFENSES    114  RESIDENCE - APT. HOUSE          18-24   \n",
      "\n",
      "        SUSP_RACE SUSP_SEX VIC_AGE_GROUP        VIC_RACE VIC_SEX   Latitude  \\\n",
      "0  BLACK HISPANIC        M         45-64  BLACK HISPANIC       F  40.858427   \n",
      "\n",
      "   Longitude  BAR_DISTANCE  NIGHTCLUB_DISTANCE  ATM_DISTANCE  ATMS_COUNT  \\\n",
      "0 -73.928801    486.953208          779.356614    766.720091         0.0   \n",
      "\n",
      "   BARS_COUNT  BUS_STOPS_COUNT  METROS_COUNT  NIGHTCLUBS_COUNT  SCHOOLS_COUNT  \\\n",
      "0         0.0              0.0           0.0               0.0            0.0   \n",
      "\n",
      "   METRO_DISTANCE  MIN_POI_DISTANCE  AVG_POI_DISTANCE  MAX_POI_DISTANCE  \\\n",
      "0      355.419467        355.419467        597.112345        779.356614   \n",
      "\n",
      "   TOTAL_POI_COUNT  POI_DIVERSITY  POI_DENSITY_SCORE  HOUR  DAY   WEEKDAY  \\\n",
      "0              0.0              0                0.0    13    2  SATURDAY   \n",
      "\n",
      "   IS_WEEKEND  MONTH  YEAR  SEASON TIME_BUCKET  IS_HOLIDAY  IS_PAYDAY  \\\n",
      "0           1     11  2024  AUTUMN   AFTERNOON           0          0   \n",
      "\n",
      "   SAME_AGE_GROUP  SAME_SEX  TO_CHECK_CITIZENS  \n",
      "0               0         0                  1  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Configuration: Full Dataset vs Sample ---\n",
    "# Set to True to use full dataset, False to use sample\n",
    "USE_FULL_DATA = False\n",
    "\n",
    "# Helper: balanced stratified sampling with shortfall redistribution\n",
    "def stratified_sample_balanced(df_in, strat_col, n_total, random_state=42):\n",
    "    if strat_col not in df_in.columns:\n",
    "        # Fallback to simple sample\n",
    "        n_take = min(n_total, len(df_in))\n",
    "        return df_in.sample(n_take, random_state=random_state)\n",
    "\n",
    "    df_in = df_in[df_in[strat_col].notna()].copy()\n",
    "    if len(df_in) == 0:\n",
    "        return df_in\n",
    "\n",
    "    total = len(df_in)\n",
    "    if n_total >= total:\n",
    "        # Return all rows if requested sample >= population\n",
    "        return df_in.sample(frac=1.0, random_state=random_state)\n",
    "\n",
    "    sizes = df_in[strat_col].value_counts().sort_index()\n",
    "    groups = df_in.groupby(strat_col)\n",
    "\n",
    "    # Ideal proportional allocation\n",
    "    ideal = sizes / total * n_total\n",
    "    base = np.floor(ideal).astype(int)\n",
    "\n",
    "    # Cap by availability\n",
    "    cap = sizes\n",
    "    alloc = base.clip(upper=cap)\n",
    "\n",
    "    # Largest remainder method\n",
    "    remaining = int(n_total - alloc.sum())\n",
    "    remainders = (ideal - base)\n",
    "\n",
    "    # First pass: distribute by largest remainders\n",
    "    for key in remainders.sort_values(ascending=False).index:\n",
    "        if remaining == 0:\n",
    "            break\n",
    "        if alloc[key] < cap[key]:\n",
    "            alloc[key] += 1\n",
    "            remaining -= 1\n",
    "\n",
    "    # Draw samples per stratum\n",
    "    parts = []\n",
    "    for key, g in groups:\n",
    "        k = int(alloc.get(key, 0))\n",
    "        if k <= 0:\n",
    "            continue\n",
    "        if k >= len(g):\n",
    "            parts.append(g)\n",
    "        else:\n",
    "            parts.append(g.sample(n=k, random_state=random_state))\n",
    "\n",
    "    out = pd.concat(parts, axis=0)\n",
    "    # Shuffle for randomness with reproducibility\n",
    "    out = out.sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Safety: trim over allocation\n",
    "    if len(out) > n_total:\n",
    "        out = out.iloc[:n_total].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "# Configure dataset based on flag\n",
    "if USE_FULL_DATA:\n",
    "    df = df_spatial.copy()\n",
    "    print(f\"Using full dataset: {df.shape[0]:,} rows\")\n",
    "else:\n",
    "    N_SAMPLE = 10_000  # target number of rows to take\n",
    "    if 'BORO_NM' in df_spatial.columns and df_spatial['BORO_NM'].notna().any():\n",
    "        df = stratified_sample_balanced(df_spatial, 'BORO_NM', N_SAMPLE, random_state=RANDOM_STATE).copy()\n",
    "        print(f\"Using stratified sample by BORO_NM: {df.shape[0]:,} rows out of {df_spatial.shape[0]:,} total\")\n",
    "        try:\n",
    "            counts = df['BORO_NM'].value_counts().sort_index()\n",
    "            props = (counts / len(df)).round(3)\n",
    "            print(\"Stratum distribution (sample):\")\n",
    "            for name, count in counts.items():\n",
    "                print(f\"  {name}: {count:,} ({props[name]:.3f})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    else:\n",
    "        n_take = min(N_SAMPLE, len(df_spatial))\n",
    "        df = df_spatial.sample(n_take, random_state=RANDOM_STATE).copy()\n",
    "        print(f\"Using simple sample: {df.shape[0]:,} rows out of {df_spatial.shape[0]:,} total\")\n",
    "\n",
    "print(f\"Dataset created: {df.shape[0]} rows out of {df_spatial.shape[0]} total\")\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 44)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92631f25",
   "metadata": {},
   "source": [
    "## K-Modes for Categorical Crime Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a50ce7",
   "metadata": {},
   "source": [
    "### Categorical Feature Preparation for K-Modes\n",
    "\n",
    "K-Modes clustering is specifically designed for categorical data. We prepare our categorical features for pattern discovery in crime types, locations, and demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc25cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL FEATURE PREPARATION FOR K-MODES ===\n",
      "Base categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
      "Added operational categorical features: ['TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY']\n",
      "Added POI/context bins: [np.str_('METRO_DISTANCE_BIN'), np.str_('POI_DENSITY_SCORE_BIN')]\n",
      "Added demographics (race excluded): ['SUSP_SEX', 'SUSP_AGE_GROUP', 'VIC_SEX', 'VIC_AGE_GROUP']\n",
      "Total categorical features for K-Modes: 12\n",
      "Rows available for K-Modes after base-feature check: 10,000\n",
      "Feature matrix shape: (10000, 12)\n",
      "First feature columns: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC', 'TIME_BUCKET', 'IS_WEEKEND']\n"
     ]
    }
   ],
   "source": [
    "# Define categorical features for K-Modes clustering\n",
    "BASE_KMODES_FEATURES = ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
    "\n",
    "# Additional categorical features directly useful for operations\n",
    "EXTRA_CATEGORICAL_FEATURES = [\n",
    "    # 'LAW_CAT_CD',               # Optional: not useful having OFNS_DESC\n",
    "    # 'LOC_OF_OCCUR_DESC',        # Optional: not useful having PREM_TYP_DESC\n",
    "    'TIME_BUCKET',              # Coarse time-of-day buckets\n",
    "    'IS_WEEKEND', 'IS_HOLIDAY', # Operationally meaningful flags\n",
    "    # 'WEEKDAY',               # Optional: more granular temporal, commented to reduce noise\n",
    "    # 'IS_PAYDAY',            # Optional: typically low impact\n",
    "    # 'SAME_AGE_GROUP',       # Optional: low operational value\n",
    "    # 'SAME_SEX',             # Optional: low operational value\n",
    "]\n",
    "\n",
    "# Demographics: keep age/sex; exclude race to avoid bias and improve fairness\n",
    "DEMOGRAPHIC_CATEGORICAL = [\n",
    "    'SUSP_SEX', 'SUSP_AGE_GROUP',\n",
    "    'VIC_SEX', 'VIC_AGE_GROUP',\n",
    "    # 'SUSP_RACE', 'VIC_RACE',\n",
    "]\n",
    "\n",
    "# Numeric POI/distances transformed into interpretable categories\n",
    "DISTANCE_COLS = [\n",
    "    'METRO_DISTANCE',\n",
    "    # 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE',\n",
    "    # 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE',\n",
    "]\n",
    "COUNT_COLS = [\n",
    "    # 'TOTAL_POI_COUNT',\n",
    "    # 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT',\n",
    "    # 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT',\n",
    "]\n",
    "SCORE_COLS = [\n",
    "    'POI_DENSITY_SCORE',\n",
    "    # 'POI_DIVERSITY',\n",
    "]\n",
    "\n",
    "print(\"=== CATEGORICAL FEATURE PREPARATION FOR K-MODES ===\")\n",
    "\n",
    "# Use the configured dataset\n",
    "_df = df.copy()\n",
    "\n",
    "def top_k_map(series, k=10):\n",
    "    if series.isna().all():\n",
    "        return series.fillna('Unknown')\n",
    "    vc = series.value_counts()\n",
    "    top = set(vc.head(k).index)\n",
    "    return series.where(series.isin(top), 'OTHER').astype(str).fillna('Unknown')\n",
    "\n",
    "# Use ColumnBinner instead of inline binning helpers\n",
    "binner_config = {\n",
    "    'METRO_DISTANCE': {\n",
    "        'kind': 'distance',\n",
    "        'bins': [-np.inf, 250, 1000, np.inf],\n",
    "        'labels': ['Near', 'Mid', 'Far']\n",
    "    },\n",
    "    'POI_DENSITY_SCORE': {\n",
    "        'kind': 'score',\n",
    "        'quantiles': 4,\n",
    "        'labels': ['Low', 'Medium', 'High', 'VeryHigh']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Instantiate and apply binner\n",
    "column_binner = ColumnBinner(config=binner_config, suffix=\"_BIN\", fill_unknown=\"Unknown\")\n",
    "column_binner.fit(_df)\n",
    "_df = column_binner.transform(_df)\n",
    "\n",
    "# Track created bins consistently\n",
    "created_bins = [col for col in column_binner.get_feature_names_out() if col in _df.columns]\n",
    "\n",
    "# Ensure core categoricals are strings and filled\n",
    "for col in BASE_KMODES_FEATURES + EXTRA_CATEGORICAL_FEATURES:\n",
    "    if col in _df.columns:\n",
    "        _df[col] = _df[col].astype(str).fillna('Unknown')\n",
    "\n",
    "# Compose the final feature list for K-Modes\n",
    "CATEGORICAL_FEATURES_KMODES = BASE_KMODES_FEATURES + [\n",
    "    c for c in EXTRA_CATEGORICAL_FEATURES if c in _df.columns\n",
    "] + created_bins + [c for c in DEMOGRAPHIC_CATEGORICAL if c in _df.columns]\n",
    "\n",
    "print(\"Base categorical features:\", BASE_KMODES_FEATURES)\n",
    "print(\"Added operational categorical features:\", [c for c in EXTRA_CATEGORICAL_FEATURES if c in _df.columns])\n",
    "print(\"Added POI/context bins:\", created_bins)\n",
    "print(\"Added demographics (race excluded):\", [c for c in DEMOGRAPHIC_CATEGORICAL if c in _df.columns])\n",
    "\n",
    "# Check feature availability\n",
    "categorical_available = [col for col in CATEGORICAL_FEATURES_KMODES if col in _df.columns]\n",
    "print(f\"Total categorical features for K-Modes: {len(categorical_available)}\")\n",
    "\n",
    "# Prepare dataset holders used downstream\n",
    "if not categorical_available:\n",
    "    raise ValueError(\"No categorical features available for K-Modes clustering\")\n",
    "\n",
    "# Keep a wide copy for labeling/ops; drop rows only if core/base features are missing\n",
    "# (to avoid losing useful non-feature columns like HOUR, IS_WEEKEND later)\n",
    "df_kmodes_input = _df.copy()\n",
    "required_for_row = [c for c in BASE_KMODES_FEATURES if c in df_kmodes_input.columns]\n",
    "df_kmodes = df_kmodes_input.dropna(subset=required_for_row).copy() if required_for_row else df_kmodes_input.copy()\n",
    "\n",
    "# Build X_categorical as the feature matrix used by the pipeline\n",
    "CATEGORICAL_FEATURES_KMODES_AVAILABLE = [c for c in CATEGORICAL_FEATURES_KMODES if c in df_kmodes.columns]\n",
    "X_categorical = df_kmodes[CATEGORICAL_FEATURES_KMODES_AVAILABLE].astype(str).fillna('Unknown')\n",
    "\n",
    "print(f\"Rows available for K-Modes after base-feature check: {len(df_kmodes):,}\")\n",
    "print(f\"Feature matrix shape: {X_categorical.shape}\")\n",
    "print(f\"First feature columns: {CATEGORICAL_FEATURES_KMODES_AVAILABLE[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36d299e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot the exact categorical dataset used for K-Modes to ensure consistency downstream\n",
    "if 'X_categorical' in globals() and 'X_categorical_kmodes_ref' not in globals():\n",
    "    X_categorical_kmodes_ref = X_categorical.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fd3e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_kmodes_input' in globals():\n",
    "    for c in df_kmodes_input.columns:\n",
    "        if str(df_kmodes_input[c].dtype) in ('object', 'category'):\n",
    "            df_kmodes_input[c] = df_kmodes_input[c].fillna('Unknown').astype(str)\n",
    "\n",
    "if 'X_categorical' in globals():\n",
    "    for c in X_categorical.columns:\n",
    "        if str(X_categorical[c].dtype) in ('object', 'category'):\n",
    "            X_categorical[c] = X_categorical[c].fillna('Unknown').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b8023",
   "metadata": {},
   "source": [
    "### K-Modes Pipeline Construction\n",
    "\n",
    "Following the same modular pipeline approach as SpatialHotspotAnalysis, we create a preprocessing pipeline for categorical features and K-Modes clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01eef35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES PIPELINE CONSTRUCTION ===\n",
      "K-Modes pipeline constructed successfully\n",
      "Pipeline steps: ['preprocess', 'cluster']\n",
      "Parameter grid defined:\n",
      "  n_clusters: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "  init methods: ['Huang', 'Cao']\n",
      "  n_init: [5, 10]\n",
      "Total combinations: 60\n"
     ]
    }
   ],
   "source": [
    "print(\"=== K-MODES PIPELINE CONSTRUCTION ===\")\n",
    "\n",
    "categorical_preprocessor = CategoricalPreprocessor(handle_missing='drop')\n",
    "\n",
    "kmodes_pipeline = Pipeline([\n",
    "    ('preprocess', categorical_preprocessor),\n",
    "    ('cluster', KModes(n_clusters=5, init='Huang', n_init=5, verbose=1, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "print(\"K-Modes pipeline constructed successfully\")\n",
    "print(f\"Pipeline steps: {[step[0] for step in kmodes_pipeline.steps]}\")\n",
    "\n",
    "kmodes_param_grid = {\n",
    "    'cluster__n_clusters': list(range(6, 21)),\n",
    "    'cluster__init': ['Huang', 'Cao'],\n",
    "    'cluster__n_init': [5, 10]\n",
    "}\n",
    "\n",
    "print(f\"Parameter grid defined:\")\n",
    "print(f\"  n_clusters: {kmodes_param_grid['cluster__n_clusters']}\")\n",
    "print(f\"  init methods: {kmodes_param_grid['cluster__init']}\")\n",
    "print(f\"  n_init: {kmodes_param_grid['cluster__n_init']}\")\n",
    "print(f\"Total combinations: {len(list(ParameterGrid(kmodes_param_grid)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d640f5",
   "metadata": {},
   "source": [
    "### K-Modes Parameter Grid Search & Evaluation\n",
    "\n",
    "Following the same systematic parameter optimization approach as SpatialHotspotAnalysis, we perform grid search to find optimal K-Modes parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f7d85ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES PARAMETER GRID SEARCH ===\n",
      "Starting grid search with 60 parameter combinations...\n",
      "\n",
      "Testing combination 1: n_clusters=6, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2325, cost: 51050.0\n",
      "Run 1, iteration: 2/100, moves: 540, cost: 51050.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3423, cost: 50380.0\n",
      "Run 2, iteration: 2/100, moves: 1239, cost: 50096.0\n",
      "Run 2, iteration: 3/100, moves: 125, cost: 50096.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3248, cost: 50001.0\n",
      "Run 3, iteration: 2/100, moves: 1334, cost: 49174.0\n",
      "Run 3, iteration: 3/100, moves: 932, cost: 48779.0\n",
      "Run 3, iteration: 4/100, moves: 211, cost: 48779.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3200, cost: 50887.0\n",
      "Run 4, iteration: 2/100, moves: 374, cost: 50887.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2790, cost: 51517.0\n",
      "Run 5, iteration: 2/100, moves: 1184, cost: 50593.0\n",
      "Run 5, iteration: 3/100, moves: 616, cost: 50593.0\n",
      "Best run was number 3\n",
      "  Runtime: 9.01s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 551-2560\n",
      "  Balance ratio: 4.65\n",
      "  Avg dissimilarity: 4.878\n",
      "  Composite score: 0.3747\n",
      "\n",
      "Testing combination 2: n_clusters=6, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2325, cost: 51050.0\n",
      "Run 1, iteration: 2/100, moves: 540, cost: 51050.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3423, cost: 50380.0\n",
      "Run 2, iteration: 2/100, moves: 1239, cost: 50096.0\n",
      "Run 2, iteration: 3/100, moves: 125, cost: 50096.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3248, cost: 50001.0\n",
      "Run 3, iteration: 2/100, moves: 1334, cost: 49174.0\n",
      "Run 3, iteration: 3/100, moves: 932, cost: 48779.0\n",
      "Run 3, iteration: 4/100, moves: 211, cost: 48779.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3200, cost: 50887.0\n",
      "Run 4, iteration: 2/100, moves: 374, cost: 50887.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2790, cost: 51517.0\n",
      "Run 5, iteration: 2/100, moves: 1184, cost: 50593.0\n",
      "Run 5, iteration: 3/100, moves: 616, cost: 50593.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3297, cost: 50274.0\n",
      "Run 6, iteration: 2/100, moves: 850, cost: 50274.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2807, cost: 49616.0\n",
      "Run 7, iteration: 2/100, moves: 943, cost: 48560.0\n",
      "Run 7, iteration: 3/100, moves: 230, cost: 48560.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2574, cost: 50751.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3893, cost: 49671.0\n",
      "Run 9, iteration: 2/100, moves: 926, cost: 49213.0\n",
      "Run 9, iteration: 3/100, moves: 635, cost: 48847.0\n",
      "Run 9, iteration: 4/100, moves: 763, cost: 48514.0\n",
      "Run 9, iteration: 5/100, moves: 88, cost: 48514.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2880, cost: 54052.0\n",
      "Run 10, iteration: 2/100, moves: 1134, cost: 52700.0\n",
      "Run 10, iteration: 3/100, moves: 1440, cost: 51614.0\n",
      "Run 10, iteration: 4/100, moves: 1231, cost: 51210.0\n",
      "Run 10, iteration: 5/100, moves: 263, cost: 51210.0\n",
      "Best run was number 9\n",
      "  Runtime: 23.46s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 1043-1985\n",
      "  Balance ratio: 1.90\n",
      "  Avg dissimilarity: 4.851\n",
      "  Composite score: 0.5415\n",
      "\n",
      "Testing combination 3: n_clusters=7, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2511, cost: 48437.0\n",
      "Run 1, iteration: 2/100, moves: 1288, cost: 48437.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3380, cost: 49846.0\n",
      "Run 2, iteration: 2/100, moves: 1825, cost: 49042.0\n",
      "Run 2, iteration: 3/100, moves: 3, cost: 49042.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3956, cost: 47094.0\n",
      "Run 3, iteration: 2/100, moves: 730, cost: 47094.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3135, cost: 49665.0\n",
      "Run 4, iteration: 2/100, moves: 128, cost: 49665.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3201, cost: 49460.0\n",
      "Run 5, iteration: 2/100, moves: 445, cost: 49460.0\n",
      "Best run was number 3\n",
      "  Runtime: 9.77s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 640-2012\n",
      "  Balance ratio: 3.14\n",
      "  Avg dissimilarity: 4.709\n",
      "  Composite score: 0.5004\n",
      "\n",
      "Testing combination 4: n_clusters=7, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2511, cost: 48437.0\n",
      "Run 1, iteration: 2/100, moves: 1288, cost: 48437.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3380, cost: 49846.0\n",
      "Run 2, iteration: 2/100, moves: 1825, cost: 49042.0\n",
      "Run 2, iteration: 3/100, moves: 3, cost: 49042.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3956, cost: 47094.0\n",
      "Run 3, iteration: 2/100, moves: 730, cost: 47094.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3135, cost: 49665.0\n",
      "Run 4, iteration: 2/100, moves: 128, cost: 49665.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3201, cost: 49460.0\n",
      "Run 5, iteration: 2/100, moves: 445, cost: 49460.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2959, cost: 49708.0\n",
      "Run 6, iteration: 2/100, moves: 1486, cost: 48444.0\n",
      "Run 6, iteration: 3/100, moves: 635, cost: 48444.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3434, cost: 48342.0\n",
      "Run 7, iteration: 2/100, moves: 577, cost: 48342.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2496, cost: 48961.0\n",
      "Run 8, iteration: 2/100, moves: 720, cost: 47942.0\n",
      "Run 8, iteration: 3/100, moves: 828, cost: 47942.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3448, cost: 48761.0\n",
      "Run 9, iteration: 2/100, moves: 734, cost: 48530.0\n",
      "Run 9, iteration: 3/100, moves: 90, cost: 48530.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3121, cost: 48433.0\n",
      "Run 10, iteration: 2/100, moves: 1142, cost: 47584.0\n",
      "Run 10, iteration: 3/100, moves: 503, cost: 47584.0\n",
      "Best run was number 3\n",
      "  Runtime: 20.30s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 640-2012\n",
      "  Balance ratio: 3.14\n",
      "  Avg dissimilarity: 4.709\n",
      "  Composite score: 0.5004\n",
      "\n",
      "Testing combination 5: n_clusters=8, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2133, cost: 48629.0\n",
      "Run 1, iteration: 2/100, moves: 626, cost: 48071.0\n",
      "Run 1, iteration: 3/100, moves: 718, cost: 47758.0\n",
      "Run 1, iteration: 4/100, moves: 801, cost: 47758.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3638, cost: 46761.0\n",
      "Run 2, iteration: 2/100, moves: 1136, cost: 46605.0\n",
      "Run 2, iteration: 3/100, moves: 93, cost: 46605.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3629, cost: 48130.0\n",
      "Run 3, iteration: 2/100, moves: 30, cost: 48130.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3319, cost: 47325.0\n",
      "Run 4, iteration: 2/100, moves: 284, cost: 47325.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3398, cost: 47342.0\n",
      "Run 5, iteration: 2/100, moves: 2254, cost: 46730.0\n",
      "Run 5, iteration: 3/100, moves: 506, cost: 46730.0\n",
      "Best run was number 2\n",
      "  Runtime: 11.89s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 690-1839\n",
      "  Balance ratio: 2.67\n",
      "  Avg dissimilarity: 4.660\n",
      "  Composite score: 0.5403\n",
      "\n",
      "Testing combination 6: n_clusters=8, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2133, cost: 48629.0\n",
      "Run 1, iteration: 2/100, moves: 626, cost: 48071.0\n",
      "Run 1, iteration: 3/100, moves: 718, cost: 47758.0\n",
      "Run 1, iteration: 4/100, moves: 801, cost: 47758.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3638, cost: 46761.0\n",
      "Run 2, iteration: 2/100, moves: 1136, cost: 46605.0\n",
      "Run 2, iteration: 3/100, moves: 93, cost: 46605.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3629, cost: 48130.0\n",
      "Run 3, iteration: 2/100, moves: 30, cost: 48130.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3319, cost: 47325.0\n",
      "Run 4, iteration: 2/100, moves: 284, cost: 47325.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3398, cost: 47342.0\n",
      "Run 5, iteration: 2/100, moves: 2254, cost: 46730.0\n",
      "Run 5, iteration: 3/100, moves: 506, cost: 46730.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2898, cost: 49268.0\n",
      "Run 6, iteration: 2/100, moves: 626, cost: 48928.0\n",
      "Run 6, iteration: 3/100, moves: 783, cost: 48066.0\n",
      "Run 6, iteration: 4/100, moves: 1187, cost: 47650.0\n",
      "Run 6, iteration: 5/100, moves: 0, cost: 47650.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2870, cost: 46816.0\n",
      "Run 7, iteration: 2/100, moves: 575, cost: 46650.0\n",
      "Run 7, iteration: 3/100, moves: 73, cost: 46650.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 3068, cost: 49588.0\n",
      "Run 8, iteration: 2/100, moves: 1469, cost: 48726.0\n",
      "Run 8, iteration: 3/100, moves: 945, cost: 48292.0\n",
      "Run 8, iteration: 4/100, moves: 880, cost: 47933.0\n",
      "Run 8, iteration: 5/100, moves: 507, cost: 47933.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3645, cost: 47373.0\n",
      "Run 9, iteration: 2/100, moves: 1375, cost: 47373.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3639, cost: 47918.0\n",
      "Run 10, iteration: 2/100, moves: 81, cost: 47918.0\n",
      "Best run was number 2\n",
      "  Runtime: 25.26s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 690-1839\n",
      "  Balance ratio: 2.67\n",
      "  Avg dissimilarity: 4.660\n",
      "  Composite score: 0.5403\n",
      "\n",
      "Testing combination 7: n_clusters=9, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2272, cost: 47137.0\n",
      "Run 1, iteration: 2/100, moves: 986, cost: 47137.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 4353, cost: 46875.0\n",
      "Run 2, iteration: 2/100, moves: 1539, cost: 46299.0\n",
      "Run 2, iteration: 3/100, moves: 322, cost: 46299.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3265, cost: 46844.0\n",
      "Run 3, iteration: 2/100, moves: 697, cost: 46844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3321, cost: 48190.0\n",
      "Run 4, iteration: 2/100, moves: 773, cost: 47415.0\n",
      "Run 4, iteration: 3/100, moves: 1184, cost: 47056.0\n",
      "Run 4, iteration: 4/100, moves: 92, cost: 47056.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2866, cost: 48186.0\n",
      "Best run was number 2\n",
      "  Runtime: 9.91s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 525-1933\n",
      "  Balance ratio: 3.68\n",
      "  Avg dissimilarity: 4.630\n",
      "  Composite score: 0.5136\n",
      "\n",
      "Testing combination 8: n_clusters=9, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2272, cost: 47137.0\n",
      "Run 1, iteration: 2/100, moves: 986, cost: 47137.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 4353, cost: 46875.0\n",
      "Run 2, iteration: 2/100, moves: 1539, cost: 46299.0\n",
      "Run 2, iteration: 3/100, moves: 322, cost: 46299.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3265, cost: 46844.0\n",
      "Run 3, iteration: 2/100, moves: 697, cost: 46844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3321, cost: 48190.0\n",
      "Run 4, iteration: 2/100, moves: 773, cost: 47415.0\n",
      "Run 4, iteration: 3/100, moves: 1184, cost: 47056.0\n",
      "Run 4, iteration: 4/100, moves: 92, cost: 47056.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2866, cost: 48186.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3382, cost: 48181.0\n",
      "Run 6, iteration: 2/100, moves: 1516, cost: 47766.0\n",
      "Run 6, iteration: 3/100, moves: 531, cost: 47766.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2749, cost: 47143.0\n",
      "Run 7, iteration: 2/100, moves: 1060, cost: 46834.0\n",
      "Run 7, iteration: 3/100, moves: 201, cost: 46834.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2903, cost: 47989.0\n",
      "Run 8, iteration: 2/100, moves: 365, cost: 47989.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3122, cost: 46841.0\n",
      "Run 9, iteration: 2/100, moves: 1036, cost: 46016.0\n",
      "Run 9, iteration: 3/100, moves: 489, cost: 46016.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3232, cost: 46934.0\n",
      "Run 10, iteration: 2/100, moves: 300, cost: 46934.0\n",
      "Best run was number 9\n",
      "  Runtime: 13.45s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 248-1994\n",
      "  Balance ratio: 8.04\n",
      "  Avg dissimilarity: 4.602\n",
      "  Composite score: 0.3525\n",
      "\n",
      "Testing combination 9: n_clusters=10, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3419, cost: 46123.0\n",
      "Run 1, iteration: 2/100, moves: 324, cost: 46123.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3306, cost: 46418.0\n",
      "Run 2, iteration: 2/100, moves: 1619, cost: 45887.0\n",
      "Run 2, iteration: 3/100, moves: 214, cost: 45887.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3507, cost: 45424.0\n",
      "Run 3, iteration: 2/100, moves: 103, cost: 45424.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3106, cost: 46101.0\n",
      "Run 4, iteration: 2/100, moves: 315, cost: 46101.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 4076, cost: 47292.0\n",
      "Run 5, iteration: 2/100, moves: 2377, cost: 47003.0\n",
      "Run 5, iteration: 3/100, moves: 30, cost: 47003.0\n",
      "Best run was number 3\n",
      "  Runtime: 12.96s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 376-1620\n",
      "  Balance ratio: 4.31\n",
      "  Avg dissimilarity: 4.542\n",
      "  Composite score: 0.5112\n",
      "\n",
      "Testing combination 10: n_clusters=10, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3419, cost: 46123.0\n",
      "Run 1, iteration: 2/100, moves: 324, cost: 46123.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3306, cost: 46418.0\n",
      "Run 2, iteration: 2/100, moves: 1619, cost: 45887.0\n",
      "Run 2, iteration: 3/100, moves: 214, cost: 45887.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3507, cost: 45424.0\n",
      "Run 3, iteration: 2/100, moves: 103, cost: 45424.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3106, cost: 46101.0\n",
      "Run 4, iteration: 2/100, moves: 315, cost: 46101.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 4076, cost: 47292.0\n",
      "Run 5, iteration: 2/100, moves: 2377, cost: 47003.0\n",
      "Run 5, iteration: 3/100, moves: 30, cost: 47003.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 4056, cost: 45777.0\n",
      "Run 6, iteration: 2/100, moves: 1403, cost: 45669.0\n",
      "Run 6, iteration: 3/100, moves: 94, cost: 45669.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3411, cost: 45983.0\n",
      "Run 7, iteration: 2/100, moves: 298, cost: 45983.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 3459, cost: 46646.0\n",
      "Run 8, iteration: 2/100, moves: 1153, cost: 46646.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3760, cost: 47227.0\n",
      "Run 9, iteration: 2/100, moves: 900, cost: 47227.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2795, cost: 47811.0\n",
      "Run 10, iteration: 2/100, moves: 93, cost: 47811.0\n",
      "Best run was number 3\n",
      "  Runtime: 12.80s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 376-1620\n",
      "  Balance ratio: 4.31\n",
      "  Avg dissimilarity: 4.542\n",
      "  Composite score: 0.5112\n",
      "\n",
      "Testing combination 11: n_clusters=11, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3556, cost: 45409.0\n",
      "Run 1, iteration: 2/100, moves: 464, cost: 45409.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3693, cost: 47822.0\n",
      "Run 2, iteration: 2/100, moves: 1595, cost: 47023.0\n",
      "Run 2, iteration: 3/100, moves: 421, cost: 47023.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3258, cost: 46773.0\n",
      "Run 3, iteration: 2/100, moves: 641, cost: 46469.0\n",
      "Run 3, iteration: 3/100, moves: 133, cost: 46469.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3008, cost: 45978.0\n",
      "Run 4, iteration: 2/100, moves: 1215, cost: 45978.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3663, cost: 45162.0\n",
      "Run 5, iteration: 2/100, moves: 500, cost: 44981.0\n",
      "Run 5, iteration: 3/100, moves: 212, cost: 44981.0\n",
      "Best run was number 5\n",
      "  Runtime: 12.82s\n",
      "  Clusters: 11\n",
      "  Cluster sizes: 268-1674\n",
      "  Balance ratio: 6.25\n",
      "  Avg dissimilarity: 4.498\n",
      "  Composite score: 0.4678\n",
      "\n",
      "Testing combination 12: n_clusters=11, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3556, cost: 45409.0\n",
      "Run 1, iteration: 2/100, moves: 464, cost: 45409.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3693, cost: 47822.0\n",
      "Run 2, iteration: 2/100, moves: 1595, cost: 47023.0\n",
      "Run 2, iteration: 3/100, moves: 421, cost: 47023.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3258, cost: 46773.0\n",
      "Run 3, iteration: 2/100, moves: 641, cost: 46469.0\n",
      "Run 3, iteration: 3/100, moves: 133, cost: 46469.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3008, cost: 45978.0\n",
      "Run 4, iteration: 2/100, moves: 1215, cost: 45978.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3663, cost: 45162.0\n",
      "Run 5, iteration: 2/100, moves: 500, cost: 44981.0\n",
      "Run 5, iteration: 3/100, moves: 212, cost: 44981.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3096, cost: 45444.0\n",
      "Run 6, iteration: 2/100, moves: 276, cost: 45444.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2753, cost: 44987.0\n",
      "Run 7, iteration: 2/100, moves: 462, cost: 44987.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 3849, cost: 44367.0\n",
      "Run 8, iteration: 2/100, moves: 907, cost: 44194.0\n",
      "Run 8, iteration: 3/100, moves: 199, cost: 44194.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3094, cost: 45813.0\n",
      "Run 9, iteration: 2/100, moves: 200, cost: 45813.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1795, cost: 46640.0\n",
      "Run 10, iteration: 2/100, moves: 281, cost: 46640.0\n",
      "Best run was number 8\n",
      "  Runtime: 28.28s\n",
      "  Clusters: 11\n",
      "  Cluster sizes: 307-1635\n",
      "  Balance ratio: 5.33\n",
      "  Avg dissimilarity: 4.419\n",
      "  Composite score: 0.5019\n",
      "\n",
      "Testing combination 13: n_clusters=12, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3723, cost: 45431.0\n",
      "Run 1, iteration: 2/100, moves: 1182, cost: 44814.0\n",
      "Run 1, iteration: 3/100, moves: 349, cost: 44814.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2313, cost: 45088.0\n",
      "Run 2, iteration: 2/100, moves: 726, cost: 44828.0\n",
      "Run 2, iteration: 3/100, moves: 327, cost: 44828.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2449, cost: 46793.0\n",
      "Run 3, iteration: 2/100, moves: 212, cost: 46793.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3337, cost: 46187.0\n",
      "Run 4, iteration: 2/100, moves: 552, cost: 46187.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2787, cost: 44623.0\n",
      "Run 5, iteration: 2/100, moves: 108, cost: 44623.0\n",
      "Best run was number 5\n",
      "  Runtime: 12.74s\n",
      "  Clusters: 12\n",
      "  Cluster sizes: 279-1481\n",
      "  Balance ratio: 5.31\n",
      "  Avg dissimilarity: 4.462\n",
      "  Composite score: 0.5106\n",
      "\n",
      "Testing combination 14: n_clusters=12, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3723, cost: 45431.0\n",
      "Run 1, iteration: 2/100, moves: 1182, cost: 44814.0\n",
      "Run 1, iteration: 3/100, moves: 349, cost: 44814.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2313, cost: 45088.0\n",
      "Run 2, iteration: 2/100, moves: 726, cost: 44828.0\n",
      "Run 2, iteration: 3/100, moves: 327, cost: 44828.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2449, cost: 46793.0\n",
      "Run 3, iteration: 2/100, moves: 212, cost: 46793.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3337, cost: 46187.0\n",
      "Run 4, iteration: 2/100, moves: 552, cost: 46187.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2787, cost: 44623.0\n",
      "Run 5, iteration: 2/100, moves: 108, cost: 44623.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3258, cost: 45422.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2710, cost: 48798.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 4138, cost: 44517.0\n",
      "Run 8, iteration: 2/100, moves: 918, cost: 44220.0\n",
      "Run 8, iteration: 3/100, moves: 245, cost: 44220.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3492, cost: 45566.0\n",
      "Run 9, iteration: 2/100, moves: 370, cost: 45566.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2653, cost: 45217.0\n",
      "Run 10, iteration: 2/100, moves: 437, cost: 45217.0\n",
      "Best run was number 8\n",
      "  Runtime: 22.45s\n",
      "  Clusters: 12\n",
      "  Cluster sizes: 228-1737\n",
      "  Balance ratio: 7.62\n",
      "  Avg dissimilarity: 4.422\n",
      "  Composite score: 0.4510\n",
      "\n",
      "Testing combination 15: n_clusters=13, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2700, cost: 44959.0\n",
      "Run 1, iteration: 2/100, moves: 555, cost: 44696.0\n",
      "Run 1, iteration: 3/100, moves: 302, cost: 44696.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2454, cost: 44752.0\n",
      "Run 2, iteration: 2/100, moves: 356, cost: 44752.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3338, cost: 44520.0\n",
      "Run 3, iteration: 2/100, moves: 548, cost: 44439.0\n",
      "Run 3, iteration: 3/100, moves: 4, cost: 44439.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2959, cost: 44906.0\n",
      "Run 4, iteration: 2/100, moves: 348, cost: 44763.0\n",
      "Run 4, iteration: 3/100, moves: 12, cost: 44763.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2810, cost: 43812.0\n",
      "Run 5, iteration: 2/100, moves: 1161, cost: 43673.0\n",
      "Run 5, iteration: 3/100, moves: 151, cost: 43673.0\n",
      "Best run was number 5\n",
      "  Runtime: 13.09s\n",
      "  Clusters: 13\n",
      "  Cluster sizes: 366-1489\n",
      "  Balance ratio: 4.07\n",
      "  Avg dissimilarity: 4.367\n",
      "  Composite score: 0.5594\n",
      "\n",
      "Testing combination 16: n_clusters=13, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2700, cost: 44959.0\n",
      "Run 1, iteration: 2/100, moves: 555, cost: 44696.0\n",
      "Run 1, iteration: 3/100, moves: 302, cost: 44696.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2454, cost: 44752.0\n",
      "Run 2, iteration: 2/100, moves: 356, cost: 44752.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3338, cost: 44520.0\n",
      "Run 3, iteration: 2/100, moves: 548, cost: 44439.0\n",
      "Run 3, iteration: 3/100, moves: 4, cost: 44439.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2959, cost: 44906.0\n",
      "Run 4, iteration: 2/100, moves: 348, cost: 44763.0\n",
      "Run 4, iteration: 3/100, moves: 12, cost: 44763.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2810, cost: 43812.0\n",
      "Run 5, iteration: 2/100, moves: 1161, cost: 43673.0\n",
      "Run 5, iteration: 3/100, moves: 151, cost: 43673.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3012, cost: 46212.0\n",
      "Run 6, iteration: 2/100, moves: 1996, cost: 44764.0\n",
      "Run 6, iteration: 3/100, moves: 1191, cost: 44402.0\n",
      "Run 6, iteration: 4/100, moves: 647, cost: 44118.0\n",
      "Run 6, iteration: 5/100, moves: 517, cost: 44118.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3743, cost: 44644.0\n",
      "Run 7, iteration: 2/100, moves: 874, cost: 44364.0\n",
      "Run 7, iteration: 3/100, moves: 105, cost: 44364.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2892, cost: 44817.0\n",
      "Run 8, iteration: 2/100, moves: 593, cost: 44817.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3708, cost: 43955.0\n",
      "Run 9, iteration: 2/100, moves: 194, cost: 43955.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2588, cost: 44643.0\n",
      "Run 10, iteration: 2/100, moves: 911, cost: 44409.0\n",
      "Run 10, iteration: 3/100, moves: 575, cost: 44409.0\n",
      "Best run was number 5\n",
      "  Runtime: 27.12s\n",
      "  Clusters: 13\n",
      "  Cluster sizes: 366-1489\n",
      "  Balance ratio: 4.07\n",
      "  Avg dissimilarity: 4.367\n",
      "  Composite score: 0.5594\n",
      "\n",
      "Testing combination 17: n_clusters=14, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3000, cost: 44686.0\n",
      "Run 1, iteration: 2/100, moves: 599, cost: 44686.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2587, cost: 44263.0\n",
      "Run 2, iteration: 2/100, moves: 1, cost: 44263.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2682, cost: 46220.0\n",
      "Run 3, iteration: 2/100, moves: 228, cost: 46220.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2851, cost: 44306.0\n",
      "Run 4, iteration: 2/100, moves: 51, cost: 44306.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3349, cost: 45016.0\n",
      "Run 5, iteration: 2/100, moves: 448, cost: 45016.0\n",
      "Best run was number 2\n",
      "  Runtime: 11.39s\n",
      "  Clusters: 14\n",
      "  Cluster sizes: 236-1341\n",
      "  Balance ratio: 5.68\n",
      "  Avg dissimilarity: 4.426\n",
      "  Composite score: 0.5231\n",
      "\n",
      "Testing combination 18: n_clusters=14, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3000, cost: 44686.0\n",
      "Run 1, iteration: 2/100, moves: 599, cost: 44686.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2587, cost: 44263.0\n",
      "Run 2, iteration: 2/100, moves: 1, cost: 44263.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2682, cost: 46220.0\n",
      "Run 3, iteration: 2/100, moves: 228, cost: 46220.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2851, cost: 44306.0\n",
      "Run 4, iteration: 2/100, moves: 51, cost: 44306.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3349, cost: 45016.0\n",
      "Run 5, iteration: 2/100, moves: 448, cost: 45016.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3405, cost: 45318.0\n",
      "Run 6, iteration: 2/100, moves: 1497, cost: 44613.0\n",
      "Run 6, iteration: 3/100, moves: 597, cost: 44218.0\n",
      "Run 6, iteration: 4/100, moves: 123, cost: 44218.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3043, cost: 44335.0\n",
      "Run 7, iteration: 2/100, moves: 445, cost: 44335.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2932, cost: 45448.0\n",
      "Run 8, iteration: 2/100, moves: 754, cost: 45448.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3140, cost: 44783.0\n",
      "Run 9, iteration: 2/100, moves: 464, cost: 44783.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3781, cost: 45386.0\n",
      "Run 10, iteration: 2/100, moves: 1176, cost: 44738.0\n",
      "Run 10, iteration: 3/100, moves: 383, cost: 44642.0\n",
      "Run 10, iteration: 4/100, moves: 4, cost: 44642.0\n",
      "Best run was number 6\n",
      "  Runtime: 25.62s\n",
      "  Clusters: 14\n",
      "  Cluster sizes: 318-1358\n",
      "  Balance ratio: 4.27\n",
      "  Avg dissimilarity: 4.422\n",
      "  Composite score: 0.5560\n",
      "\n",
      "Testing combination 19: n_clusters=15, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2834, cost: 44684.0\n",
      "Run 1, iteration: 2/100, moves: 891, cost: 44468.0\n",
      "Run 1, iteration: 3/100, moves: 279, cost: 44468.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3315, cost: 43468.0\n",
      "Run 2, iteration: 2/100, moves: 957, cost: 43200.0\n",
      "Run 2, iteration: 3/100, moves: 110, cost: 43200.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3221, cost: 43648.0\n",
      "Run 3, iteration: 2/100, moves: 574, cost: 43455.0\n",
      "Run 3, iteration: 3/100, moves: 34, cost: 43455.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3993, cost: 43829.0\n",
      "Run 4, iteration: 2/100, moves: 1511, cost: 43476.0\n",
      "Run 4, iteration: 3/100, moves: 101, cost: 43476.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3643, cost: 43231.0\n",
      "Run 5, iteration: 2/100, moves: 850, cost: 43042.0\n",
      "Run 5, iteration: 3/100, moves: 62, cost: 43042.0\n",
      "Best run was number 5\n",
      "  Runtime: 14.66s\n",
      "  Clusters: 15\n",
      "  Cluster sizes: 313-1150\n",
      "  Balance ratio: 3.67\n",
      "  Avg dissimilarity: 4.304\n",
      "  Composite score: 0.5840\n",
      "\n",
      "Testing combination 20: n_clusters=15, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2834, cost: 44684.0\n",
      "Run 1, iteration: 2/100, moves: 891, cost: 44468.0\n",
      "Run 1, iteration: 3/100, moves: 279, cost: 44468.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3315, cost: 43468.0\n",
      "Run 2, iteration: 2/100, moves: 957, cost: 43200.0\n",
      "Run 2, iteration: 3/100, moves: 110, cost: 43200.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3221, cost: 43648.0\n",
      "Run 3, iteration: 2/100, moves: 574, cost: 43455.0\n",
      "Run 3, iteration: 3/100, moves: 34, cost: 43455.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3993, cost: 43829.0\n",
      "Run 4, iteration: 2/100, moves: 1511, cost: 43476.0\n",
      "Run 4, iteration: 3/100, moves: 101, cost: 43476.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3643, cost: 43231.0\n",
      "Run 5, iteration: 2/100, moves: 850, cost: 43042.0\n",
      "Run 5, iteration: 3/100, moves: 62, cost: 43042.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2615, cost: 43433.0\n",
      "Run 6, iteration: 2/100, moves: 383, cost: 43433.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2870, cost: 43866.0\n",
      "Run 7, iteration: 2/100, moves: 434, cost: 43866.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 3157, cost: 44803.0\n",
      "Run 8, iteration: 2/100, moves: 370, cost: 44803.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 3689, cost: 44088.0\n",
      "Run 9, iteration: 2/100, moves: 441, cost: 43777.0\n",
      "Run 9, iteration: 3/100, moves: 572, cost: 43480.0\n",
      "Run 9, iteration: 4/100, moves: 97, cost: 43480.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3226, cost: 44037.0\n",
      "Run 10, iteration: 2/100, moves: 601, cost: 43942.0\n",
      "Run 10, iteration: 3/100, moves: 0, cost: 43942.0\n",
      "Best run was number 5\n",
      "  Runtime: 27.09s\n",
      "  Clusters: 15\n",
      "  Cluster sizes: 313-1150\n",
      "  Balance ratio: 3.67\n",
      "  Avg dissimilarity: 4.304\n",
      "  Composite score: 0.5840\n",
      "\n",
      "Testing combination 21: n_clusters=16, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2339, cost: 43664.0\n",
      "Run 1, iteration: 2/100, moves: 586, cost: 43664.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3412, cost: 43660.0\n",
      "Run 2, iteration: 2/100, moves: 498, cost: 43660.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3233, cost: 43127.0\n",
      "Run 3, iteration: 2/100, moves: 1155, cost: 42850.0\n",
      "Run 3, iteration: 3/100, moves: 138, cost: 42850.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2022, cost: 43481.0\n",
      "Run 4, iteration: 2/100, moves: 793, cost: 43161.0\n",
      "Run 4, iteration: 3/100, moves: 231, cost: 43051.0\n",
      "Run 4, iteration: 4/100, moves: 10, cost: 43051.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2959, cost: 43275.0\n",
      "Run 5, iteration: 2/100, moves: 23, cost: 43275.0\n",
      "Best run was number 3\n",
      "  Runtime: 13.04s\n",
      "  Clusters: 16\n",
      "  Cluster sizes: 167-1541\n",
      "  Balance ratio: 9.23\n",
      "  Avg dissimilarity: 4.285\n",
      "  Composite score: 0.4784\n",
      "\n",
      "Testing combination 22: n_clusters=16, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2339, cost: 43664.0\n",
      "Run 1, iteration: 2/100, moves: 586, cost: 43664.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3412, cost: 43660.0\n",
      "Run 2, iteration: 2/100, moves: 498, cost: 43660.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3233, cost: 43127.0\n",
      "Run 3, iteration: 2/100, moves: 1155, cost: 42850.0\n",
      "Run 3, iteration: 3/100, moves: 138, cost: 42850.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2022, cost: 43481.0\n",
      "Run 4, iteration: 2/100, moves: 793, cost: 43161.0\n",
      "Run 4, iteration: 3/100, moves: 231, cost: 43051.0\n",
      "Run 4, iteration: 4/100, moves: 10, cost: 43051.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2959, cost: 43275.0\n",
      "Run 5, iteration: 2/100, moves: 23, cost: 43275.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 4161, cost: 43263.0\n",
      "Run 6, iteration: 2/100, moves: 850, cost: 42997.0\n",
      "Run 6, iteration: 3/100, moves: 323, cost: 42822.0\n",
      "Run 6, iteration: 4/100, moves: 50, cost: 42822.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3835, cost: 43154.0\n",
      "Run 7, iteration: 2/100, moves: 790, cost: 43154.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2517, cost: 43751.0\n",
      "Run 8, iteration: 2/100, moves: 306, cost: 43751.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2874, cost: 44391.0\n",
      "Run 9, iteration: 2/100, moves: 483, cost: 44391.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2650, cost: 43690.0\n",
      "Run 10, iteration: 2/100, moves: 9, cost: 43690.0\n",
      "Best run was number 6\n",
      "  Runtime: 26.06s\n",
      "  Clusters: 16\n",
      "  Cluster sizes: 266-1640\n",
      "  Balance ratio: 6.17\n",
      "  Avg dissimilarity: 4.282\n",
      "  Composite score: 0.5398\n",
      "\n",
      "Testing combination 23: n_clusters=17, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2771, cost: 42642.0\n",
      "Run 1, iteration: 2/100, moves: 231, cost: 42642.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3391, cost: 42521.0\n",
      "Run 2, iteration: 2/100, moves: 245, cost: 42521.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2871, cost: 43796.0\n",
      "Run 3, iteration: 2/100, moves: 714, cost: 43462.0\n",
      "Run 3, iteration: 3/100, moves: 76, cost: 43462.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3097, cost: 42778.0\n",
      "Run 4, iteration: 2/100, moves: 515, cost: 42429.0\n",
      "Run 4, iteration: 3/100, moves: 321, cost: 42429.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3478, cost: 41884.0\n",
      "Run 5, iteration: 2/100, moves: 525, cost: 41884.0\n",
      "Best run was number 5\n",
      "  Runtime: 12.62s\n",
      "  Clusters: 17\n",
      "  Cluster sizes: 180-1203\n",
      "  Balance ratio: 6.68\n",
      "  Avg dissimilarity: 4.188\n",
      "  Composite score: 0.5444\n",
      "\n",
      "Testing combination 24: n_clusters=17, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2771, cost: 42642.0\n",
      "Run 1, iteration: 2/100, moves: 231, cost: 42642.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3391, cost: 42521.0\n",
      "Run 2, iteration: 2/100, moves: 245, cost: 42521.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2871, cost: 43796.0\n",
      "Run 3, iteration: 2/100, moves: 714, cost: 43462.0\n",
      "Run 3, iteration: 3/100, moves: 76, cost: 43462.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3097, cost: 42778.0\n",
      "Run 4, iteration: 2/100, moves: 515, cost: 42429.0\n",
      "Run 4, iteration: 3/100, moves: 321, cost: 42429.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3478, cost: 41884.0\n",
      "Run 5, iteration: 2/100, moves: 525, cost: 41884.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2601, cost: 44129.0\n",
      "Run 6, iteration: 2/100, moves: 592, cost: 43865.0\n",
      "Run 6, iteration: 3/100, moves: 44, cost: 43865.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2652, cost: 42797.0\n",
      "Run 7, iteration: 2/100, moves: 103, cost: 42797.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 3314, cost: 42491.0\n",
      "Run 8, iteration: 2/100, moves: 159, cost: 42491.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2455, cost: 42438.0\n",
      "Run 9, iteration: 2/100, moves: 912, cost: 42438.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3113, cost: 44351.0\n",
      "Run 10, iteration: 2/100, moves: 672, cost: 44053.0\n",
      "Run 10, iteration: 3/100, moves: 56, cost: 44053.0\n",
      "Best run was number 5\n",
      "  Runtime: 25.86s\n",
      "  Clusters: 17\n",
      "  Cluster sizes: 180-1203\n",
      "  Balance ratio: 6.68\n",
      "  Avg dissimilarity: 4.188\n",
      "  Composite score: 0.5444\n",
      "\n",
      "Testing combination 25: n_clusters=18, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2662, cost: 42696.0\n",
      "Run 1, iteration: 2/100, moves: 384, cost: 42696.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2947, cost: 43421.0\n",
      "Run 2, iteration: 2/100, moves: 617, cost: 43331.0\n",
      "Run 2, iteration: 3/100, moves: 67, cost: 43331.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2732, cost: 43238.0\n",
      "Run 3, iteration: 2/100, moves: 324, cost: 43238.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 4065, cost: 42255.0\n",
      "Run 4, iteration: 2/100, moves: 612, cost: 42255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2653, cost: 42739.0\n",
      "Run 5, iteration: 2/100, moves: 405, cost: 42604.0\n",
      "Run 5, iteration: 3/100, moves: 16, cost: 42604.0\n",
      "Best run was number 4\n",
      "  Runtime: 13.74s\n",
      "  Clusters: 18\n",
      "  Cluster sizes: 205-916\n",
      "  Balance ratio: 4.47\n",
      "  Avg dissimilarity: 4.226\n",
      "  Composite score: 0.5867\n",
      "\n",
      "Testing combination 26: n_clusters=18, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2662, cost: 42696.0\n",
      "Run 1, iteration: 2/100, moves: 384, cost: 42696.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2947, cost: 43421.0\n",
      "Run 2, iteration: 2/100, moves: 617, cost: 43331.0\n",
      "Run 2, iteration: 3/100, moves: 67, cost: 43331.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2732, cost: 43238.0\n",
      "Run 3, iteration: 2/100, moves: 324, cost: 43238.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 4065, cost: 42255.0\n",
      "Run 4, iteration: 2/100, moves: 612, cost: 42255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2653, cost: 42739.0\n",
      "Run 5, iteration: 2/100, moves: 405, cost: 42604.0\n",
      "Run 5, iteration: 3/100, moves: 16, cost: 42604.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3608, cost: 42700.0\n",
      "Run 6, iteration: 2/100, moves: 852, cost: 42268.0\n",
      "Run 6, iteration: 3/100, moves: 376, cost: 42268.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2792, cost: 43388.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2996, cost: 42497.0\n",
      "Run 8, iteration: 2/100, moves: 810, cost: 42180.0\n",
      "Run 8, iteration: 3/100, moves: 107, cost: 42180.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2839, cost: 43225.0\n",
      "Run 9, iteration: 2/100, moves: 718, cost: 42904.0\n",
      "Run 9, iteration: 3/100, moves: 81, cost: 42904.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 3702, cost: 42636.0\n",
      "Run 10, iteration: 2/100, moves: 1175, cost: 42222.0\n",
      "Run 10, iteration: 3/100, moves: 56, cost: 42222.0\n",
      "Best run was number 8\n",
      "  Runtime: 22.94s\n",
      "  Clusters: 18\n",
      "  Cluster sizes: 150-1410\n",
      "  Balance ratio: 9.40\n",
      "  Avg dissimilarity: 4.218\n",
      "  Composite score: 0.5003\n",
      "\n",
      "Testing combination 27: n_clusters=19, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3175, cost: 42724.0\n",
      "Run 1, iteration: 2/100, moves: 528, cost: 42724.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2832, cost: 43159.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3574, cost: 42481.0\n",
      "Run 3, iteration: 2/100, moves: 623, cost: 42481.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3477, cost: 42096.0\n",
      "Run 4, iteration: 2/100, moves: 171, cost: 42096.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3190, cost: 42983.0\n",
      "Run 5, iteration: 2/100, moves: 1346, cost: 42182.0\n",
      "Run 5, iteration: 3/100, moves: 503, cost: 42004.0\n",
      "Run 5, iteration: 4/100, moves: 63, cost: 42004.0\n",
      "Best run was number 5\n",
      "  Runtime: 8.61s\n",
      "  Clusters: 19\n",
      "  Cluster sizes: 188-1394\n",
      "  Balance ratio: 7.41\n",
      "  Avg dissimilarity: 4.200\n",
      "  Composite score: 0.5431\n",
      "\n",
      "Testing combination 28: n_clusters=19, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 3175, cost: 42724.0\n",
      "Run 1, iteration: 2/100, moves: 528, cost: 42724.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2832, cost: 43159.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3574, cost: 42481.0\n",
      "Run 3, iteration: 2/100, moves: 623, cost: 42481.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 3477, cost: 42096.0\n",
      "Run 4, iteration: 2/100, moves: 171, cost: 42096.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 3190, cost: 42983.0\n",
      "Run 5, iteration: 2/100, moves: 1346, cost: 42182.0\n",
      "Run 5, iteration: 3/100, moves: 503, cost: 42004.0\n",
      "Run 5, iteration: 4/100, moves: 63, cost: 42004.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2976, cost: 43261.0\n",
      "Run 6, iteration: 2/100, moves: 559, cost: 43032.0\n",
      "Run 6, iteration: 3/100, moves: 389, cost: 42874.0\n",
      "Run 6, iteration: 4/100, moves: 673, cost: 42568.0\n",
      "Run 6, iteration: 5/100, moves: 727, cost: 42223.0\n",
      "Run 6, iteration: 6/100, moves: 34, cost: 42223.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2673, cost: 42101.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2603, cost: 41857.0\n",
      "Run 8, iteration: 2/100, moves: 481, cost: 41857.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2687, cost: 43559.0\n",
      "Run 9, iteration: 2/100, moves: 498, cost: 43408.0\n",
      "Run 9, iteration: 3/100, moves: 223, cost: 43408.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2176, cost: 42680.0\n",
      "Run 10, iteration: 2/100, moves: 1048, cost: 42550.0\n",
      "Run 10, iteration: 3/100, moves: 35, cost: 42550.0\n",
      "Best run was number 8\n",
      "  Runtime: 17.34s\n",
      "  Clusters: 19\n",
      "  Cluster sizes: 166-1382\n",
      "  Balance ratio: 8.33\n",
      "  Avg dissimilarity: 4.186\n",
      "  Composite score: 0.5291\n",
      "\n",
      "Testing combination 29: n_clusters=20, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1725, cost: 42905.0\n",
      "Run 1, iteration: 2/100, moves: 183, cost: 42905.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3017, cost: 42480.0\n",
      "Run 2, iteration: 2/100, moves: 154, cost: 42480.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3065, cost: 42239.0\n",
      "Run 3, iteration: 2/100, moves: 857, cost: 42002.0\n",
      "Run 3, iteration: 3/100, moves: 433, cost: 41803.0\n",
      "Run 3, iteration: 4/100, moves: 3, cost: 41803.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2995, cost: 41682.0\n",
      "Run 4, iteration: 2/100, moves: 385, cost: 41663.0\n",
      "Run 4, iteration: 3/100, moves: 377, cost: 41474.0\n",
      "Run 4, iteration: 4/100, moves: 61, cost: 41474.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2642, cost: 41844.0\n",
      "Run 5, iteration: 2/100, moves: 618, cost: 41844.0\n",
      "Best run was number 4\n",
      "  Runtime: 7.88s\n",
      "  Clusters: 20\n",
      "  Cluster sizes: 125-1480\n",
      "  Balance ratio: 11.84\n",
      "  Avg dissimilarity: 4.147\n",
      "  Composite score: 0.4832\n",
      "\n",
      "Testing combination 30: n_clusters=20, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1725, cost: 42905.0\n",
      "Run 1, iteration: 2/100, moves: 183, cost: 42905.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 3017, cost: 42480.0\n",
      "Run 2, iteration: 2/100, moves: 154, cost: 42480.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 3065, cost: 42239.0\n",
      "Run 3, iteration: 2/100, moves: 857, cost: 42002.0\n",
      "Run 3, iteration: 3/100, moves: 433, cost: 41803.0\n",
      "Run 3, iteration: 4/100, moves: 3, cost: 41803.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2995, cost: 41682.0\n",
      "Run 4, iteration: 2/100, moves: 385, cost: 41663.0\n",
      "Run 4, iteration: 3/100, moves: 377, cost: 41474.0\n",
      "Run 4, iteration: 4/100, moves: 61, cost: 41474.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2642, cost: 41844.0\n",
      "Run 5, iteration: 2/100, moves: 618, cost: 41844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 3117, cost: 43011.0\n",
      "Run 6, iteration: 2/100, moves: 1593, cost: 42683.0\n",
      "Run 6, iteration: 3/100, moves: 417, cost: 42493.0\n",
      "Run 6, iteration: 4/100, moves: 435, cost: 42276.0\n",
      "Run 6, iteration: 5/100, moves: 221, cost: 42276.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 3092, cost: 42561.0\n",
      "Run 7, iteration: 2/100, moves: 89, cost: 42561.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 4100, cost: 42300.0\n",
      "Run 8, iteration: 2/100, moves: 538, cost: 42137.0\n",
      "Run 8, iteration: 3/100, moves: 129, cost: 42137.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2737, cost: 41702.0\n",
      "Run 9, iteration: 2/100, moves: 13, cost: 41702.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1618, cost: 42483.0\n",
      "Run 10, iteration: 2/100, moves: 5, cost: 42483.0\n",
      "Best run was number 4\n",
      "  Runtime: 15.86s\n",
      "  Clusters: 20\n",
      "  Cluster sizes: 125-1480\n",
      "  Balance ratio: 11.84\n",
      "  Avg dissimilarity: 4.147\n",
      "  Composite score: 0.4832\n",
      "\n",
      "Testing combination 31: n_clusters=6, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 1, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 2, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 3, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 4, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 5, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.40s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 664-3337\n",
      "  Balance ratio: 5.03\n",
      "  Avg dissimilarity: 4.964\n",
      "  Composite score: 0.3448\n",
      "\n",
      "Testing combination 32: n_clusters=6, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 1, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 2, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 3, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 4, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 5, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 6, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 7, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 8, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 9, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2176, cost: 49639.0\n",
      "Run 10, iteration: 2/100, moves: 983, cost: 49639.0\n",
      "Best run was number 1\n",
      "  Runtime: 9.49s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 664-3337\n",
      "  Balance ratio: 5.03\n",
      "  Avg dissimilarity: 4.964\n",
      "  Composite score: 0.3448\n",
      "\n",
      "Testing combination 33: n_clusters=7, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 1, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 1, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 2, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 2, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 3, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 3, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 4, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 4, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 5, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.29s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 555-2988\n",
      "  Balance ratio: 5.38\n",
      "  Avg dissimilarity: 4.834\n",
      "  Composite score: 0.3780\n",
      "\n",
      "Testing combination 34: n_clusters=7, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 1, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 1, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 2, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 2, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 3, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 3, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 4, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 4, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 5, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 6, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 6, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 7, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 7, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 8, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 8, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 9, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 9, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2101, cost: 48393.0\n",
      "Run 10, iteration: 2/100, moves: 1421, cost: 48340.0\n",
      "Run 10, iteration: 3/100, moves: 28, cost: 48340.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.87s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 555-2988\n",
      "  Balance ratio: 5.38\n",
      "  Avg dissimilarity: 4.834\n",
      "  Composite score: 0.3780\n",
      "\n",
      "Testing combination 35: n_clusters=8, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 1, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 2, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 3, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 4, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 5, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.21s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 522-2904\n",
      "  Balance ratio: 5.56\n",
      "  Avg dissimilarity: 4.793\n",
      "  Composite score: 0.4051\n",
      "\n",
      "Testing combination 36: n_clusters=8, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 1, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 2, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 3, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 4, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 5, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 6, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 7, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 8, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 9, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1871, cost: 47926.0\n",
      "Run 10, iteration: 2/100, moves: 1246, cost: 47926.0\n",
      "Best run was number 1\n",
      "  Runtime: 12.63s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 522-2904\n",
      "  Balance ratio: 5.56\n",
      "  Avg dissimilarity: 4.793\n",
      "  Composite score: 0.4051\n",
      "\n",
      "Testing combination 37: n_clusters=9, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 1, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 1, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 2, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 2, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 3, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 3, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 4, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 4, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 5, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 5, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Best run was number 1\n",
      "  Runtime: 13.10s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 477-2643\n",
      "  Balance ratio: 5.54\n",
      "  Avg dissimilarity: 4.637\n",
      "  Composite score: 0.4433\n",
      "\n",
      "Testing combination 38: n_clusters=9, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 1, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 1, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 2, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 2, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 3, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 3, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 4, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 4, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 5, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 5, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 6, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 6, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 7, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 7, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 8, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 8, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 9, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 9, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1982, cost: 46746.0\n",
      "Run 10, iteration: 2/100, moves: 1581, cost: 46366.0\n",
      "Run 10, iteration: 3/100, moves: 401, cost: 46366.0\n",
      "Best run was number 1\n",
      "  Runtime: 34.74s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 477-2643\n",
      "  Balance ratio: 5.54\n",
      "  Avg dissimilarity: 4.637\n",
      "  Composite score: 0.4433\n",
      "\n",
      "Testing combination 39: n_clusters=10, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 1, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 1, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 2, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 2, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 3, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 3, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 4, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 4, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 5, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 5, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Best run was number 1\n",
      "  Runtime: 17.73s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 344-2507\n",
      "  Balance ratio: 7.29\n",
      "  Avg dissimilarity: 4.589\n",
      "  Composite score: 0.4080\n",
      "\n",
      "Testing combination 40: n_clusters=10, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 1, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 1, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 2, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 2, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 3, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 3, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 4, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 4, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 5, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 5, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 6, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 6, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 7, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 7, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 8, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 8, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 9, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 9, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1954, cost: 46248.0\n",
      "Run 10, iteration: 2/100, moves: 1546, cost: 45888.0\n",
      "Run 10, iteration: 3/100, moves: 445, cost: 45888.0\n",
      "Best run was number 1\n",
      "  Runtime: 33.73s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 344-2507\n",
      "  Balance ratio: 7.29\n",
      "  Avg dissimilarity: 4.589\n",
      "  Composite score: 0.4080\n",
      "\n",
      "Testing combination 41: n_clusters=11, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 1, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 1, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 2, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 2, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 3, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 3, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 4, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 4, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 5, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 5, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Best run was number 1\n",
      "  Runtime: 7.12s\n",
      "  Clusters: 11\n",
      "  Cluster sizes: 350-2041\n",
      "  Balance ratio: 5.83\n",
      "  Avg dissimilarity: 4.591\n",
      "  Composite score: 0.4724\n",
      "\n",
      "Testing combination 42: n_clusters=11, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 1, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 1, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 2, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 2, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 3, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 3, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 4, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 4, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 5, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 5, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 6, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 6, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 7, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 7, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 8, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 8, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 9, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 9, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2072, cost: 45977.0\n",
      "Run 10, iteration: 2/100, moves: 825, cost: 45915.0\n",
      "Run 10, iteration: 3/100, moves: 56, cost: 45915.0\n",
      "Best run was number 1\n",
      "  Runtime: 13.87s\n",
      "  Clusters: 11\n",
      "  Cluster sizes: 350-2041\n",
      "  Balance ratio: 5.83\n",
      "  Avg dissimilarity: 4.591\n",
      "  Composite score: 0.4724\n",
      "\n",
      "Testing combination 43: n_clusters=12, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 1, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 1, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 2, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 2, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 3, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 3, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 4, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 4, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 5, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 5, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Best run was number 1\n",
      "  Runtime: 7.64s\n",
      "  Clusters: 12\n",
      "  Cluster sizes: 336-1842\n",
      "  Balance ratio: 5.48\n",
      "  Avg dissimilarity: 4.515\n",
      "  Composite score: 0.5015\n",
      "\n",
      "Testing combination 44: n_clusters=12, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 1, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 1, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 2, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 2, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 3, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 3, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 4, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 4, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 5, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 5, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 6, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 6, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 7, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 7, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 8, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 8, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 9, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 9, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2058, cost: 45211.0\n",
      "Run 10, iteration: 2/100, moves: 715, cost: 45148.0\n",
      "Run 10, iteration: 3/100, moves: 77, cost: 45148.0\n",
      "Best run was number 1\n",
      "  Runtime: 15.44s\n",
      "  Clusters: 12\n",
      "  Cluster sizes: 336-1842\n",
      "  Balance ratio: 5.48\n",
      "  Avg dissimilarity: 4.515\n",
      "  Composite score: 0.5015\n",
      "\n",
      "Testing combination 45: n_clusters=13, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 1, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 2, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 3, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 4, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 5, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.43s\n",
      "  Clusters: 13\n",
      "  Cluster sizes: 336-1839\n",
      "  Balance ratio: 5.47\n",
      "  Avg dissimilarity: 4.462\n",
      "  Composite score: 0.5163\n",
      "\n",
      "Testing combination 46: n_clusters=13, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 1, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 2, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 3, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 4, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 5, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 6, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 7, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 8, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 9, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2250, cost: 44621.0\n",
      "Run 10, iteration: 2/100, moves: 308, cost: 44621.0\n",
      "Best run was number 1\n",
      "  Runtime: 12.80s\n",
      "  Clusters: 13\n",
      "  Cluster sizes: 336-1839\n",
      "  Balance ratio: 5.47\n",
      "  Avg dissimilarity: 4.462\n",
      "  Composite score: 0.5163\n",
      "\n",
      "Testing combination 47: n_clusters=14, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 1, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 2, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 3, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 4, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 5, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.80s\n",
      "  Clusters: 14\n",
      "  Cluster sizes: 233-1734\n",
      "  Balance ratio: 7.44\n",
      "  Avg dissimilarity: 4.430\n",
      "  Composite score: 0.4822\n",
      "\n",
      "Testing combination 48: n_clusters=14, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 1, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 2, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 3, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 4, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 5, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 6, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 7, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 8, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 9, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2215, cost: 44302.0\n",
      "Run 10, iteration: 2/100, moves: 314, cost: 44302.0\n",
      "Best run was number 1\n",
      "  Runtime: 13.57s\n",
      "  Clusters: 14\n",
      "  Cluster sizes: 233-1734\n",
      "  Balance ratio: 7.44\n",
      "  Avg dissimilarity: 4.430\n",
      "  Composite score: 0.4822\n",
      "\n",
      "Testing combination 49: n_clusters=15, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 1, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 1, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 2, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 2, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 3, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 3, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 4, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 4, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 5, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 5, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Best run was number 1\n",
      "  Runtime: 8.55s\n",
      "  Clusters: 15\n",
      "  Cluster sizes: 233-1683\n",
      "  Balance ratio: 7.22\n",
      "  Avg dissimilarity: 4.340\n",
      "  Composite score: 0.5049\n",
      "\n",
      "Testing combination 50: n_clusters=15, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 1, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 1, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 2, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 2, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 3, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 3, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 4, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 4, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 5, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 5, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 6, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 6, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 7, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 7, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 8, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 8, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 9, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 9, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2211, cost: 43709.0\n",
      "Run 10, iteration: 2/100, moves: 726, cost: 43405.0\n",
      "Run 10, iteration: 3/100, moves: 140, cost: 43405.0\n",
      "Best run was number 1\n",
      "  Runtime: 16.95s\n",
      "  Clusters: 15\n",
      "  Cluster sizes: 233-1683\n",
      "  Balance ratio: 7.22\n",
      "  Avg dissimilarity: 4.340\n",
      "  Composite score: 0.5049\n",
      "\n",
      "Testing combination 51: n_clusters=16, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 1, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 1, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 2, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 2, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 3, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 3, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 4, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 4, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 5, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 5, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Best run was number 1\n",
      "  Runtime: 8.68s\n",
      "  Clusters: 16\n",
      "  Cluster sizes: 233-1551\n",
      "  Balance ratio: 6.66\n",
      "  Avg dissimilarity: 4.279\n",
      "  Composite score: 0.5303\n",
      "\n",
      "Testing combination 52: n_clusters=16, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 1, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 1, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 2, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 2, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 3, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 3, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 4, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 4, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 5, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 5, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 6, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 6, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 7, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 7, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 8, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 8, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 9, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 9, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2284, cost: 43096.0\n",
      "Run 10, iteration: 2/100, moves: 718, cost: 42792.0\n",
      "Run 10, iteration: 3/100, moves: 138, cost: 42792.0\n",
      "Best run was number 1\n",
      "  Runtime: 17.50s\n",
      "  Clusters: 16\n",
      "  Cluster sizes: 233-1551\n",
      "  Balance ratio: 6.66\n",
      "  Avg dissimilarity: 4.279\n",
      "  Composite score: 0.5303\n",
      "\n",
      "Testing combination 53: n_clusters=17, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 1, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 1, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 2, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 2, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 3, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 3, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 4, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 4, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 5, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 5, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Best run was number 1\n",
      "  Runtime: 9.07s\n",
      "  Clusters: 17\n",
      "  Cluster sizes: 223-1520\n",
      "  Balance ratio: 6.82\n",
      "  Avg dissimilarity: 4.263\n",
      "  Composite score: 0.5357\n",
      "\n",
      "Testing combination 54: n_clusters=17, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 1, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 1, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 2, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 2, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 3, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 3, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 4, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 4, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 5, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 5, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 6, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 6, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 7, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 7, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 8, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 8, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 9, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 9, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2274, cost: 42749.0\n",
      "Run 10, iteration: 2/100, moves: 773, cost: 42630.0\n",
      "Run 10, iteration: 3/100, moves: 79, cost: 42630.0\n",
      "Best run was number 1\n",
      "  Runtime: 18.33s\n",
      "  Clusters: 17\n",
      "  Cluster sizes: 223-1520\n",
      "  Balance ratio: 6.82\n",
      "  Avg dissimilarity: 4.263\n",
      "  Composite score: 0.5357\n",
      "\n",
      "Testing combination 55: n_clusters=18, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 1, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 1, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 2, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 2, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 3, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 3, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 4, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 4, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 5, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 5, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Best run was number 1\n",
      "  Runtime: 9.44s\n",
      "  Clusters: 18\n",
      "  Cluster sizes: 223-1427\n",
      "  Balance ratio: 6.40\n",
      "  Avg dissimilarity: 4.223\n",
      "  Composite score: 0.5528\n",
      "\n",
      "Testing combination 56: n_clusters=18, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 1, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 1, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 2, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 2, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 3, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 3, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 4, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 4, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 5, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 5, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 6, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 6, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 7, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 7, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 8, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 8, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 9, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 9, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2175, cost: 42351.0\n",
      "Run 10, iteration: 2/100, moves: 823, cost: 42234.0\n",
      "Run 10, iteration: 3/100, moves: 78, cost: 42234.0\n",
      "Best run was number 1\n",
      "  Runtime: 19.86s\n",
      "  Clusters: 18\n",
      "  Cluster sizes: 223-1427\n",
      "  Balance ratio: 6.40\n",
      "  Avg dissimilarity: 4.223\n",
      "  Composite score: 0.5528\n",
      "\n",
      "Testing combination 57: n_clusters=19, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 1, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 1, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 2, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 2, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 3, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 3, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 4, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 4, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 5, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 5, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Best run was number 1\n",
      "  Runtime: 9.96s\n",
      "  Clusters: 19\n",
      "  Cluster sizes: 125-1338\n",
      "  Balance ratio: 10.70\n",
      "  Avg dissimilarity: 4.200\n",
      "  Composite score: 0.4882\n",
      "\n",
      "Testing combination 58: n_clusters=19, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 1, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 1, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 2, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 2, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 3, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 3, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 4, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 4, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 5, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 5, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 6, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 6, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 7, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 7, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 8, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 8, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 9, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 9, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2235, cost: 42121.0\n",
      "Run 10, iteration: 2/100, moves: 814, cost: 42005.0\n",
      "Run 10, iteration: 3/100, moves: 79, cost: 42005.0\n",
      "Best run was number 1\n",
      "  Runtime: 19.97s\n",
      "  Clusters: 19\n",
      "  Cluster sizes: 125-1338\n",
      "  Balance ratio: 10.70\n",
      "  Avg dissimilarity: 4.200\n",
      "  Composite score: 0.4882\n",
      "\n",
      "Testing combination 59: n_clusters=20, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 1, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 1, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 2, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 2, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 3, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 3, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 4, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 4, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 5, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 5, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Best run was number 1\n",
      "  Runtime: 10.20s\n",
      "  Clusters: 20\n",
      "  Cluster sizes: 124-1201\n",
      "  Balance ratio: 9.69\n",
      "  Avg dissimilarity: 4.152\n",
      "  Composite score: 0.5168\n",
      "\n",
      "Testing combination 60: n_clusters=20, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 1, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 1, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 2, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 2, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 3, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 3, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 4, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 4, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 5, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 5, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 6, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 6, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 7, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 7, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 8, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 8, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 9, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 9, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2250, cost: 41642.0\n",
      "Run 10, iteration: 2/100, moves: 813, cost: 41525.0\n",
      "Run 10, iteration: 3/100, moves: 77, cost: 41525.0\n",
      "Best run was number 1\n",
      "  Runtime: 23.40s\n",
      "  Clusters: 20\n",
      "  Cluster sizes: 124-1201\n",
      "  Balance ratio: 9.69\n",
      "  Avg dissimilarity: 4.152\n",
      "  Composite score: 0.5168\n",
      "\n",
      "=== K-MODES GRID SEARCH RESULTS ===\n",
      "Total successful runs: 60\n",
      "Best composite score: 0.5867\n",
      "Best parameters: {'cluster__init': 'Huang', 'cluster__n_clusters': 18, 'cluster__n_init': 5}\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "    n_clusters init_method  n_init  composite_score  min_cluster_size  \\\n",
      "24          18       Huang       5           0.5867               205   \n",
      "18          15       Huang       5           0.5840               313   \n",
      "19          15       Huang      10           0.5840               313   \n",
      "14          13       Huang       5           0.5594               366   \n",
      "15          13       Huang      10           0.5594               366   \n",
      "\n",
      "    max_cluster_size  avg_dissimilarity  \n",
      "24               916             4.2255  \n",
      "18              1150             4.3042  \n",
      "19              1150             4.3042  \n",
      "14              1489             4.3673  \n",
      "15              1489             4.3673  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== K-MODES PARAMETER GRID SEARCH ===\")\n",
    "\n",
    "kmodes_results = []\n",
    "best_params = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Custom evaluation metric for categorical clustering\n",
    "def evaluate_kmodes_clustering(X_encoded, labels, centroids):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    n_samples = len(labels)\n",
    "    cluster_sizes = pd.Series(labels).value_counts().sort_index()\n",
    "    min_cluster_size = cluster_sizes.min()\n",
    "    max_cluster_size = cluster_sizes.max()\n",
    "    cluster_balance = max_cluster_size / max(min_cluster_size, 1)\n",
    "\n",
    "    total_dissimilarity = 0\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        if cluster_mask.sum() > 1:\n",
    "            cluster_data = X_encoded[cluster_mask]\n",
    "            centroid = centroids[cluster_id]\n",
    "            for sample in cluster_data:\n",
    "                total_dissimilarity += np.sum(sample != centroid)\n",
    "    avg_dissimilarity = total_dissimilarity / max(n_samples, 1)\n",
    "\n",
    "    return {\n",
    "        'n_clusters': n_clusters,\n",
    "        'min_cluster_size': min_cluster_size,\n",
    "        'max_cluster_size': max_cluster_size,\n",
    "        'cluster_balance': cluster_balance,\n",
    "        'avg_dissimilarity': avg_dissimilarity\n",
    "    }\n",
    "\n",
    "print(f\"Starting grid search with {len(list(ParameterGrid(kmodes_param_grid)))} parameter combinations...\")\n",
    "\n",
    "for i, params in enumerate(ParameterGrid(kmodes_param_grid)):\n",
    "    print(f\"\\nTesting combination {i+1}: n_clusters={params['cluster__n_clusters']}, \"\n",
    "          f\"init={params['cluster__init']}, n_init={params['cluster__n_init']}\")\n",
    "    try:\n",
    "        kmodes_pipeline.set_params(**params)\n",
    "        t0 = time.perf_counter()\n",
    "        labels = kmodes_pipeline.fit_predict(X_categorical)\n",
    "        runtime = time.perf_counter() - t0\n",
    "\n",
    "        # Encode X using the same pipeline preprocessor to align with centroids' space\n",
    "        X_encoded = kmodes_pipeline.named_steps['preprocess'].transform(X_categorical)\n",
    "        X_encoded_arr = X_encoded.values if hasattr(X_encoded, 'values') else X_encoded\n",
    "\n",
    "        centroids = kmodes_pipeline.named_steps['cluster'].cluster_centroids_\n",
    "\n",
    "        eval_metrics = evaluate_kmodes_clustering(X_encoded_arr, labels, centroids)\n",
    "\n",
    "        # Normalized composite score\n",
    "        num_features = X_encoded_arr.shape[1] if hasattr(X_encoded_arr, 'shape') and len(X_encoded_arr.shape) == 2 else 1\n",
    "        norm_dissim = eval_metrics['avg_dissimilarity'] / max(1.0, float(num_features))\n",
    "        imbalance = max(0.0, (float(eval_metrics['cluster_balance']) - 1.0) / max(1.0, float(eval_metrics['n_clusters']) - 1.0))\n",
    "        alpha = 0.3\n",
    "        composite_score = (1.0 - norm_dissim) - alpha * imbalance\n",
    "\n",
    "        result = {\n",
    "            'n_clusters': params['cluster__n_clusters'],\n",
    "            'init_method': params['cluster__init'],\n",
    "            'n_init': params['cluster__n_init'],\n",
    "            'runtime_s': runtime,\n",
    "            'composite_score': composite_score,\n",
    "            **eval_metrics\n",
    "        }\n",
    "\n",
    "        kmodes_results.append(result)\n",
    "        if composite_score > best_score:\n",
    "            best_score = composite_score\n",
    "            best_params = params.copy()\n",
    "\n",
    "        print(f\"  Runtime: {runtime:.2f}s\")\n",
    "        print(f\"  Clusters: {eval_metrics['n_clusters']}\")\n",
    "        print(f\"  Cluster sizes: {eval_metrics['min_cluster_size']}-{eval_metrics['max_cluster_size']}\")\n",
    "        print(f\"  Balance ratio: {eval_metrics['cluster_balance']:.2f}\")\n",
    "        print(f\"  Avg dissimilarity: {eval_metrics['avg_dissimilarity']:.3f}\")\n",
    "        print(f\"  Composite score: {composite_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "df_kmodes_results = pd.DataFrame(kmodes_results)\n",
    "\n",
    "if not df_kmodes_results.empty:\n",
    "    print(f\"\\n=== K-MODES GRID SEARCH RESULTS ===\")\n",
    "    print(f\"Total successful runs: {len(df_kmodes_results)}\")\n",
    "    print(f\"Best composite score: {best_score:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    top_results = df_kmodes_results.nlargest(5, 'composite_score')\n",
    "    print(f\"\\nTop 5 parameter combinations:\")\n",
    "    print(top_results[['n_clusters', 'init_method', 'n_init', 'composite_score', \n",
    "                      'min_cluster_size', 'max_cluster_size', 'avg_dissimilarity']].round(4))\n",
    "else:\n",
    "    print(\"No successful K-Modes runs completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ccb95e",
   "metadata": {},
   "source": [
    "### K-Modes Results Analysis & Pattern Discovery\n",
    "\n",
    "We analyze the discovered categorical crime patterns and create detailed cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "321d4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES FINAL MODEL & PATTERN ANALYSIS ===\n",
      "Fitting final K-Modes model with best parameters...\n",
      "Best parameters: {'cluster__init': 'Huang', 'cluster__n_clusters': 18, 'cluster__n_init': 5}\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 2662, cost: 42696.0\n",
      "Run 1, iteration: 2/100, moves: 384, cost: 42696.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2947, cost: 43421.0\n",
      "Run 2, iteration: 2/100, moves: 617, cost: 43331.0\n",
      "Run 2, iteration: 3/100, moves: 67, cost: 43331.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 2732, cost: 43238.0\n",
      "Run 3, iteration: 2/100, moves: 324, cost: 43238.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 4065, cost: 42255.0\n",
      "Run 4, iteration: 2/100, moves: 612, cost: 42255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 2653, cost: 42739.0\n",
      "Run 5, iteration: 2/100, moves: 405, cost: 42604.0\n",
      "Run 5, iteration: 3/100, moves: 16, cost: 42604.0\n",
      "Best run was number 4\n",
      "✓ Final model fitted successfully\n",
      "Number of clusters: 18\n",
      "Cluster distribution:\n",
      "  Cluster 0: 797 samples (8.0%)\n",
      "  Cluster 1: 777 samples (7.8%)\n",
      "  Cluster 2: 916 samples (9.2%)\n",
      "  Cluster 3: 674 samples (6.7%)\n",
      "  Cluster 4: 816 samples (8.2%)\n",
      "  Cluster 5: 668 samples (6.7%)\n",
      "  Cluster 6: 531 samples (5.3%)\n",
      "  Cluster 7: 643 samples (6.4%)\n",
      "  Cluster 8: 309 samples (3.1%)\n",
      "  Cluster 9: 384 samples (3.8%)\n",
      "  Cluster 10: 205 samples (2.1%)\n",
      "  Cluster 11: 353 samples (3.5%)\n",
      "  Cluster 12: 727 samples (7.3%)\n",
      "  Cluster 13: 323 samples (3.2%)\n",
      "  Cluster 14: 384 samples (3.8%)\n",
      "  Cluster 15: 506 samples (5.1%)\n",
      "  Cluster 16: 582 samples (5.8%)\n",
      "  Cluster 17: 405 samples (4.0%)\n",
      "\n",
      "=== CATEGORICAL CRIME PATTERN PROFILES ===\n",
      "\n",
      "--- CLUSTER 0 PROFILE ---\n",
      "Size: 797 samples (8.0%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: OTHER OFFENSES RELATED TO THEFT\n",
      "  PREM_TYP_DESC: TRANSIT - NYC SUBWAY\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: E\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 35.6%\n",
      "  BRONX: 23.8%\n",
      "  MANHATTAN: 21.7%\n",
      "  QUEENS: 16.2%\n",
      "  STATEN ISLAND: 2.6%\n",
      "Top PREM_TYP_DESC:\n",
      "  TRANSIT - NYC SUBWAY: 52.8%\n",
      "  STREET: 15.7%\n",
      "  RESIDENCE - APT. HOUSE: 5.3%\n",
      "  RESIDENCE - PUBLIC HOUSING: 2.8%\n",
      "  OTHER: 2.6%\n",
      "Top OFNS_DESC:\n",
      "  OTHER OFFENSES RELATED TO THEFT: 35.5%\n",
      "  DANGEROUS WEAPONS: 6.1%\n",
      "  DANGEROUS DRUGS: 5.6%\n",
      "  ADMINISTRATIVE CODE: 4.6%\n",
      "  OFFENSES AGAINST PUBLIC ADMINI: 4.4%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 64.5%\n",
      "  EVENING: 13.6%\n",
      "  MORNING: 11.0%\n",
      "  NIGHT: 10.9%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.4%\n",
      "  1: 27.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.6%\n",
      "  1: 2.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 84.8%\n",
      "  Far: 8.9%\n",
      "  Mid: 6.3%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 70.9%\n",
      "  Low: 10.2%\n",
      "  Medium: 9.9%\n",
      "  High: 9.0%\n",
      "\n",
      "--- CLUSTER 1 PROFILE ---\n",
      "Size: 777 samples (7.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE-HOUSE\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 25-44\n",
      "Top BORO_NM:\n",
      "  QUEENS: 53.5%\n",
      "  BRONX: 19.0%\n",
      "  BROOKLYN: 11.1%\n",
      "  MANHATTAN: 8.5%\n",
      "  STATEN ISLAND: 7.9%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE-HOUSE: 34.6%\n",
      "  RESIDENCE - APT. HOUSE: 22.9%\n",
      "  STREET: 13.6%\n",
      "  RESIDENCE - PUBLIC HOUSING: 5.8%\n",
      "  HOMELESS SHELTER: 2.8%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 31.1%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 18.9%\n",
      "  FELONY ASSAULT: 13.0%\n",
      "  MISCELLANEOUS PENAL LAW: 6.6%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 5.4%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 48.0%\n",
      "  AFTERNOON: 20.8%\n",
      "  NIGHT: 16.3%\n",
      "  MORNING: 14.8%\n",
      "Top IS_WEEKEND:\n",
      "  0: 74.4%\n",
      "  1: 25.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 95.5%\n",
      "  1: 4.5%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 65.4%\n",
      "  Far: 21.5%\n",
      "  Near: 13.1%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 49.3%\n",
      "  Medium: 24.2%\n",
      "  Low: 14.2%\n",
      "  VeryHigh: 12.4%\n",
      "\n",
      "--- CLUSTER 2 PROFILE ---\n",
      "Size: 916 samples (9.2%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: MORNING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: U\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 45-64\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 34.9%\n",
      "  BRONX: 22.7%\n",
      "  BROOKLYN: 20.3%\n",
      "  QUEENS: 17.5%\n",
      "  STATEN ISLAND: 4.6%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 54.4%\n",
      "  RESIDENCE - APT. HOUSE: 11.2%\n",
      "  RESIDENCE-HOUSE: 10.5%\n",
      "  RESIDENCE - PUBLIC HOUSING: 6.7%\n",
      "  HOMELESS SHELTER: 1.9%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 44.5%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 12.0%\n",
      "  GRAND LARCENY: 8.7%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 6.0%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 5.5%\n",
      "Top TIME_BUCKET:\n",
      "  MORNING: 38.6%\n",
      "  EVENING: 22.3%\n",
      "  AFTERNOON: 21.6%\n",
      "  NIGHT: 17.5%\n",
      "Top IS_WEEKEND:\n",
      "  0: 82.9%\n",
      "  1: 17.1%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.0%\n",
      "  1: 4.0%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 60.3%\n",
      "  Near: 25.3%\n",
      "  Far: 14.4%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 46.4%\n",
      "  Medium: 18.4%\n",
      "  VeryHigh: 18.3%\n",
      "  High: 16.8%\n",
      "\n",
      "--- CLUSTER 3 PROFILE ---\n",
      "Size: 674 samples (6.7%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: U\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: D\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 37.2%\n",
      "  MANHATTAN: 25.5%\n",
      "  QUEENS: 21.8%\n",
      "  BRONX: 13.2%\n",
      "  STATEN ISLAND: 2.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 26.7%\n",
      "  STREET: 11.3%\n",
      "  DEPARTMENT STORE: 10.4%\n",
      "  DRUG STORE: 6.4%\n",
      "  RESIDENCE - APT. HOUSE: 6.4%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 63.9%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.1%\n",
      "  BURGLARY: 5.6%\n",
      "  GRAND LARCENY: 5.6%\n",
      "  VEHICLE AND TRAFFIC LAWS: 2.8%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 53.9%\n",
      "  AFTERNOON: 22.6%\n",
      "  MORNING: 12.5%\n",
      "  NIGHT: 11.1%\n",
      "Top IS_WEEKEND:\n",
      "  0: 73.7%\n",
      "  1: 26.3%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.0%\n",
      "  1: 3.0%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 72.1%\n",
      "  Mid: 15.6%\n",
      "  Far: 12.3%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 64.5%\n",
      "  High: 12.2%\n",
      "  Low: 11.7%\n",
      "  Medium: 11.6%\n",
      "\n",
      "--- CLUSTER 4 PROFILE ---\n",
      "Size: 816 samples (8.2%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: U\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: F\n",
      "  VIC_AGE_GROUP: 45-64\n",
      "Top BORO_NM:\n",
      "  BRONX: 59.4%\n",
      "  QUEENS: 16.9%\n",
      "  BROOKLYN: 14.6%\n",
      "  MANHATTAN: 4.8%\n",
      "  STATEN ISLAND: 4.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 43.3%\n",
      "  RESIDENCE - APT. HOUSE: 21.4%\n",
      "  RESIDENCE-HOUSE: 10.3%\n",
      "  RESIDENCE - PUBLIC HOUSING: 8.9%\n",
      "  HOMELESS SHELTER: 2.6%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 29.5%\n",
      "  PETIT LARCENY: 14.1%\n",
      "  GRAND LARCENY: 10.5%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.7%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 7.0%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 60.8%\n",
      "  EVENING: 17.4%\n",
      "  MORNING: 11.9%\n",
      "  NIGHT: 9.9%\n",
      "Top IS_WEEKEND:\n",
      "  0: 78.1%\n",
      "  1: 21.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.2%\n",
      "  1: 2.8%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 65.2%\n",
      "  Near: 18.0%\n",
      "  Far: 16.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 45.6%\n",
      "  Medium: 22.4%\n",
      "  High: 17.9%\n",
      "  VeryHigh: 14.1%\n",
      "\n",
      "--- CLUSTER 5 PROFILE ---\n",
      "Size: 668 samples (6.7%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 25-44\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 46.4%\n",
      "  BRONX: 21.0%\n",
      "  BROOKLYN: 20.1%\n",
      "  QUEENS: 9.3%\n",
      "  STATEN ISLAND: 3.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 55.1%\n",
      "  STREET: 13.8%\n",
      "  RESIDENCE - PUBLIC HOUSING: 6.4%\n",
      "  HOMELESS SHELTER: 2.7%\n",
      "  RESIDENCE-HOUSE: 2.5%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 33.4%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 16.9%\n",
      "  FELONY ASSAULT: 9.1%\n",
      "  PETIT LARCENY: 7.8%\n",
      "  GRAND LARCENY: 6.6%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 61.8%\n",
      "  NIGHT: 15.3%\n",
      "  EVENING: 13.3%\n",
      "  MORNING: 9.6%\n",
      "Top IS_WEEKEND:\n",
      "  0: 74.1%\n",
      "  1: 25.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.1%\n",
      "  1: 3.9%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 60.3%\n",
      "  Near: 31.9%\n",
      "  Far: 7.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 50.9%\n",
      "  VeryHigh: 19.2%\n",
      "  Medium: 15.3%\n",
      "  High: 14.7%\n",
      "\n",
      "--- CLUSTER 6 PROFILE ---\n",
      "Size: 531 samples (5.3%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: MORNING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: D\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 71.2%\n",
      "  QUEENS: 11.9%\n",
      "  BRONX: 8.3%\n",
      "  BROOKLYN: 5.6%\n",
      "  STATEN ISLAND: 3.0%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 38.4%\n",
      "  DRUG STORE: 13.2%\n",
      "  DEPARTMENT STORE: 12.1%\n",
      "  COMMERCIAL BUILDING: 5.1%\n",
      "  CLOTHING/BOUTIQUE: 4.5%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 74.8%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 5.3%\n",
      "  BURGLARY: 4.1%\n",
      "  GRAND LARCENY: 3.2%\n",
      "  OTHER OFFENSES RELATED TO THEFT: 1.3%\n",
      "Top TIME_BUCKET:\n",
      "  MORNING: 58.2%\n",
      "  AFTERNOON: 24.7%\n",
      "  EVENING: 10.7%\n",
      "  NIGHT: 6.4%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.7%\n",
      "  1: 27.3%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.0%\n",
      "  1: 3.0%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 71.6%\n",
      "  Mid: 20.7%\n",
      "  Far: 7.7%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 39.7%\n",
      "  VeryHigh: 29.6%\n",
      "  High: 15.8%\n",
      "  Low: 14.9%\n",
      "\n",
      "--- CLUSTER 7 PROFILE ---\n",
      "Size: 643 samples (6.4%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: F\n",
      "  VIC_AGE_GROUP: 45-64\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 30.0%\n",
      "  BROOKLYN: 26.3%\n",
      "  BRONX: 22.1%\n",
      "  QUEENS: 14.5%\n",
      "  STATEN ISLAND: 7.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 63.3%\n",
      "  RESIDENCE - PUBLIC HOUSING: 10.9%\n",
      "  RESIDENCE-HOUSE: 8.2%\n",
      "  STREET: 4.0%\n",
      "  HOMELESS SHELTER: 1.7%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 40.6%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 13.1%\n",
      "  PETIT LARCENY: 8.9%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 7.3%\n",
      "  MISCELLANEOUS PENAL LAW: 7.0%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 48.8%\n",
      "  MORNING: 18.4%\n",
      "  EVENING: 18.4%\n",
      "  NIGHT: 14.5%\n",
      "Top IS_WEEKEND:\n",
      "  0: 68.9%\n",
      "  1: 31.1%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 95.6%\n",
      "  1: 4.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 66.7%\n",
      "  Near: 20.5%\n",
      "  Far: 12.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 73.7%\n",
      "  High: 10.6%\n",
      "  VeryHigh: 10.1%\n",
      "  Low: 5.6%\n",
      "\n",
      "--- CLUSTER 8 PROFILE ---\n",
      "Size: 309 samples (3.1%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE-HOUSE\n",
      "  TIME_BUCKET: NIGHT\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: F\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  QUEENS: 64.4%\n",
      "  BRONX: 13.9%\n",
      "  BROOKLYN: 8.7%\n",
      "  STATEN ISLAND: 8.4%\n",
      "  MANHATTAN: 4.5%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE-HOUSE: 42.7%\n",
      "  RESIDENCE - APT. HOUSE: 18.8%\n",
      "  STREET: 11.7%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.5%\n",
      "  AIRPORT TERMINAL: 4.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 20.7%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 12.9%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 8.7%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 8.4%\n",
      "  FELONY ASSAULT: 8.4%\n",
      "Top TIME_BUCKET:\n",
      "  NIGHT: 50.8%\n",
      "  MORNING: 21.7%\n",
      "  AFTERNOON: 15.9%\n",
      "  EVENING: 11.7%\n",
      "Top IS_WEEKEND:\n",
      "  0: 60.2%\n",
      "  1: 39.8%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 93.9%\n",
      "  1: 6.1%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 65.0%\n",
      "  Far: 27.5%\n",
      "  Near: 7.4%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 74.1%\n",
      "  Medium: 12.9%\n",
      "  VeryHigh: 6.5%\n",
      "  High: 6.5%\n",
      "\n",
      "--- CLUSTER 9 PROFILE ---\n",
      "Size: 384 samples (3.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: D\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 45.1%\n",
      "  QUEENS: 21.4%\n",
      "  MANHATTAN: 15.9%\n",
      "  BRONX: 12.5%\n",
      "  STATEN ISLAND: 5.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 32.3%\n",
      "  DEPARTMENT STORE: 16.1%\n",
      "  COMMERCIAL BUILDING: 6.8%\n",
      "  RESIDENCE - APT. HOUSE: 5.7%\n",
      "  DRUG STORE: 5.5%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 69.5%\n",
      "  BURGLARY: 6.0%\n",
      "  GRAND LARCENY: 5.2%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 4.2%\n",
      "  DANGEROUS DRUGS: 2.3%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 74.0%\n",
      "  EVENING: 11.7%\n",
      "  MORNING: 9.4%\n",
      "  NIGHT: 4.9%\n",
      "Top IS_WEEKEND:\n",
      "  0: 75.0%\n",
      "  1: 25.0%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 84.4%\n",
      "  Far: 8.6%\n",
      "  Near: 7.0%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 59.4%\n",
      "  Low: 17.7%\n",
      "  VeryHigh: 13.0%\n",
      "  Medium: 9.9%\n",
      "\n",
      "--- CLUSTER 10 PROFILE ---\n",
      "Size: 205 samples (2.1%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: GRAND LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: D\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 82.4%\n",
      "  BRONX: 8.8%\n",
      "  QUEENS: 6.3%\n",
      "  BROOKLYN: 2.0%\n",
      "  STATEN ISLAND: 0.5%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 29.3%\n",
      "  STREET: 9.8%\n",
      "  CLOTHING/BOUTIQUE: 9.8%\n",
      "  DEPARTMENT STORE: 6.8%\n",
      "  TRANSIT - NYC SUBWAY: 6.3%\n",
      "Top OFNS_DESC:\n",
      "  GRAND LARCENY: 50.7%\n",
      "  PETIT LARCENY: 17.1%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.3%\n",
      "  ROBBERY: 5.4%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 3.4%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 78.0%\n",
      "  EVENING: 14.1%\n",
      "  NIGHT: 4.9%\n",
      "  MORNING: 2.9%\n",
      "Top IS_WEEKEND:\n",
      "  0: 74.1%\n",
      "  1: 25.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.6%\n",
      "  1: 3.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 86.8%\n",
      "  Mid: 10.2%\n",
      "  Far: 2.9%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 66.8%\n",
      "  VeryHigh: 17.1%\n",
      "  Low: 9.3%\n",
      "  Medium: 6.8%\n",
      "\n",
      "--- CLUSTER 11 PROFILE ---\n",
      "Size: 353 samples (3.5%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: MORNING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: U\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 45-64\n",
      "Top BORO_NM:\n",
      "  QUEENS: 66.3%\n",
      "  BROOKLYN: 15.9%\n",
      "  BRONX: 11.3%\n",
      "  STATEN ISLAND: 4.0%\n",
      "  MANHATTAN: 2.5%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 46.7%\n",
      "  RESIDENCE-HOUSE: 17.6%\n",
      "  STREET: 14.7%\n",
      "  RESIDENCE - PUBLIC HOUSING: 3.1%\n",
      "  COMMERCIAL BUILDING: 2.3%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 26.3%\n",
      "  GRAND LARCENY: 17.0%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 11.3%\n",
      "  PETIT LARCENY: 8.5%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 5.9%\n",
      "Top TIME_BUCKET:\n",
      "  MORNING: 51.8%\n",
      "  EVENING: 19.0%\n",
      "  AFTERNOON: 15.9%\n",
      "  NIGHT: 13.3%\n",
      "Top IS_WEEKEND:\n",
      "  0: 75.6%\n",
      "  1: 24.4%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.3%\n",
      "  1: 3.7%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 57.2%\n",
      "  Far: 29.2%\n",
      "  Near: 13.6%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 75.4%\n",
      "  VeryHigh: 10.2%\n",
      "  High: 10.2%\n",
      "  Low: 4.2%\n",
      "\n",
      "--- CLUSTER 12 PROFILE ---\n",
      "Size: 727 samples (7.3%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: VEHICLE AND TRAFFIC LAWS\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: E\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 41.7%\n",
      "  BRONX: 23.9%\n",
      "  QUEENS: 19.0%\n",
      "  MANHATTAN: 10.0%\n",
      "  STATEN ISLAND: 5.4%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 84.6%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.8%\n",
      "  RESIDENCE - APT. HOUSE: 3.0%\n",
      "  GROCERY/BODEGA: 1.1%\n",
      "  OTHER: 1.0%\n",
      "Top OFNS_DESC:\n",
      "  VEHICLE AND TRAFFIC LAWS: 41.3%\n",
      "  DANGEROUS DRUGS: 11.1%\n",
      "  DANGEROUS WEAPONS: 7.6%\n",
      "  FORGERY: 6.3%\n",
      "  OFFENSES AGAINST PUBLIC ADMINI: 5.9%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 59.6%\n",
      "  AFTERNOON: 17.2%\n",
      "  NIGHT: 14.3%\n",
      "  MORNING: 8.9%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.4%\n",
      "  1: 27.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.9%\n",
      "  1: 2.1%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 76.2%\n",
      "  Far: 13.2%\n",
      "  Near: 10.6%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 37.6%\n",
      "  Medium: 27.2%\n",
      "  Low: 18.8%\n",
      "  High: 16.4%\n",
      "\n",
      "--- CLUSTER 13 PROFILE ---\n",
      "Size: 323 samples (3.2%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: MORNING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 18-24\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 49.8%\n",
      "  BRONX: 18.6%\n",
      "  MANHATTAN: 18.6%\n",
      "  QUEENS: 11.5%\n",
      "  STATEN ISLAND: 1.5%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 52.9%\n",
      "  RESIDENCE - APT. HOUSE: 12.4%\n",
      "  RESIDENCE - PUBLIC HOUSING: 6.8%\n",
      "  HOMELESS SHELTER: 3.4%\n",
      "  RESIDENCE-HOUSE: 3.4%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 52.3%\n",
      "  FELONY ASSAULT: 8.4%\n",
      "  HARRASSMENT 2: 7.7%\n",
      "  ROBBERY: 5.9%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 5.6%\n",
      "Top TIME_BUCKET:\n",
      "  MORNING: 41.2%\n",
      "  AFTERNOON: 21.4%\n",
      "  NIGHT: 21.1%\n",
      "  EVENING: 16.4%\n",
      "Top IS_WEEKEND:\n",
      "  0: 74.3%\n",
      "  1: 25.7%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.0%\n",
      "  1: 4.0%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 75.5%\n",
      "  Mid: 13.0%\n",
      "  Far: 11.5%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 47.4%\n",
      "  VeryHigh: 20.4%\n",
      "  Medium: 19.8%\n",
      "  Low: 12.4%\n",
      "\n",
      "--- CLUSTER 14 PROFILE ---\n",
      "Size: 384 samples (3.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: DANGEROUS DRUGS\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: E\n",
      "  VIC_AGE_GROUP: UNKNOWN\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 58.3%\n",
      "  BRONX: 22.1%\n",
      "  QUEENS: 10.7%\n",
      "  BROOKLYN: 5.7%\n",
      "  STATEN ISLAND: 3.1%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 74.7%\n",
      "  RESIDENCE - APT. HOUSE: 4.9%\n",
      "  TRANSIT - NYC SUBWAY: 4.7%\n",
      "  RESIDENCE - PUBLIC HOUSING: 2.9%\n",
      "  OTHER: 2.1%\n",
      "Top OFNS_DESC:\n",
      "  DANGEROUS DRUGS: 35.4%\n",
      "  VEHICLE AND TRAFFIC LAWS: 9.1%\n",
      "  FORGERY: 7.0%\n",
      "  OTHER STATE LAWS: 6.0%\n",
      "  OFFENSES INVOLVING FRAUD: 4.7%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 54.9%\n",
      "  AFTERNOON: 24.0%\n",
      "  NIGHT: 14.6%\n",
      "  MORNING: 6.5%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.4%\n",
      "  1: 27.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 98.2%\n",
      "  1: 1.8%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 78.4%\n",
      "  Mid: 14.1%\n",
      "  Far: 7.6%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 56.0%\n",
      "  Medium: 16.4%\n",
      "  Low: 15.1%\n",
      "  VeryHigh: 12.5%\n",
      "\n",
      "--- CLUSTER 15 PROFILE ---\n",
      "Size: 506 samples (5.1%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: F\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: F\n",
      "  VIC_AGE_GROUP: 25-44\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 48.0%\n",
      "  BRONX: 23.5%\n",
      "  MANHATTAN: 15.0%\n",
      "  QUEENS: 11.3%\n",
      "  STATEN ISLAND: 2.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 61.1%\n",
      "  RESIDENCE - PUBLIC HOUSING: 9.3%\n",
      "  STREET: 5.9%\n",
      "  RESIDENCE-HOUSE: 5.7%\n",
      "  HOMELESS SHELTER: 3.4%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 43.7%\n",
      "  FELONY ASSAULT: 12.5%\n",
      "  HARRASSMENT 2: 12.1%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 7.9%\n",
      "  MISCELLANEOUS PENAL LAW: 6.7%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 48.4%\n",
      "  MORNING: 17.6%\n",
      "  AFTERNOON: 17.0%\n",
      "  NIGHT: 17.0%\n",
      "Top IS_WEEKEND:\n",
      "  0: 71.1%\n",
      "  1: 28.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 95.5%\n",
      "  1: 4.5%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 58.7%\n",
      "  Mid: 29.6%\n",
      "  Far: 11.7%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 36.8%\n",
      "  Medium: 26.7%\n",
      "  VeryHigh: 18.6%\n",
      "  Low: 18.0%\n",
      "\n",
      "--- CLUSTER 16 PROFILE ---\n",
      "Size: 582 samples (5.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: GRAND LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 1\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: U\n",
      "  SUSP_AGE_GROUP: UNKNOWN\n",
      "  VIC_SEX: M\n",
      "  VIC_AGE_GROUP: 25-44\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 43.0%\n",
      "  QUEENS: 20.8%\n",
      "  BRONX: 19.8%\n",
      "  MANHATTAN: 13.7%\n",
      "  STATEN ISLAND: 2.7%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 64.3%\n",
      "  RESIDENCE - APT. HOUSE: 9.6%\n",
      "  RESIDENCE-HOUSE: 5.2%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.1%\n",
      "  BAR/NIGHT CLUB: 1.9%\n",
      "Top OFNS_DESC:\n",
      "  GRAND LARCENY: 29.7%\n",
      "  PETIT LARCENY: 17.7%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 11.5%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 10.1%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 5.8%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 57.7%\n",
      "  NIGHT: 19.1%\n",
      "  AFTERNOON: 15.5%\n",
      "  MORNING: 7.7%\n",
      "Top IS_WEEKEND:\n",
      "  1: 70.6%\n",
      "  0: 29.4%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.9%\n",
      "  1: 2.1%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 63.2%\n",
      "  Near: 24.2%\n",
      "  Far: 12.5%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 48.8%\n",
      "  Medium: 22.0%\n",
      "  VeryHigh: 16.3%\n",
      "  Low: 12.9%\n",
      "\n",
      "--- CLUSTER 17 PROFILE ---\n",
      "Size: 405 samples (4.0%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: M\n",
      "  SUSP_AGE_GROUP: 25-44\n",
      "  VIC_SEX: F\n",
      "  VIC_AGE_GROUP: 25-44\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 61.5%\n",
      "  BRONX: 20.2%\n",
      "  QUEENS: 7.4%\n",
      "  MANHATTAN: 7.4%\n",
      "  STATEN ISLAND: 3.5%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 35.1%\n",
      "  RESIDENCE - APT. HOUSE: 27.9%\n",
      "  RESIDENCE - PUBLIC HOUSING: 17.8%\n",
      "  RESIDENCE-HOUSE: 5.9%\n",
      "  OTHER: 2.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 35.8%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 16.5%\n",
      "  FELONY ASSAULT: 9.9%\n",
      "  MISCELLANEOUS PENAL LAW: 9.6%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 5.2%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 50.6%\n",
      "  MORNING: 22.2%\n",
      "  AFTERNOON: 18.5%\n",
      "  NIGHT: 8.6%\n",
      "Top IS_WEEKEND:\n",
      "  0: 68.9%\n",
      "  1: 31.1%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 94.6%\n",
      "  1: 5.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 77.8%\n",
      "  Near: 11.9%\n",
      "  Far: 10.4%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 60.7%\n",
      "  Medium: 17.3%\n",
      "  VeryHigh: 13.3%\n",
      "  High: 8.6%\n",
      "\n",
      "Sample cluster profiles:\n",
      "   cluster  size top_boro_nm     top_prem_typ_desc  \\\n",
      "0        0   797    BROOKLYN  TRANSIT - NYC SUBWAY   \n",
      "1        1   777      QUEENS       RESIDENCE-HOUSE   \n",
      "2        2   916   MANHATTAN                STREET   \n",
      "3        3   674    BROOKLYN           CHAIN STORE   \n",
      "4        4   816       BRONX                STREET   \n",
      "\n",
      "                     top_ofns_desc top_time_bucket top_is_weekend  \\\n",
      "0  OTHER OFFENSES RELATED TO THEFT       AFTERNOON              0   \n",
      "1                    HARRASSMENT 2         EVENING              0   \n",
      "2                    PETIT LARCENY         MORNING              0   \n",
      "3                    PETIT LARCENY         EVENING              0   \n",
      "4                    HARRASSMENT 2       AFTERNOON              0   \n",
      "\n",
      "  top_is_holiday top_metro_distance_bin top_poi_density_score_bin  \n",
      "0              0                   Near                  VeryHigh  \n",
      "1              0                    Mid                      High  \n",
      "2              0                    Mid                       Low  \n",
      "3              0                   Near                  VeryHigh  \n",
      "4              0                    Mid                       Low  \n"
     ]
    }
   ],
   "source": [
    "if 'df_kmodes_results' in locals() and not df_kmodes_results.empty:\n",
    "    print(\"=== K-MODES FINAL MODEL & PATTERN ANALYSIS ===\")\n",
    "    \n",
    "    print(f\"Fitting final K-Modes model with best parameters...\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    final_kmodes_pipeline = Pipeline([\n",
    "        ('preprocess', CategoricalPreprocessor(handle_missing='drop')),\n",
    "        ('cluster', KModes(\n",
    "            n_clusters=best_params['cluster__n_clusters'],\n",
    "            init=best_params['cluster__init'],\n",
    "            n_init=best_params['cluster__n_init'],\n",
    "            verbose=1,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    final_labels = final_kmodes_pipeline.fit_predict(X_categorical)\n",
    "    final_centroids = final_kmodes_pipeline.named_steps['cluster'].cluster_centroids_\n",
    "\n",
    "    # Feature names aligned with the preprocessor output\n",
    "    try:\n",
    "        feature_names = final_kmodes_pipeline.named_steps['preprocess'].get_feature_names_out().tolist()\n",
    "    except Exception:\n",
    "        feature_names = list(X_categorical.columns)\n",
    "    feature_names = [f for f in feature_names]\n",
    "\n",
    "    df_kmodes_labeled = df_kmodes.copy()\n",
    "    df_kmodes_labeled['cluster'] = final_labels\n",
    "    \n",
    "    print(f\"Final model fitted successfully\")\n",
    "    print(f\"Number of clusters: {len(np.unique(final_labels))}\")\n",
    "    print(f\"Cluster distribution:\")\n",
    "    cluster_counts = pd.Series(final_labels).value_counts().sort_index()\n",
    "    for cluster_id, count in cluster_counts.items():\n",
    "        print(f\"  Cluster {cluster_id}: {count} samples ({(count/len(final_labels))*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n=== CATEGORICAL CRIME PATTERN PROFILES ===\")\n",
    "    \n",
    "    cluster_profiles = []\n",
    "    \n",
    "    for cluster_id in sorted(np.unique(final_labels)):\n",
    "        cluster_mask = final_labels == cluster_id\n",
    "        cluster_data = df_kmodes_labeled[cluster_mask]\n",
    "        cluster_size = cluster_mask.sum()\n",
    "        \n",
    "        print(f\"\\n--- CLUSTER {cluster_id} PROFILE ---\")\n",
    "        print(f\"Size: {cluster_size} samples ({(cluster_size/len(final_labels))*100:.1f}%)\")\n",
    "        \n",
    "        centroid = final_centroids[cluster_id]\n",
    "        print(f\"Centroid pattern:\")\n",
    "        for i, feature in enumerate(feature_names[:len(centroid)]):\n",
    "            print(f\"  {feature}: {centroid[i]}\")\n",
    "        \n",
    "        summary_cols = [\n",
    "            'BORO_NM', 'PREM_TYP_DESC', 'OFNS_DESC',\n",
    "            'TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY',\n",
    "            'METRO_DISTANCE_BIN', 'POI_DENSITY_SCORE_BIN',\n",
    "        ]\n",
    "        summary_cols = [c for c in summary_cols if c in cluster_data.columns]\n",
    "        for col in summary_cols:\n",
    "            dist = cluster_data[col].value_counts(normalize=True).head(5)\n",
    "            print(f\"Top {col}:\")\n",
    "            for val, pct in dist.items():\n",
    "                print(f\"  {val}: {pct*100:.1f}%\")\n",
    "        \n",
    "        profile = {\n",
    "            'cluster': int(cluster_id),\n",
    "            'size': int(cluster_size),\n",
    "        }\n",
    "        for col in summary_cols:\n",
    "            top_val = cluster_data[col].value_counts().idxmax()\n",
    "            profile[f'top_{col.lower()}'] = str(top_val)\n",
    "        cluster_profiles.append(profile)\n",
    "    \n",
    "    df_cluster_profiles = pd.DataFrame(cluster_profiles)\n",
    "    print(\"\\nSample cluster profiles:\")\n",
    "    print(df_cluster_profiles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9b84a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserve K-Modes best params/score for later summary\n",
    "if 'best_params' in globals() and 'best_score' in globals():\n",
    "    kmodes_best_params = best_params.copy()\n",
    "    kmodes_best_score = float(best_score)\n",
    "else:\n",
    "    kmodes_best_params = None\n",
    "    kmodes_best_score = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248adafa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Police-Focused Crime Intelligence Analysis\n",
    "\n",
    "This section transforms the K-Modes clustering results into **actionable intelligence** for law enforcement operations. We create operational crime profiles, tactical recommendations, and priority assessment for police deployment.\n",
    "\n",
    "## Crime Pattern Intelligence Reports\n",
    "\n",
    "Transform abstract clustering results into concrete operational insights for police commanders and patrol units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d49b32",
   "metadata": {},
   "source": [
    "### Operational cluster summaries (concise tables)\n",
    "\n",
    "The tables below summarize clusters for police operations without narrative: top patterns and cross-tabs by borough, crime type, time, premises, weekend/holiday, and demographics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dc4af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ops] Building ops from df_cluster_profiles\n",
      "[ops] Inferring crime_count from size\n",
      "[ops] Estimating concentration_score from labeled data\n",
      "Top clusters (by priority, volume, concentration):\n",
      " cluster_id    priority  crime_count primary_borough                   primary_crime       primary_premises primary_time_bucket\n",
      "          2        HIGH          916       MANHATTAN                   PETIT LARCENY                 STREET             MORNING\n",
      "          4        HIGH          816           BRONX                   HARRASSMENT 2                 STREET           AFTERNOON\n",
      "          0        HIGH          797        BROOKLYN OTHER OFFENSES RELATED TO THEFT   TRANSIT - NYC SUBWAY           AFTERNOON\n",
      "          1        HIGH          777          QUEENS                   HARRASSMENT 2        RESIDENCE-HOUSE             EVENING\n",
      "         12 MEDIUM-HIGH          727        BROOKLYN        VEHICLE AND TRAFFIC LAWS                 STREET             EVENING\n",
      "          3 MEDIUM-HIGH          674        BROOKLYN                   PETIT LARCENY            CHAIN STORE             EVENING\n",
      "          5 MEDIUM-HIGH          668       MANHATTAN                   HARRASSMENT 2 RESIDENCE - APT. HOUSE           AFTERNOON\n",
      "          7      MEDIUM          643       MANHATTAN                   HARRASSMENT 2 RESIDENCE - APT. HOUSE           AFTERNOON\n",
      "         16      MEDIUM          582        BROOKLYN                   GRAND LARCENY                 STREET             EVENING\n",
      "          6      MEDIUM          531       MANHATTAN                   PETIT LARCENY            CHAIN STORE             MORNING\n",
      "         15      MEDIUM          506        BROOKLYN    ASSAULT 3 & RELATED OFFENSES RESIDENCE - APT. HOUSE             EVENING\n",
      "         17         LOW          405        BROOKLYN                   HARRASSMENT 2                 STREET             EVENING\n",
      "\n",
      "Borough x Priority\n",
      "priority       HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "BORO_NM                                       \n",
      "BRONX          0.46  0.17    0.19         0.18\n",
      "BROOKLYN       0.25  0.25    0.25         0.25\n",
      "MANHATTAN      0.24  0.23    0.30         0.23\n",
      "QUEENS         0.39  0.29    0.15         0.16\n",
      "STATEN ISLAND  0.38  0.22    0.21         0.18\n",
      "\n",
      "Top Crime Types x Priority (top 12)\n",
      "priority                         HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "OFNS_DESC                                                       \n",
      "ASSAULT 3 & RELATED OFFENSES     0.26  0.29    0.32         0.12\n",
      "CRIMINAL MISCHIEF & RELATED OF   0.39  0.23    0.23         0.15\n",
      "DANGEROUS DRUGS                  0.17  0.52    0.03         0.28\n",
      "FELONY ASSAULT                   0.36  0.24    0.26         0.14\n",
      "GRAND LARCENY                    0.27  0.30    0.30         0.12\n",
      "HARRASSMENT 2                    0.36  0.23    0.24         0.17\n",
      "MISCELLANEOUS PENAL LAW          0.29  0.28    0.29         0.14\n",
      "OFF. AGNST PUB ORD SENSBLTY &    0.31  0.27    0.32         0.10\n",
      "OTHER                            0.35  0.26    0.12         0.27\n",
      "OTHER OFFENSES RELATED TO THEFT  0.92  0.04    0.03         0.02\n",
      "PETIT LARCENY                    0.30  0.18    0.28         0.24\n",
      "ROBBERY                          0.38  0.24    0.19         0.19\n",
      "VEHICLE AND TRAFFIC LAWS         0.20  0.11    0.06         0.63\n",
      "\n",
      "Premises x Priority (top 12)\n",
      "priority                    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "PREM_TYP_DESC                                              \n",
      "CHAIN STORE                 0.05  0.32    0.34         0.29\n",
      "COMMERCIAL BUILDING         0.21  0.31    0.24         0.24\n",
      "DEPARTMENT STORE            0.10  0.33    0.27         0.30\n",
      "DRUG STORE                  0.06  0.20    0.45         0.29\n",
      "GROCERY/BODEGA              0.29  0.29    0.13         0.29\n",
      "HOMELESS SHELTER            0.38  0.23    0.25         0.15\n",
      "OTHER                       0.32  0.26    0.21         0.21\n",
      "RESIDENCE - APT. HOUSE      0.23  0.20    0.37         0.20\n",
      "RESIDENCE - PUBLIC HOUSING  0.34  0.25    0.25         0.16\n",
      "RESIDENCE-HOUSE             0.54  0.27    0.13         0.05\n",
      "STREET                      0.36  0.24    0.15         0.26\n",
      "TRANSIT - NYC SUBWAY        0.82  0.08    0.05         0.06\n",
      "\n",
      "Time Bucket x Priority\n",
      "priority     HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "TIME_BUCKET                                 \n",
      "AFTERNOON    0.40  0.23    0.18         0.20\n",
      "EVENING      0.27  0.21    0.24         0.28\n",
      "MORNING      0.33  0.27    0.29         0.11\n",
      "NIGHT        0.31  0.27    0.22         0.19\n",
      "\n",
      "Weekend x Priority\n",
      "priority    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "IS_WEEKEND                                 \n",
      "0           0.36  0.24    0.19         0.21\n",
      "1           0.26  0.23    0.31         0.19\n",
      "\n",
      "Holiday x Priority\n",
      "priority    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "IS_HOLIDAY                                 \n",
      "0           0.33  0.24    0.23         0.21\n",
      "1           0.33  0.26    0.23         0.18\n",
      "\n",
      "Suspect Sex x Priority\n",
      "priority  HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "SUSP_SEX                                 \n",
      "F         0.27  0.20    0.33         0.19\n",
      "M         0.27  0.30    0.21         0.22\n",
      "U         0.47  0.14    0.20         0.19\n",
      "\n",
      "Suspect Age x Priority\n",
      "priority        HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "SUSP_AGE_GROUP                                 \n",
      "18-24           0.28  0.25    0.21         0.26\n",
      "25-44           0.30  0.32    0.19         0.18\n",
      "45-64           0.27  0.30    0.23         0.20\n",
      "65+             0.25  0.22    0.32         0.22\n",
      "<18             0.32  0.23    0.25         0.19\n",
      "UNKNOWN         0.37  0.16    0.25         0.22\n",
      "\n",
      "Victim Sex x Priority\n",
      "priority  HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "VIC_SEX                                  \n",
      "D         0.11  0.30    0.30         0.30\n",
      "E         0.34  0.25    0.02         0.40\n",
      "F         0.33  0.23    0.35         0.08\n",
      "L         0.37  0.37    0.09         0.16\n",
      "M         0.44  0.20    0.17         0.19\n",
      "\n",
      "Victim Age x Priority\n",
      "priority       HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "VIC_AGE_GROUP                                 \n",
      "18-24          0.28  0.34    0.26         0.12\n",
      "25-44          0.33  0.20    0.30         0.17\n",
      "45-64          0.51  0.19    0.24         0.05\n",
      "65+            0.48  0.19    0.19         0.13\n",
      "<18            0.41  0.22    0.21         0.16\n",
      "UNKNOWN        0.23  0.27    0.15         0.34\n"
     ]
    }
   ],
   "source": [
    "# Build operational dataframe and produce concise police-focused tables\n",
    "# Helper: mode with safe fallback\n",
    "_def = lambda s, default='Unknown': (s.mode().iloc[0] if not s.mode().empty else default)\n",
    "\n",
    "# Build ops\n",
    "ops = None\n",
    "try:\n",
    "    if 'df_operational' in locals() and isinstance(df_operational, pd.DataFrame) and not df_operational.empty:\n",
    "        print(\"[ops] Using provided df_operational\")\n",
    "        ops = df_operational.copy()\n",
    "    elif 'df_cluster_profiles' in locals() and isinstance(df_cluster_profiles, pd.DataFrame) and not df_cluster_profiles.empty:\n",
    "        print(\"[ops] Building ops from df_cluster_profiles\")\n",
    "        # Derive a minimal ops from profiles\n",
    "        dfp = df_cluster_profiles.copy()\n",
    "        rename_map = {\n",
    "            'cluster': 'cluster_id',\n",
    "            'top_ofns_desc': 'primary_crime',\n",
    "            'top_boro_nm': 'primary_borough',\n",
    "            'top_prem_typ_desc': 'primary_premises',\n",
    "            'top_time_bucket': 'primary_time_bucket',\n",
    "            'crime_count': 'crime_count',\n",
    "            'concentration_score': 'concentration_score'\n",
    "        }\n",
    "        for col in list(rename_map):\n",
    "            if col not in dfp.columns:\n",
    "                if col == 'crime_count' and 'size' in dfp.columns:\n",
    "                    print(\"[ops] Inferring crime_count from size\")\n",
    "                    dfp['crime_count'] = dfp['size']\n",
    "                elif col == 'concentration_score' and 'composite_score' in dfp.columns:\n",
    "                    print(\"[ops] Inferring concentration_score from composite_score\")\n",
    "                    dfp['concentration_score'] = dfp['composite_score']\n",
    "                elif col == 'top_ofns_desc' and 'OFNS_DESC' in dfp.columns:\n",
    "                    print(\"[ops] Inferring top_ofns_desc from OFNS_DESC\")\n",
    "                    dfp['top_ofns_desc'] = dfp['OFNS_DESC']\n",
    "                elif col == 'top_boro_nm' and 'BORO_NM' in dfp.columns:\n",
    "                    print(\"[ops] Inferring top_boro_nm from BORO_NM\")\n",
    "                    dfp['top_boro_nm'] = dfp['BORO_NM']\n",
    "                elif col == 'top_prem_typ_desc' and 'PREM_TYP_DESC' in dfp.columns:\n",
    "                    print(\"[ops] Inferring top_prem_typ_desc from PREM_TYP_DESC\")\n",
    "                    dfp['top_prem_typ_desc'] = dfp['PREM_TYP_DESC']\n",
    "                elif col == 'top_time_bucket' and 'TIME_BUCKET' in dfp.columns:\n",
    "                    print(\"[ops] Inferring top_time_bucket from TIME_BUCKET\")\n",
    "                    dfp['top_time_bucket'] = dfp['TIME_BUCKET']\n",
    "        ops = dfp.rename(columns={k: v for k, v in rename_map.items() if k in dfp.columns})\n",
    "    elif 'df_kmodes_labeled' in locals() and isinstance(df_kmodes_labeled, pd.DataFrame) and not df_kmodes_labeled.empty:\n",
    "        print(\"[ops] Building ops from df_kmodes_labeled (groupby)\")\n",
    "        g = df_kmodes_labeled.groupby('cluster')\n",
    "        rows = []\n",
    "        for cid, grp in g:\n",
    "            rows.append({\n",
    "                'cluster_id': int(cid),\n",
    "                'primary_crime': _def(grp['OFNS_DESC']) if 'OFNS_DESC' in grp.columns else 'Unknown',\n",
    "                'primary_borough': _def(grp['BORO_NM']) if 'BORO_NM' in grp.columns else 'Unknown',\n",
    "                'primary_premises': _def(grp['PREM_TYP_DESC']) if 'PREM_TYP_DESC' in grp.columns else 'Unknown',\n",
    "                'primary_time_bucket': _def(grp['TIME_BUCKET']) if 'TIME_BUCKET' in grp.columns else 'Unknown',\n",
    "                'crime_count': int(len(grp))\n",
    "            })\n",
    "        ops = pd.DataFrame(rows)\n",
    "    else:\n",
    "        print(\"[ops] No sources available; creating empty DataFrame\")\n",
    "        ops = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(\"[ops] Exception while building ops:\", e)\n",
    "    ops = pd.DataFrame()\n",
    "\n",
    "# Normalize to canonical column names if imported schema differs\n",
    "if not ops.empty:\n",
    "    def ensure_col(dst, target, candidates, transform=None, default_val=np.nan):\n",
    "        if target in dst.columns:\n",
    "            return\n",
    "        for c in candidates:\n",
    "            if c in dst.columns:\n",
    "                print(f\"[ops] Filling missing column '{target}' from '{c}'\")\n",
    "                dst[target] = dst[c] if transform is None else transform(dst[c])\n",
    "                return\n",
    "        print(f\"[ops] Column '{target}' not found; filling default\")\n",
    "        dst[target] = default_val\n",
    "\n",
    "    ensure_col(ops, 'cluster_id', ['cluster', 'cid'], transform=lambda s: s.astype('Int64'))\n",
    "    ensure_col(ops, 'primary_borough', ['BORO_NM', 'borough', 'top_boro_nm'])\n",
    "    ensure_col(ops, 'primary_crime', ['OFNS_DESC', 'crime_type', 'top_ofns_desc'])\n",
    "    ensure_col(ops, 'primary_premises', ['PREM_TYP_DESC', 'premises', 'top_prem_typ_desc'])\n",
    "    ensure_col(ops, 'primary_time_bucket', ['TIME_BUCKET', 'time_bucket', 'top_time_bucket'])\n",
    "\n",
    "ops['crime_count'] = ops.get('crime_count', pd.Series(dtype=int)).fillna(0).astype(int)\n",
    "if 'concentration_score' not in ops.columns:\n",
    "    if 'df_kmodes_labeled' in locals() and not df_kmodes_labeled.empty and 'cluster' in df_kmodes_labeled.columns:\n",
    "        print(\"[ops] Estimating concentration_score from labeled data\")\n",
    "        conc_vals = []\n",
    "        for _, r in ops.iterrows():\n",
    "            cid = r.get('cluster_id', None)\n",
    "            if pd.isna(cid): conc_vals.append(np.nan); continue\n",
    "            grp = df_kmodes_labeled[df_kmodes_labeled['cluster'] == cid]\n",
    "            if grp.empty or 'OFNS_DESC' not in grp.columns:\n",
    "                conc_vals.append(np.nan); continue\n",
    "            top_frac = grp['OFNS_DESC'].value_counts(normalize=True).max()\n",
    "            conc_vals.append(top_frac)\n",
    "        ops['concentration_score'] = conc_vals\n",
    "    else:\n",
    "        print(\"[ops] concentration_score unavailable; filling NaN\")\n",
    "        ops['concentration_score'] = np.nan\n",
    "\n",
    "# Priority tiers by crime_count with concentration as tiebreaker\n",
    "q80 = ops['crime_count'].quantile(0.8) if len(ops) else 0\n",
    "q60 = ops['crime_count'].quantile(0.6) if len(ops) else 0\n",
    "q40 = ops['crime_count'].quantile(0.4) if len(ops) else 0\n",
    "\n",
    "def pr_rank(row):\n",
    "    if row['crime_count'] >= q80: return 'HIGH'\n",
    "    if row['crime_count'] >= q60: return 'MEDIUM-HIGH'\n",
    "    if row['crime_count'] >= q40: return 'MEDIUM'\n",
    "    return 'LOW'\n",
    "\n",
    "if not ops.empty:\n",
    "    ops['priority'] = ops.apply(pr_rank, axis=1)\n",
    "else:\n",
    "    ops['priority'] = []\n",
    "\n",
    "# Print concise tables\n",
    "if not ops.empty:\n",
    "    display_cols = ['cluster_id','priority','crime_count','primary_borough','primary_crime','primary_premises','primary_time_bucket']\n",
    "    missing = [c for c in display_cols if c not in ops.columns]\n",
    "    for c in missing:\n",
    "        print(f\"[ops] Missing display col '{c}', filling with 'Unknown'\")\n",
    "        ops[c] = 'Unknown'\n",
    "\n",
    "    # Use ordered categorical to sort priority correctly\n",
    "    pr_order = pd.CategoricalDtype(['HIGH','MEDIUM-HIGH','MEDIUM','LOW'], ordered=True)\n",
    "    ops['priority_ord'] = ops['priority'].astype(pr_order)\n",
    "    top_clusters = ops.sort_values(['priority_ord','crime_count','concentration_score'], ascending=[True, False, False])\n",
    "    top_clusters = top_clusters[display_cols].head(12)\n",
    "    print('Top clusters (by priority, volume, concentration):')\n",
    "    print(top_clusters.to_string(index=False))\n",
    "\n",
    "    if 'df_kmodes_labeled' in locals() and not df_kmodes_labeled.empty:\n",
    "        pr_map = dict(zip(ops['cluster_id'], ops['priority']))\n",
    "        base = df_kmodes_labeled.copy()\n",
    "        base['priority'] = base['cluster'].map(pr_map).fillna('LOW')\n",
    "\n",
    "        def ctab(col, top_k=None, title=None):\n",
    "            if col not in base.columns:\n",
    "                print(f\"[ops] Skipping crosstab; missing '{col}'\")\n",
    "                return None\n",
    "            s = base[col].astype(str)\n",
    "            if top_k:\n",
    "                top = s.value_counts().head(top_k).index\n",
    "                s = s.where(s.isin(top), 'OTHER')\n",
    "            t = pd.crosstab(s, base['priority'], normalize='index').round(2)\n",
    "            if title:\n",
    "                print('\\n'+title)\n",
    "            print(t)\n",
    "            return t\n",
    "\n",
    "        borough_priority = ctab('BORO_NM', title='Borough x Priority')\n",
    "        crime_priority = ctab('OFNS_DESC', top_k=12, title='Top Crime Types x Priority (top 12)')\n",
    "        premises_priority = ctab('PREM_TYP_DESC', top_k=12, title='Premises x Priority (top 12)')\n",
    "        time_priority = ctab('TIME_BUCKET', title='Time Bucket x Priority')\n",
    "        weekend_priority = ctab('IS_WEEKEND', title='Weekend x Priority')\n",
    "        holiday_priority = ctab('IS_HOLIDAY', title='Holiday x Priority')\n",
    "        suspsex_priority = ctab('SUSP_SEX', top_k=6, title='Suspect Sex x Priority')\n",
    "        suspage_priority = ctab('SUSP_AGE_GROUP', top_k=6, title='Suspect Age x Priority')\n",
    "        vicsex_priority = ctab('VIC_SEX', top_k=6, title='Victim Sex x Priority')\n",
    "        vicage_priority = ctab('VIC_AGE_GROUP', top_k=6, title='Victim Age x Priority')\n",
    "\n",
    "        ops_export = ops.copy()\n",
    "        export_cols = display_cols + ['concentration_score']\n",
    "        ops_export = ops_export[export_cols]\n",
    "else:\n",
    "    print('No operational data available for concise tables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e06f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\police_operational_intelligence_enriched.csv\n",
      "JSON saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\executive_crime_summary_enriched.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    csv_path = os.path.join(output_dir, 'police_operational_intelligence_enriched.csv')\n",
    "    json_path = os.path.join(output_dir, 'executive_crime_summary_enriched.json')\n",
    "\n",
    "    if 'ops_export' in locals() and not ops_export.empty:\n",
    "        ops_export.to_csv(csv_path, index=False)\n",
    "        print(f'CSV saved: {csv_path}')\n",
    "\n",
    "    if 'executive_summary' in locals() and isinstance(executive_summary, dict):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(executive_summary, f, indent=2)\n",
    "        print(f'JSON saved: {json_path}')\n",
    "except Exception as e:\n",
    "    print('Export skipped/error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acaf8b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing X_categorical; skipping re-binning.\n"
     ]
    }
   ],
   "source": [
    "if 'X_categorical' not in globals():\n",
    "    column_binner = ColumnBinner(binner_config, suffix=\"_BIN\", fill_unknown=\"Unknown\")\n",
    "    X_categorical = column_binner.fit_transform(base_df)\n",
    "    created_bins_km_context = getattr(column_binner, 'created_bins_', [])\n",
    "    print(f\"Created {len(created_bins_km_context)} binned features.\")\n",
    "else:\n",
    "    print(\"Using existing X_categorical; skipping re-binning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "610886c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot created with 12 columns.\n"
     ]
    }
   ],
   "source": [
    "# Snapshot for K-Modes reference (read-only copy)\n",
    "X_categorical_kmodes_ref = X_categorical.copy()\n",
    "created_bins_kmodes_ref = list(created_bins_km_context) if 'created_bins_km_context' in globals() else []\n",
    "print(f\"Snapshot created with {len(X_categorical_kmodes_ref.columns)} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbc90f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUTIVE CRIME INTELLIGENCE DASHBOARD\n",
      "============================================================\n",
      "\n",
      "EXECUTIVE SUMMARY\n",
      "   Total crimes analyzed: 10,000\n",
      "   Crime patterns identified: 18\n",
      "   High priority patterns: 4\n",
      "   High priority crime volume: 3,306 (33.1%)\n",
      "\n",
      "KEY INSIGHTS\n",
      "   Most concentrated pattern: PETIT LARCENY - MANHATTAN - CHAIN STORE - MORNING - Weekday - SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "      - 75% concentration, 531 crimes\n",
      "   Highest volume pattern: PETIT LARCENY - MANHATTAN - STREET - MORNING - Weekday - SUSP: U UNKNOWN | VIC: M 45-64\n",
      "      - 916 crimes (9.2% of total)\n",
      "\n",
      "BOROUGH CRIME INTELLIGENCE\n",
      "   BRONX:\n",
      "      - Total: 2,230 | High priority: 1,031 (46.2%)\n",
      "   QUEENS:\n",
      "      - Total: 2,160 | High priority: 843 (39.0%)\n",
      "   BROOKLYN:\n",
      "      - Total: 2,747 | High priority: 675 (24.6%)\n",
      "   MANHATTAN:\n",
      "      - Total: 2,447 | High priority: 598 (24.4%)\n",
      "   STATEN ISLAND:\n",
      "      - Total: 416 | High priority: 159 (38.2%)\n",
      "\n",
      "IMMEDIATE ACTION ITEMS\n",
      "   Deploy immediately:\n",
      "      1. OTHER OFFENSES RELATED TO THEFT - BROOKLYN - TRANSIT - NYC SUBWAY - AFTERNOON - Weekday - SUSP: M 25-44 | VIC: E UNKNOWN\n",
      "         - 797 crimes, 36% concentration\n",
      "      2. HARRASSMENT 2 - QUEENS - RESIDENCE-HOUSE - EVENING - Weekday - SUSP: M 25-44 | VIC: M 25-44\n",
      "         - 777 crimes, 31% concentration\n",
      "      3. PETIT LARCENY - MANHATTAN - STREET - MORNING - Weekday - SUSP: U UNKNOWN | VIC: M 45-64\n",
      "         - 916 crimes, 45% concentration\n",
      "   Plan enhanced operations:\n",
      "      1. PETIT LARCENY - BROOKLYN - CHAIN STORE - EVENING - Weekday - SUSP: U UNKNOWN | VIC: D UNKNOWN\n",
      "         - 674 crimes\n",
      "      2. HARRASSMENT 2 - MANHATTAN - RESIDENCE - APT. HOUSE - AFTERNOON - Weekday - SUSP: M UNKNOWN | VIC: M 25-44\n",
      "         - 668 crimes\n",
      "\n",
      "RESOURCE ALLOCATION RECOMMENDATION\n",
      "   Focus 80% of resources on 7 patterns\n",
      "   Targeting 5,375 crimes (53.8% of total volume)\n",
      "   Expected result: maximum impact with focused deployment\n",
      "\n",
      "Executive summary saved to: executive_crime_summary.json\n",
      "All police intelligence reports saved to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n"
     ]
    }
   ],
   "source": [
    "# === POLICE EXECUTIVE DASHBOARD ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTIVE CRIME INTELLIGENCE DASHBOARD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def _safe_mode(s, default=\"Unknown\"):\n",
    "    try:\n",
    "        m = s.mode(dropna=True)\n",
    "        return m.iloc[0] if not m.empty else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "# Build a compact signature using cluster-level top attributes\n",
    "# Falls back to row fields when detailed data isn't available\n",
    "\n",
    "def signature_for_cluster(cluster_id=None, row=None, base_df=None):\n",
    "    # Initialize fields from row fallbacks\n",
    "    crime = (row.get('primary_crime') if isinstance(row, dict) else getattr(row, 'primary_crime', None)) or \"Unknown\"\n",
    "    borough = (row.get('primary_borough') if isinstance(row, dict) else getattr(row, 'primary_borough', None)) or \"Unknown\"\n",
    "    premises = (row.get('primary_premises') if isinstance(row, dict) else getattr(row, 'primary_premises', None)) or None\n",
    "    time_bucket = (row.get('primary_time_bucket') if isinstance(row, dict) else getattr(row, 'primary_time_bucket', None)) or None\n",
    "\n",
    "    weekend_tok = None\n",
    "    holiday_tok = None\n",
    "    susp_sex = None\n",
    "    susp_age = None\n",
    "    vic_sex = None\n",
    "    vic_age = None\n",
    "\n",
    "    if base_df is not None and cluster_id is not None and 'cluster' in base_df.columns:\n",
    "        g = base_df[base_df['cluster'] == cluster_id]\n",
    "        if not g.empty:\n",
    "            # Prefer actual cluster modes when available\n",
    "            if 'OFNS_DESC' in g.columns:\n",
    "                crime = _safe_mode(g['OFNS_DESC'], crime)\n",
    "            if 'BORO_NM' in g.columns:\n",
    "                borough = _safe_mode(g['BORO_NM'], borough)\n",
    "            if 'PREM_TYP_DESC' in g.columns:\n",
    "                premises = _safe_mode(g['PREM_TYP_DESC'], premises)\n",
    "            if 'TIME_BUCKET' in g.columns:\n",
    "                time_bucket = _safe_mode(g['TIME_BUCKET'], time_bucket)\n",
    "            if 'IS_WEEKEND' in g.columns:\n",
    "                w = _safe_mode(g['IS_WEEKEND'], None)\n",
    "                if pd.isna(w):\n",
    "                    weekend_tok = None\n",
    "                else:\n",
    "                    weekend_tok = 'Weekend' if str(w).lower() in ['1', 'true', 'yes'] else 'Weekday'\n",
    "            if 'IS_HOLIDAY' in g.columns:\n",
    "                h = _safe_mode(g['IS_HOLIDAY'], None)\n",
    "                if pd.isna(h):\n",
    "                    holiday_tok = None\n",
    "                else:\n",
    "                    holiday_tok = 'Holiday' if str(h).lower() in ['1', 'true', 'yes'] else None\n",
    "            if 'SUSP_SEX' in g.columns:\n",
    "                susp_sex = _safe_mode(g['SUSP_SEX'], None)\n",
    "            if 'SUSP_AGE_GROUP' in g.columns:\n",
    "                susp_age = _safe_mode(g['SUSP_AGE_GROUP'], None)\n",
    "            if 'VIC_SEX' in g.columns:\n",
    "                vic_sex = _safe_mode(g['VIC_SEX'], None)\n",
    "            if 'VIC_AGE_GROUP' in g.columns:\n",
    "                vic_age = _safe_mode(g['VIC_AGE_GROUP'], None)\n",
    "\n",
    "    tokens = [str(crime), str(borough)]\n",
    "    if premises and str(premises) != 'Unknown':\n",
    "        tokens.append(str(premises))\n",
    "    if time_bucket and str(time_bucket) != 'Unknown':\n",
    "        tokens.append(str(time_bucket))\n",
    "    if weekend_tok:\n",
    "        tokens.append(weekend_tok)\n",
    "    if holiday_tok:\n",
    "        tokens.append(holiday_tok)\n",
    "\n",
    "    demo_parts = []\n",
    "    if susp_sex or susp_age:\n",
    "        demo_parts.append(f\"SUSP: {susp_sex or '?'} {susp_age or ''}\".strip())\n",
    "    if vic_sex or vic_age:\n",
    "        demo_parts.append(f\"VIC: {vic_sex or '?'} {vic_age or ''}\".strip())\n",
    "    if demo_parts:\n",
    "        tokens.append(\" | \".join(demo_parts))\n",
    "\n",
    "    return \" - \".join([t for t in tokens if t and str(t).strip()])\n",
    "\n",
    "# Prefer df_operational; fallback to previously built 'ops'; then to saved enriched CSV\n",
    "ops_df = None\n",
    "if 'df_operational' in locals() and isinstance(df_operational, pd.DataFrame) and not df_operational.empty:\n",
    "    ops_df = df_operational.copy()\n",
    "elif 'ops' in locals() and isinstance(ops, pd.DataFrame) and not ops.empty:\n",
    "    ops_df = ops.copy()\n",
    "else:\n",
    "    try:\n",
    "        export_dir = os.path.join(project_root, 'JupyterOutputs', 'Final')\n",
    "        csv_path = os.path.join(export_dir, 'police_operational_intelligence_enriched.csv')\n",
    "        if os.path.exists(csv_path):\n",
    "            ops_df = pd.read_csv(csv_path)\n",
    "    except Exception as _e:\n",
    "        ops_df = None\n",
    "\n",
    "# Shared selector with fallback\n",
    "_get_key_pattern = lambda df, key, fallback_col: (\n",
    "    df.loc[df[key].astype(float).idxmax()] if key in df.columns and pd.api.types.is_numeric_dtype(df[key]) and df[key].notna().any()\n",
    "    else df.loc[df[fallback_col].idxmax()] if fallback_col in df.columns and df[fallback_col].notna().any()\n",
    "    else df.iloc[0]\n",
    ")\n",
    "\n",
    "if ops_df is not None and not ops_df.empty:\n",
    "    # Ensure expected columns exist\n",
    "    for col in ['cluster_id','primary_crime','primary_borough','primary_premises','primary_time_bucket','crime_count']:\n",
    "        if col not in ops_df.columns:\n",
    "            ops_df[col] = np.nan\n",
    "\n",
    "    # Executive summary statistics\n",
    "    total_crimes = int(ops_df.get('crime_count', pd.Series(dtype=int)).sum()) if 'crime_count' in ops_df.columns else int(len(ops_df))\n",
    "    high_priority_patterns = int((ops_df.get('priority', pd.Series([])) == 'HIGH').sum()) if 'priority' in ops_df.columns else 0\n",
    "    high_priority_crimes = int(ops_df[ops_df.get('priority','') == 'HIGH']['crime_count'].sum()) if 'crime_count' in ops_df.columns and 'priority' in ops_df.columns else 0\n",
    "\n",
    "    # Identify key patterns using shared helper\n",
    "    most_concentrated = _get_key_pattern(ops_df, 'concentration_score', 'crime_count')\n",
    "    highest_volume = _get_key_pattern(ops_df, 'crime_count', 'crime_count')\n",
    "\n",
    "    # Base dataframe for cluster-level modes\n",
    "    base_df = df_kmodes_labeled.copy() if 'df_kmodes_labeled' in locals() and isinstance(df_kmodes_labeled, pd.DataFrame) and not df_kmodes_labeled.empty else None\n",
    "\n",
    "    # Compact signatures\n",
    "    mc_sig = signature_for_cluster(cluster_id=int(most_concentrated.get('cluster_id')) if 'cluster_id' in most_concentrated else None,\n",
    "                                   row=most_concentrated.to_dict() if hasattr(most_concentrated, 'to_dict') else most_concentrated,\n",
    "                                   base_df=base_df)\n",
    "    hv_sig = signature_for_cluster(cluster_id=int(highest_volume.get('cluster_id')) if 'cluster_id' in highest_volume else None,\n",
    "                                   row=highest_volume.to_dict() if hasattr(highest_volume, 'to_dict') else highest_volume,\n",
    "                                   base_df=base_df)\n",
    "\n",
    "    print(f\"\\nEXECUTIVE SUMMARY\")\n",
    "    print(f\"   Total crimes analyzed: {total_crimes:,}\")\n",
    "    print(f\"   Crime patterns identified: {len(ops_df)}\")\n",
    "    print(f\"   High priority patterns: {high_priority_patterns}\")\n",
    "    if total_crimes > 0 and high_priority_crimes:\n",
    "        print(f\"   High priority crime volume: {high_priority_crimes:,} ({(high_priority_crimes/total_crimes)*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nKEY INSIGHTS\")\n",
    "    if 'concentration_score' in ops_df.columns:\n",
    "        conc_pct = most_concentrated.get('concentration_score')\n",
    "        conc_str = f\"{float(conc_pct):.0%}\" if pd.notna(conc_pct) else \"N/A\"\n",
    "        print(f\"   Most concentrated pattern: {mc_sig}\")\n",
    "        print(f\"      - {conc_str} concentration, {int(most_concentrated.get('crime_count', 0)):,} crimes\")\n",
    "    else:\n",
    "        print(f\"   Key pattern: {mc_sig}\")\n",
    "        print(f\"      - {int(most_concentrated.get('crime_count', 0)):,} crimes\")\n",
    "    hv_pct = (highest_volume.get('crime_count', 0) / total_crimes * 100) if total_crimes else 0\n",
    "    print(f\"   Highest volume pattern: {hv_sig}\")\n",
    "    print(f\"      - {int(highest_volume.get('crime_count', 0)):,} crimes ({hv_pct:.1f}% of total)\")\n",
    "\n",
    "    # Borough-level intelligence\n",
    "    if base_df is not None and 'BORO_NM' in base_df.columns:\n",
    "        print(f\"\\nBOROUGH CRIME INTELLIGENCE\")\n",
    "        # Map priority to labeled data\n",
    "        pr_map = dict(zip(ops_df['cluster_id'], ops_df.get('priority', '')))\n",
    "        cluster_data_all = base_df.copy()\n",
    "        cluster_data_all['priority'] = cluster_data_all['cluster'].map(pr_map)\n",
    "\n",
    "        borough_intelligence = cluster_data_all.groupby('BORO_NM').agg({\n",
    "            'cluster': 'count',\n",
    "            'priority': lambda x: (x == 'HIGH').sum()\n",
    "        }).rename(columns={'cluster': 'total_crimes', 'priority': 'high_priority_crimes'})\n",
    "        borough_intelligence['high_priority_pct'] = (borough_intelligence['high_priority_crimes'] /\n",
    "                                                     borough_intelligence['total_crimes'] * 100).round(1)\n",
    "        borough_intelligence = borough_intelligence.sort_values('high_priority_crimes', ascending=False)\n",
    "        for borough, stats in borough_intelligence.iterrows():\n",
    "            print(f\"   {borough}:\")\n",
    "            print(f\"      - Total: {int(stats['total_crimes']):,} | High priority: {int(stats['high_priority_crimes']):,} ({stats['high_priority_pct']:.1f}%)\")\n",
    "\n",
    "    # Operational recommendations summary\n",
    "    print(f\"\\nIMMEDIATE ACTION ITEMS\")\n",
    "    high_priority_df = ops_df[ops_df.get('priority','') == 'HIGH'].head(3) if 'priority' in ops_df.columns else pd.DataFrame()\n",
    "    if not high_priority_df.empty:\n",
    "        print(\"   Deploy immediately:\")\n",
    "        for i, (_, pattern) in enumerate(high_priority_df.iterrows(), 1):\n",
    "            sig = signature_for_cluster(cluster_id=int(pattern.get('cluster_id')) if 'cluster_id' in pattern else None,\n",
    "                                        row=pattern.to_dict(), base_df=base_df)\n",
    "            print(f\"      {i}. {sig}\")\n",
    "            extra = []\n",
    "            if 'crime_count' in pattern:\n",
    "                extra.append(f\"{int(pattern['crime_count']):,} crimes\")\n",
    "            if 'concentration_score' in pattern and pd.notna(pattern['concentration_score']):\n",
    "                extra.append(f\"{float(pattern['concentration_score']):.0%} concentration\")\n",
    "            if extra:\n",
    "                print(f\"         - {', '.join(extra)}\")\n",
    "\n",
    "    medium_priority_df = ops_df[ops_df.get('priority','').isin(['MEDIUM-HIGH', 'MEDIUM'])].head(2) if 'priority' in ops_df.columns else pd.DataFrame()\n",
    "    if not medium_priority_df.empty:\n",
    "        print(\"   Plan enhanced operations:\")\n",
    "        for i, (_, pattern) in enumerate(medium_priority_df.iterrows(), 1):\n",
    "            sig = signature_for_cluster(cluster_id=int(pattern.get('cluster_id')) if 'cluster_id' in pattern else None,\n",
    "                                        row=pattern.to_dict(), base_df=base_df)\n",
    "            print(f\"      {i}. {sig}\")\n",
    "            if 'crime_count' in pattern:\n",
    "                print(f\"         - {int(pattern['crime_count']):,} crimes\")\n",
    "\n",
    "    # Resource allocation recommendation\n",
    "    print(f\"\\nRESOURCE ALLOCATION RECOMMENDATION\")\n",
    "    focus_mask = ops_df.get('priority','').isin(['HIGH', 'MEDIUM-HIGH']) if 'priority' in ops_df.columns else pd.Series([False]*len(ops_df))\n",
    "    total_budget_crimes = int(ops_df.loc[focus_mask, 'crime_count'].sum()) if 'crime_count' in ops_df.columns else 0\n",
    "    print(f\"   Focus 80% of resources on {int(focus_mask.sum())} patterns\")\n",
    "    if total_crimes:\n",
    "        print(f\"   Targeting {total_budget_crimes:,} crimes ({(total_budget_crimes/total_crimes)*100:.1f}% of total volume)\")\n",
    "    print(f\"   Expected result: maximum impact with focused deployment\")\n",
    "\n",
    "    # Structured details for the two key patterns (where available)\n",
    "    def structured_details(row_obj):\n",
    "        cid = int(row_obj.get('cluster_id')) if 'cluster_id' in row_obj else None\n",
    "        # Derive modes from base_df if possible\n",
    "        details = {}\n",
    "        if base_df is not None and cid is not None:\n",
    "            g = base_df[base_df['cluster'] == cid]\n",
    "            if not g.empty:\n",
    "                details.update({\n",
    "                    'crime_type': _safe_mode(g['OFNS_DESC']) if 'OFNS_DESC' in g.columns else row_obj.get('primary_crime', 'Unknown'),\n",
    "                    'borough': _safe_mode(g['BORO_NM']) if 'BORO_NM' in g.columns else row_obj.get('primary_borough', 'Unknown'),\n",
    "                    'premises': _safe_mode(g['PREM_TYP_DESC']) if 'PREM_TYP_DESC' in g.columns else row_obj.get('primary_premises', 'Unknown'),\n",
    "                    'time_bucket': _safe_mode(g['TIME_BUCKET']) if 'TIME_BUCKET' in g.columns else row_obj.get('primary_time_bucket', 'Unknown'),\n",
    "                    'is_weekend_mode': bool(str(_safe_mode(g['IS_WEEKEND'], 'False')).lower() in ['1','true','yes']) if 'IS_WEEKEND' in g.columns else None,\n",
    "                    'is_holiday_mode': bool(str(_safe_mode(g['IS_HOLIDAY'], 'False')).lower() in ['1','true','yes']) if 'IS_HOLIDAY' in g.columns else None,\n",
    "                    'suspect_sex_mode': _safe_mode(g['SUSP_SEX']) if 'SUSP_SEX' in g.columns else None,\n",
    "                    'suspect_age_mode': _safe_mode(g['SUSP_AGE_GROUP']) if 'SUSP_AGE_GROUP' in g.columns else None,\n",
    "                    'victim_sex_mode': _safe_mode(g['VIC_SEX']) if 'VIC_SEX' in g.columns else None,\n",
    "                    'victim_age_mode': _safe_mode(g['VIC_AGE_GROUP']) if 'VIC_AGE_GROUP' in g.columns else None,\n",
    "                })\n",
    "        else:\n",
    "            details.update({\n",
    "                'crime_type': row_obj.get('primary_crime', 'Unknown'),\n",
    "                'borough': row_obj.get('primary_borough', 'Unknown'),\n",
    "                'premises': row_obj.get('primary_premises', 'Unknown'),\n",
    "                'time_bucket': row_obj.get('primary_time_bucket', 'Unknown'),\n",
    "            })\n",
    "        # Always add volume metrics\n",
    "        details['volume'] = int(row_obj.get('crime_count', 0))\n",
    "        if 'concentration_score' in row_obj and pd.notna(row_obj['concentration_score']):\n",
    "            details['concentration'] = f\"{float(row_obj['concentration_score']):.0%}\"\n",
    "        return details\n",
    "\n",
    "    most_concentrated = most_concentrated if isinstance(most_concentrated, dict) else most_concentrated.to_dict()\n",
    "    highest_volume = highest_volume if isinstance(highest_volume, dict) else highest_volume.to_dict()\n",
    "    mc_details = structured_details(most_concentrated)\n",
    "    hv_details = structured_details(highest_volume)\n",
    "\n",
    "    # Create executive summary for export\n",
    "    executive_summary = {\n",
    "        'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        'total_crimes_analyzed': int(total_crimes),\n",
    "        'patterns_identified': int(len(ops_df)),\n",
    "        'high_priority_patterns': int(high_priority_patterns),\n",
    "        'high_priority_crime_percentage': round((high_priority_crimes/total_crimes)*100, 1) if total_crimes else 0.0,\n",
    "        'most_concentrated_pattern_signature': mc_sig,\n",
    "        'highest_volume_pattern_signature': hv_sig,\n",
    "        'most_concentrated_pattern': mc_details,\n",
    "        'highest_volume_pattern': hv_details,\n",
    "        'immediate_deployment_needed': high_priority_patterns > 0,\n",
    "        'resource_focus_patterns': int(focus_mask.sum()) if isinstance(focus_mask, pd.Series) else 0\n",
    "    }\n",
    "\n",
    "    # Save executive summary\n",
    "    with open(os.path.join(output_dir, 'executive_crime_summary.json'), 'w') as f:\n",
    "        json.dump(executive_summary, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"\\nExecutive summary saved to: executive_crime_summary.json\")\n",
    "    print(f\"All police intelligence reports saved to: {output_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"No operational data available for executive dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "919a4a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\executive_crime_summary_enriched.json\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "_def = object()\n",
    "\n",
    "def _get(name, default=None):\n",
    "    return globals().get(name, default)\n",
    "\n",
    "def _as_mapping(x):\n",
    "    return dict(x) if isinstance(x, Mapping) else {}\n",
    "\n",
    "def _to_int(x, default=None):\n",
    "    try:\n",
    "        if x is None: return default\n",
    "        if isinstance(x, (int,)):\n",
    "            return int(x)\n",
    "        if isinstance(x, float) and math.isfinite(x):\n",
    "            return int(x)\n",
    "        if isinstance(x, str) and x.strip():\n",
    "            return int(float(x))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return default\n",
    "\n",
    "def _to_pct(x, default=None):\n",
    "    try:\n",
    "        if x is None: return default\n",
    "        if isinstance(x, (int, float)) and math.isfinite(x):\n",
    "            return round(float(x), 1)\n",
    "        s = str(x).strip()\n",
    "        if s.endswith('%'):\n",
    "            return round(float(s[:-1]), 1)\n",
    "        return round(float(s), 1)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _build_signature(p):\n",
    "    if not p:\n",
    "        return None\n",
    "    crime = p.get('crime_type') or p.get('CRIME') or p.get('OFNS_DESC') or p.get('PD_DESC') or p.get('LAW_CAT') or p.get('LAW_CAT_CD')\n",
    "    borough = p.get('borough') or p.get('BORO_NM') or p.get('BOROUGH') or p.get('BORO')\n",
    "    premises = p.get('premises') or p.get('LOC_OF_OCCUR') or p.get('PREM_TYP_DESC') or p.get('LOCATION')\n",
    "    timeb = p.get('time_bucket') or p.get('TIME_BUCKET') or p.get('TIME') or p.get('TIME_BIN')\n",
    "    is_weekend = bool(p.get('is_weekend_mode')) if 'is_weekend_mode' in p else bool(p.get('WEEKEND'))\n",
    "    wkd = 'Weekend' if is_weekend else 'Weekday'\n",
    "    susp_sex = p.get('suspect_sex_mode') or p.get('SUSP_SEX') or p.get('SUSPECT_SEX') or 'U'\n",
    "    susp_age = p.get('suspect_age_mode') or p.get('SUSP_AGE') or p.get('SUSPECT_AGE') or 'UNKNOWN'\n",
    "    vic_sex = p.get('victim_sex_mode') or p.get('VIC_SEX') or p.get('VICTIM_SEX') or 'U'\n",
    "    vic_age = p.get('victim_age_mode') or p.get('VIC_AGE') or p.get('VICTIM_AGE') or 'UNKNOWN'\n",
    "    parts = [crime, borough, premises, timeb]\n",
    "    parts = [str(x) for x in parts if x not in (None, '', 'UNKNOWN')]\n",
    "    left = ' - '.join(parts) if parts else 'Pattern'\n",
    "    return f\"{left} - {wkd} - SUSP: {susp_sex} {susp_age} | VIC: {vic_sex} {vic_age}\"\n",
    "\n",
    "def _coerce_pattern(src):\n",
    "    p = _as_mapping(src)\n",
    "    if not p:\n",
    "        return None\n",
    "    # Normalize selected fields, keep extras if already present\n",
    "    out = {\n",
    "        'crime_type': p.get('crime_type') or p.get('CRIME') or p.get('OFNS_DESC') or p.get('PD_DESC') or p.get('LAW_CAT') or p.get('LAW_CAT_CD'),\n",
    "        'borough': p.get('borough') or p.get('BORO_NM') or p.get('BOROUGH') or p.get('BORO'),\n",
    "        'premises': p.get('premises') or p.get('LOC_OF_OCCUR') or p.get('PREM_TYP_DESC') or p.get('LOCATION'),\n",
    "        'time_bucket': p.get('time_bucket') or p.get('TIME_BUCKET') or p.get('TIME') or p.get('TIME_BIN'),\n",
    "        'is_weekend_mode': bool(p.get('is_weekend_mode')) if 'is_weekend_mode' in p else bool(p.get('WEEKEND')),\n",
    "        'is_holiday_mode': bool(p.get('is_holiday_mode')) if 'is_holiday_mode' in p else bool(p.get('HOLIDAY')),\n",
    "        'suspect_sex_mode': p.get('suspect_sex_mode') or p.get('SUSP_SEX') or p.get('SUSPECT_SEX'),\n",
    "        'suspect_age_mode': p.get('suspect_age_mode') or p.get('SUSP_AGE') or p.get('SUSPECT_AGE'),\n",
    "        'victim_sex_mode': p.get('victim_sex_mode') or p.get('VIC_SEX') or p.get('VICTIM_SEX'),\n",
    "        'victim_age_mode': p.get('victim_age_mode') or p.get('VIC_AGE') or p.get('VICTIM_AGE'),\n",
    "    }\n",
    "    # Carry over optional metrics if available\n",
    "    for k in ('volume','count','cases','concentration','concentration_score'):\n",
    "        if p.get(k) is not None:\n",
    "            out[k] = p.get(k)\n",
    "    # Prefer unified names\n",
    "    if out.get('count') is not None and out.get('volume') is None:\n",
    "        out['volume'] = out['count']\n",
    "    if out.get('cases') is not None and out.get('volume') is None:\n",
    "        out['volume'] = out['cases']\n",
    "    return {k:v for k,v in out.items() if v is not None}\n",
    "\n",
    "# Collect inputs\n",
    "project_root = _get('project_root') or os.getcwd()\n",
    "output_dir = os.path.join(project_root, 'JupyterOutputs', 'Clustering (MultidimensionalClusteringAnalysis)')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Totals and counts\n",
    "_total_crimes = _to_int(_get('total_crimes'))\n",
    "if _total_crimes is None:\n",
    "    df = _get('df')\n",
    "    try:\n",
    "        _total_crimes = int(len(df)) if df is not None else None\n",
    "    except Exception:\n",
    "        _total_crimes = None\n",
    "\n",
    "cluster_profiles = _get('cluster_profiles') or []\n",
    "_patterns_identified = _to_int(len(cluster_profiles), 0)\n",
    "\n",
    "_high_priority_patterns = _to_int(_get('high_priority_patterns'), 0)\n",
    "_high_priority_crimes = _to_int(_get('high_priority_crimes'), None)\n",
    "\n",
    "_pct = None\n",
    "if _high_priority_crimes is not None and _total_crimes:\n",
    "    _pct = round(100.0 * _high_priority_crimes / max(1, _total_crimes), 1)\n",
    "\n",
    "# Patterns\n",
    "mc = _coerce_pattern(_get('most_concentrated'))\n",
    "hv = _coerce_pattern(_get('highest_volume'))\n",
    "\n",
    "mc_sig = _build_signature(mc) if mc else None\n",
    "hv_sig = _build_signature(hv) if hv else None\n",
    "\n",
    "# Deployment heuristic\n",
    "conc_val = None\n",
    "if mc and mc.get('concentration') is not None:\n",
    "    conc_val = _to_pct(mc.get('concentration'))\n",
    "\n",
    "# conc_val already in percent units (0-100); compare to 60.0 threshold\n",
    "_immediate = bool((_high_priority_patterns or 0) > 0 or (conc_val is not None and conc_val >= 60.0))\n",
    "_focus = max(1, min(5, _high_priority_patterns or max(1, _patterns_identified // 3)))\n",
    "\n",
    "exec_enriched = {\n",
    "    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "    'total_crimes_analyzed': _total_crimes,\n",
    "    'patterns_identified': _patterns_identified,\n",
    "    'high_priority_patterns': _high_priority_patterns,\n",
    "    'high_priority_crime_percentage': _pct,\n",
    "    'most_concentrated_pattern_signature': mc_sig,\n",
    "    'highest_volume_pattern_signature': hv_sig,\n",
    "    'most_concentrated_pattern': mc,\n",
    "    'highest_volume_pattern': hv,\n",
    "    'immediate_deployment_needed': _immediate,\n",
    "    'resource_focus_patterns': _focus,\n",
    "}\n",
    "\n",
    "json_path = os.path.join(output_dir, 'executive_crime_summary_enriched.json')\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(exec_enriched, f, indent=2, ensure_ascii=False)\n",
    "print(f\"JSON saved: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6af2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deliverables summary:\n",
      "{'file': 'c:\\\\UNIVERSITA MAG\\\\Data mining and Machine learning\\\\Progetto\\\\crime-analyzer\\\\JupyterOutputs\\\\Clustering (MultidimensionalClusteringAnalysis)\\\\executive_crime_summary.json', 'status': 'OK', 'size_kb': 1.3}\n",
      "{'file': 'c:\\\\UNIVERSITA MAG\\\\Data mining and Machine learning\\\\Progetto\\\\crime-analyzer\\\\JupyterOutputs\\\\Clustering (MultidimensionalClusteringAnalysis)\\\\executive_crime_summary_enriched.json', 'status': 'OK', 'size_kb': 0.7}\n",
      "{'file': 'c:\\\\UNIVERSITA MAG\\\\Data mining and Machine learning\\\\Progetto\\\\crime-analyzer\\\\JupyterOutputs\\\\Clustering (MultidimensionalClusteringAnalysis)\\\\police_operational_intelligence_enriched.csv', 'status': 'OK', 'size_kb': 1.5}\n"
     ]
    }
   ],
   "source": [
    "expected_files = [\n",
    "    os.path.join(output_dir, \"executive_crime_summary.json\"),\n",
    "    os.path.join(output_dir, \"executive_crime_summary_enriched.json\"),\n",
    "    os.path.join(output_dir, \"police_operational_intelligence_enriched.csv\")\n",
    "]\n",
    "\n",
    "files_info = []\n",
    "for fp in expected_files:\n",
    "    exists = os.path.exists(fp)\n",
    "    size_kb = (os.path.getsize(fp) / 1024.0) if exists else 0.0\n",
    "    files_info.append({\n",
    "        \"file\": str(fp),\n",
    "        \"status\": \"OK\" if exists else (\"MISSING (optional)\" if os.path.basename(fp).endswith((\"_enriched.json\", \"_enriched.csv\")) else \"MISSING\"),\n",
    "        \"size_kb\": round(size_kb, 1)\n",
    "    })\n",
    "\n",
    "print(\"Deliverables summary:\")\n",
    "for info in files_info:\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211c9d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Advanced Clustering Methods\n",
    "\n",
    "This section explores advanced clustering techniques for discovering complex crime patterns that might be missed by traditional methods. These approaches complement the operational analysis above and provide research-grade insights for academic and advanced analytical purposes.\n",
    "\n",
    "\n",
    "## Categorical Dimensionality Reduction + Clustering\n",
    "\n",
    "Categorical dimensionality reduction transforms high-cardinality categorical data into a lower-dimensional continuous space, enabling the application of distance-based clustering algorithms while preserving the essential categorical relationships. \n",
    "\n",
    "The Categorical Dimensionality Reduction Pipeline follows our established architecture and uses a robust OneHot + PCA approach instead of traditional MCA:\n",
    "\n",
    "`CategoricalPreprocessor → CategoricalDimensionalityReducer → KMeans`\n",
    "\n",
    "Why OneHot + PCA instead of MCA?\n",
    "- Numerical stability: no NaN values produced during transformation\n",
    "- Robust implementation: well-tested sklearn components\n",
    "- Consistent results: reproducible across different data distributions\n",
    "- Better performance: more efficient and scalable for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4b0a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cd_pipeline(n_components=5, random_state=RANDOM_STATE):\n",
    "    dimred = CategoricalDimensionalityReducer(n_components=n_components, random_state=random_state)\n",
    "    cluster = KMeans(n_clusters=16, random_state=random_state, n_init=10)\n",
    "    return Pipeline([\n",
    "        (\"dimred\", dimred),\n",
    "        (\"cluster\", cluster)\n",
    "    ])\n",
    "\n",
    "categorical_dimred_pipeline = make_cd_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cef39006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_eval' not in globals():\n",
    "    if 'X_categorical' in globals():\n",
    "        X_eval = X_categorical.copy()\n",
    "    elif 'df_kmodes' in globals() and 'CATEGORICAL_FEATURES_KMODES_AVAILABLE' in globals():\n",
    "        X_eval = df_kmodes[CATEGORICAL_FEATURES_KMODES_AVAILABLE].astype(str).fillna('Unknown')\n",
    "    elif 'categorical_available' in globals() and 'df' in globals():\n",
    "        cols = [c for c in categorical_available if c in df.columns]\n",
    "        X_eval = df[cols].astype(str).fillna('Unknown')\n",
    "    else:\n",
    "        X_eval = pd.DataFrame()\n",
    "\n",
    "if 'cat_dimred_param_grid' not in globals():\n",
    "    cat_dimred_param_grid = {\n",
    "        'dimred__n_components': [10, 20, 30],\n",
    "        'cluster__n_clusters': [8, 12, 16, 20],\n",
    "        'cluster__n_init': [10, 20]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df1fd09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CD+KMeans score: 0.1973\n",
      "Best CD+KMeans params: {'dimred__n_components': 10, 'cluster__n_clusters': 16, 'cluster__n_init': 10}\n"
     ]
    }
   ],
   "source": [
    "cd_best_score = -1.0\n",
    "cd_best_params = None\n",
    "cd_final = None\n",
    "\n",
    "# Normalize/expand grid to a list of dicts (cartesian product for dict-of-lists)\n",
    "if isinstance(cat_dimred_param_grid, Mapping):\n",
    "    keys = list(cat_dimred_param_grid.keys())\n",
    "    vals = []\n",
    "    for k in keys:\n",
    "        v = cat_dimred_param_grid[k]\n",
    "        if isinstance(v, (list, tuple, np.ndarray)):\n",
    "            vals.append(list(v))\n",
    "        else:\n",
    "            vals.append([v])\n",
    "    grid_iter = [dict(zip(keys, combo)) for combo in product(*vals)]\n",
    "elif isinstance(cat_dimred_param_grid, (list, tuple)):\n",
    "    # Ensure each element is a dict\n",
    "    for p in cat_dimred_param_grid:\n",
    "        if not isinstance(p, Mapping):\n",
    "            raise TypeError(\"Each entry in cat_dimred_param_grid must be a dict of parameters\")\n",
    "    grid_iter = list(cat_dimred_param_grid)\n",
    "else:\n",
    "    raise TypeError(\"cat_dimred_param_grid must be a dict or a list of dicts\")\n",
    "\n",
    "for params in grid_iter:\n",
    "    pipe_copy = Pipeline(categorical_dimred_pipeline.steps)\n",
    "\n",
    "    # Allow parameters for both dimred and cluster\n",
    "    prefixed = {}\n",
    "    for k, v in params.items():\n",
    "        if k.startswith(\"cluster__\") or k.startswith(\"dimred__\"):\n",
    "            prefixed[k] = v\n",
    "        else:\n",
    "            # Default to cluster params if unprefixed common names appear\n",
    "            prefixed[f\"cluster__{k}\"] = v\n",
    "\n",
    "    pipe_copy.set_params(**prefixed)\n",
    "\n",
    "    # Fit-transform through the dimred step and ensure numpy arrays for KMeans to avoid feature-name warnings\n",
    "    X_val_transformed_df = pipe_copy.named_steps['dimred'].fit_transform(X_eval)\n",
    "    X_val_transformed = np.asarray(X_val_transformed_df)\n",
    "    labels = pipe_copy.named_steps['cluster'].fit_predict(X_val_transformed)\n",
    "\n",
    "    # Compute silhouette only if >1 cluster and <n_samples-1\n",
    "    if len(np.unique(labels)) > 1 and len(np.unique(labels)) < len(labels):\n",
    "        score = silhouette_score(X_val_transformed, labels)\n",
    "    else:\n",
    "        score = -1.0\n",
    "\n",
    "    if score > cd_best_score:\n",
    "        cd_best_score = score\n",
    "        cd_best_params = dict(prefixed)\n",
    "        cd_final = pipe_copy\n",
    "\n",
    "print(f\"Best CD+KMeans score: {cd_best_score:.4f}\")\n",
    "print(f\"Best CD+KMeans params: {cd_best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c95d854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spectral_param_grid' not in globals():\n",
    "    spectral_param_grid = {\n",
    "        'n_clusters': [8, 12, 16],\n",
    "        'affinity': ['rbf', 'nearest_neighbors'],\n",
    "        'gamma': [0.1, 0.5, 1.0, 2.0],\n",
    "        'n_neighbors': [10, 20, 30],\n",
    "        'assign_labels': ['kmeans']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b519a",
   "metadata": {},
   "source": [
    "### Spectral Clustering: pipeline overview\n",
    "\n",
    "We apply Spectral Clustering on a mixed-feature representation assembled with a ColumnTransformer:\n",
    "- Categorical features → GroupBalancedOneHotEncoder (each feature scaled by 1/√k across its one-hot group)\n",
    "- Numerical features → StandardScaler\n",
    "\n",
    "The resulting numeric matrix feeds SpectralClustering with a small grid over n_clusters and affinity/nearest-neighbors settings.\n",
    "\n",
    "Pipeline: `ColumnTransformer(GroupBalancedOneHotEncoder for categoricals, StandardScaler for numericals) → SpectralClustering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "624288ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Spectral score: 0.1034\n",
      "Best Spectral params: {'cluster__n_clusters': 8, 'cluster__affinity': 'nearest_neighbors', 'cluster__gamma': 0.1, 'cluster__n_neighbors': 30, 'cluster__assign_labels': 'kmeans'}\n",
      "[Info] Group-balanced categorical encoding is always active.\n"
     ]
    }
   ],
   "source": [
    "# Spectral clustering evaluation with integrated group-balanced categorical encoding.\n",
    "\n",
    "def _expand_param_grid(grid):\n",
    "    if isinstance(grid, Mapping):\n",
    "        keys = list(grid.keys())\n",
    "        vals = []\n",
    "        for k in keys:\n",
    "            v = grid[k]\n",
    "            if isinstance(v, (list, tuple, np.ndarray)):\n",
    "                vals.append(list(v))\n",
    "            else:\n",
    "                vals.append([v])\n",
    "        return [dict(zip(keys, combo)) for combo in product(*vals)]\n",
    "    elif isinstance(grid, (list, tuple)):\n",
    "        out = []\n",
    "        for p in grid:\n",
    "            if not isinstance(p, Mapping):\n",
    "                raise TypeError(\"Each entry in spectral_param_grid must be a dict of parameters\")\n",
    "            out.append(p)\n",
    "        return out\n",
    "    else:\n",
    "        raise TypeError(\"spectral_param_grid must be a dict or a list of dicts\")\n",
    "\n",
    "def _normalize_colnames(X_df, cols):\n",
    "    df_cols_str = set(map(str, X_df.columns))\n",
    "    normalized = []\n",
    "    for c in cols or []:\n",
    "        cs = str(c)\n",
    "        if cs in df_cols_str and cs not in normalized:\n",
    "            normalized.append(cs)\n",
    "    return normalized\n",
    "\n",
    "def _sanitize_params(params, n_samples):\n",
    "    allowed_unprefixed = {\n",
    "        'n_clusters','affinity','gamma','n_neighbors','assign_labels',\n",
    "        'eigen_solver','n_init','n_components','random_state'\n",
    "    }\n",
    "    prefixed = {}\n",
    "    for k, v in params.items():\n",
    "        if k.startswith('dimred__'):\n",
    "            continue\n",
    "        if '__' in k:\n",
    "            if k.startswith('cluster__'):\n",
    "                key = k.split('__', 1)[1]\n",
    "                if key in allowed_unprefixed:\n",
    "                    prefixed[k] = v\n",
    "        else:\n",
    "            if k in allowed_unprefixed:\n",
    "                prefixed[f\"cluster__{k}\"] = v\n",
    "    nk_key = 'cluster__n_clusters'\n",
    "    if nk_key in prefixed:\n",
    "        try:\n",
    "            nk = int(prefixed[nk_key])\n",
    "            if nk <= 1 or nk >= n_samples:\n",
    "                return None\n",
    "        except Exception:\n",
    "            return None\n",
    "    aff_key = 'cluster__affinity'\n",
    "    nn_key = 'cluster__n_neighbors'\n",
    "    if prefixed.get(aff_key) == 'nearest_neighbors':\n",
    "        nn = int(prefixed.get(nn_key, min(10, max(2, n_samples-1))))\n",
    "        if nn <= 1:\n",
    "            nn = 2\n",
    "        if nn >= n_samples:\n",
    "            nn = max(2, n_samples-1)\n",
    "        prefixed[nn_key] = nn\n",
    "    return prefixed\n",
    "\n",
    "def spectral_clustering_evaluation(X_df, categorical_cols, numerical_cols, param_grid, random_state=RANDOM_STATE):\n",
    "    if not isinstance(X_df, pd.DataFrame):\n",
    "        raise TypeError(\"X_df must be a pandas DataFrame\")\n",
    "\n",
    "    categorical_cols = _normalize_colnames(X_df, categorical_cols)\n",
    "    numerical_cols = _normalize_colnames(X_df, numerical_cols)\n",
    "\n",
    "    if not categorical_cols and not numerical_cols:\n",
    "        raise ValueError(\"No features available for SpectralClustering: categorical_cols and numerical_cols are both empty.\")\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", GroupBalancedOneHotEncoder(), categorical_cols),\n",
    "            (\"num\", StandardScaler(with_mean=True, with_std=True), numerical_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"cluster\", SpectralClustering(random_state=random_state, assign_labels='kmeans')),\n",
    "    ])\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    best_pipe = None\n",
    "\n",
    "    grid_iter = _expand_param_grid(param_grid)\n",
    "\n",
    "    # Fit preprocessing once (deterministic embedding)\n",
    "    X_emb_base = pipe.named_steps['pre'].fit_transform(X_df)\n",
    "    n_samples = X_emb_base.shape[0]\n",
    "\n",
    "    for params in grid_iter:\n",
    "        prefixed = _sanitize_params(params, n_samples)\n",
    "        if prefixed is None:\n",
    "            continue\n",
    "        pipe_try = Pipeline(pipe.steps)\n",
    "        try:\n",
    "            pipe_try.set_params(**prefixed)\n",
    "            labels = pipe_try.named_steps['cluster'].fit_predict(X_emb_base)\n",
    "            if len(np.unique(labels)) > 1 and len(np.unique(labels)) < len(labels):\n",
    "                sil = silhouette_score(X_emb_base, labels, metric='euclidean')\n",
    "            else:\n",
    "                sil = -1.0\n",
    "            if sil > best_score:\n",
    "                best_score = sil\n",
    "                best_params = dict(prefixed)\n",
    "                best_pipe = pipe_try\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not np.isfinite(best_score):\n",
    "        try:\n",
    "            nk = min(8, max(2, n_samples-1))\n",
    "            fallback = {'n_clusters': nk, 'affinity': 'rbf', 'assign_labels': 'kmeans'}\n",
    "            pipe_fallback = Pipeline(pipe.steps)\n",
    "            pipe_fallback.set_params(**{f\"cluster__{k}\": v for k, v in fallback.items()})\n",
    "            labels = pipe_fallback.named_steps['cluster'].fit_predict(X_emb_base)\n",
    "            if len(np.unique(labels)) > 1 and len(np.unique(labels)) < len(labels):\n",
    "                sil = silhouette_score(X_emb_base, labels, metric='euclidean')\n",
    "            else:\n",
    "                sil = -1.0\n",
    "            best_score = sil\n",
    "            best_params = {f\"cluster__{k}\": v for k, v in fallback.items()}\n",
    "            best_pipe = pipe_fallback\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if best_pipe is not None:\n",
    "        # Reuse the already fitted preprocessor (contains balanced encoding)\n",
    "        best_pipe.named_steps['pre'] = pipe.named_steps['pre']\n",
    "\n",
    "    return best_score, best_params, best_pipe, X_emb_base\n",
    "\n",
    "# Run evaluation\n",
    "categorical_cols = list(categorical_available) if 'categorical_available' in locals() else []\n",
    "numerical_cols = list(available_numericals) if 'available_numericals' in locals() else []\n",
    "param_grid = spectral_param_grid\n",
    "\n",
    "best_spectral_score, best_spectral_params, spectral_pipeline, _X_spectral_embedding = spectral_clustering_evaluation(\n",
    "    X_eval, categorical_cols, numerical_cols, param_grid, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Best Spectral score: {best_spectral_score:.4f}\")\n",
    "print(f\"Best Spectral params: {best_spectral_params}\")\n",
    "print(\"[Info] Group-balanced categorical encoding is always active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb6200",
   "metadata": {},
   "source": [
    "### Spectral: search space and configuration\n",
    "\n",
    "We evaluate SpectralClustering over a compact grid of parameters. Features are prepared with a ColumnTransformer combining GroupBalancedOneHotEncoder for categoricals and StandardScaler for numericals. The transformed matrix is then clustered via SpectralClustering.\n",
    "\n",
    "Key search dimensions:\n",
    "- n_clusters\n",
    "- affinity (rbf vs nearest_neighbors with n_neighbors)\n",
    "- assign_labels = 'kmeans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32bb2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\pipeline_methods_comparison.json\n"
     ]
    }
   ],
   "source": [
    "method_comparison = {\n",
    "    \"K-Modes\": {\n",
    "        \"best_score\": float(kmodes_best_score) if 'kmodes_best_score' in globals() else None,\n",
    "        \"best_params\": dict(kmodes_best_params) if 'kmodes_best_params' in globals() else None,\n",
    "    },\n",
    "    \"CategoricalDimRed+KMeans\": {\n",
    "        \"best_score\": float(cd_best_score) if 'cd_best_score' in globals() else None,\n",
    "        \"best_params\": dict(cd_best_params) if 'cd_best_params' in globals() else None,\n",
    "    },\n",
    "    \"Spectral\": {\n",
    "        \"best_score\": float(best_spectral_score) if 'best_spectral_score' in globals() else None,\n",
    "        \"best_params\": dict(best_spectral_params) if 'best_spectral_params' in globals() else None,\n",
    "    }\n",
    "}\n",
    "\n",
    "comparison_path = Path(project_root) / \"JupyterOutputs\" / \"Clustering (MultidimensionalClusteringAnalysis)\" / \"pipeline_methods_comparison.json\"\n",
    "comparison_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(comparison_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(method_comparison, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", comparison_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c291dbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K-Modes': {'best_score': 0.5866698350071736,\n",
       "  'best_params': {'cluster__init': 'Huang',\n",
       "   'cluster__n_clusters': 18,\n",
       "   'cluster__n_init': 5}},\n",
       " 'CatDimRed+KMeans': {'best_score': 0.19733085500583938,\n",
       "  'best_params': {'dimred__n_components': 10,\n",
       "   'cluster__n_clusters': 16,\n",
       "   'cluster__n_init': 10}},\n",
       " 'Spectral': {'best_score': 0.10340519954298237,\n",
       "  'best_params': {'cluster__n_clusters': 8,\n",
       "   'cluster__affinity': 'nearest_neighbors',\n",
       "   'cluster__gamma': 0.1,\n",
       "   'cluster__n_neighbors': 30,\n",
       "   'cluster__assign_labels': 'kmeans'}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build comparison with distinct variable names to avoid overwrites\n",
    "comparison_summary = {}\n",
    "\n",
    "if 'kmodes_best_score' in globals() and kmodes_best_score is not None:\n",
    "    comparison_summary['K-Modes'] = {\n",
    "        'best_score': kmodes_best_score,\n",
    "        'best_params': kmodes_best_params\n",
    "    }\n",
    "\n",
    "if 'cd_best_score' in globals():  # categorical dimred + kmeans\n",
    "    comparison_summary['CatDimRed+KMeans'] = {\n",
    "        'best_score': float(cd_best_score),\n",
    "        'best_params': cd_best_params\n",
    "    }\n",
    "\n",
    "if 'best_spectral_score' in globals():\n",
    "    comparison_summary['Spectral'] = {\n",
    "        'best_score': float(best_spectral_score),\n",
    "        'best_params': best_spectral_params\n",
    "    }\n",
    "\n",
    "comparison_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901360db",
   "metadata": {},
   "source": [
    "### Brief Interpretation (Spectral vs K-Modes)\n",
    "A low Spectral Clustering silhouette (≈0.10) is **not a failure**: spectral builds structure in the Laplacian eigenvector space and only then maps cluster labels back to the original mixed feature space, where Euclidean compactness is naturally weaker for smooth, overlapping crime patterns. We nevertheless adopt K‑Modes as the primary method because it is simpler, more directly interpretable (mode-based centroids), and achieves a higher silhouette under categorical dissimilarity. Spectral remains a complementary exploratory tool rather than the operational default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692c9e4",
   "metadata": {},
   "source": [
    "## Literature comparison\n",
    "\n",
    "| Study (year)                 | Domain / Data                                                                 | Method                                                                                   | Evaluation metric(s)                                                             | Key findings                                                                                                                                            | Differences vs our approach                                                                                                                                                                                                                                              |\n",
    "| ---------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Nath (2006)**              | Real crime incident records (sheriff’s office)                                | K-means clustering (with attribute weighting & semi-supervised refinement)               | Qualitative validation; improved analyst productivity                            | Clustering exposed repeat crime patterns (e.g., same suspect profiles across incidents) aiding faster crime resolution                                  | Used generic K-means requiring manual tuning for categorical data; our approach uses K-modes/Spectral to handle categoricals natively and excludes bias-prone features (e.g., race) not addressed in their work.                                                         |\n",
    "| **Gharehchopogh & Haggi (2020)** | Community-level crime stats (UCI “Community and Crime” dataset, 1994 samples) | Hybrid K-modes clustering with Elephant Herding Optimization for centroid initialization | Cluster purity (unsupervised accuracy) = 91.45%                                  | Metaheuristic-guided K-modes achieved high-purity clusters of crimes by similarity                                                                      | Focuses on optimizing one clustering algorithm for aggregated data; our approach clusters individual incidents with richer features (time, location context, demographics) and compares multiple clustering methods rather than a single optimized workflow.             |\n",
    "| **Duda (2021)**              | Urban traffic accidents (42k crashes, Pittsburgh 2010–2019)                   | K-modes clustering on categorical crash attributes (road type, time, etc.)               | No explicit metric (clusters evaluated via chi-square feature association tests) | Identified distinct accident clusters (e.g., nearly all accidents in one cluster occurred at intersections), enabling narrative profiles of crash types | Different domain (traffic accidents vs. crime incidents); uses only categorical clustering, whereas we cluster crime incidents and integrate additional context features (e.g., POI proximity, holiday flags) and multiple algorithms for a more comprehensive analysis. |\n",
    "| **Al-Ibrahim & Kurdi (2024)**    | Unstructured crime reports (text documents, \\~3.5k crime news narratives)     | Spectral graph clustering enhanced with GCN (graph neural network) embeddings            | Silhouette = 0.77; Davies–Bouldin Index = 0.51 (high cluster quality)            | Graph-based spectral clustering outperformed traditional methods, finding clearer crime report groupings despite sparse high-dimensional data           | Targets textual data with complex graph/deep learning techniques; our approach handles structured categorical data with emphasis on interpretability and does not require neural networks, focusing instead on operational features and simpler clustering models.       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe7d3d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**The Multidimensional Clustering Workflow**:\n",
    "- Uncovers categorical and mixed‑feature crime patterns beyond geography (borough, premises, time bucket, demographics, POI/context)\n",
    "- Compares complementary methods — K‑Modes, One‑Hot + PCA → KMeans, and Spectral with group‑balanced encoding\n",
    "- Uses balanced encoding and interpretable binning to prevent high‑cardinality dominance and keep clusters readable\n",
    "- Produces operational intelligence artifacts (executive summary, priority tables, enriched CSV) for police planning and briefings\n",
    "- Remains modular and extensible across feature groups, encoders, reducers, clustering algorithms, and export/reporting\n",
    "\n",
    "**What the results tell us**:\n",
    "- Clusters form consistent “profiles” of crime: primary crime types, premises, time windows, and demographic modes per borough\n",
    "- Priority ranking focuses resources on the highest‑volume and most concentrated patterns for maximum impact\n",
    "\n",
    "**Future Work**:\n",
    "- **Constraint‑based clustering**: inject domain knowledge (must‑/cannot‑link) for finer operational relevance\n",
    "- **Temporal dynamics**: rolling windows, drift monitoring, and decay weighting to emphasize recent incidents.\n",
    "- **Significance and actionability**: simple permutation tests for concentration, counterfactual checks; integrate with Spatial Hotspots for joint targeting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
