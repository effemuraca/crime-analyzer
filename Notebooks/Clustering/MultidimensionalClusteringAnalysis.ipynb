{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63940ca4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "This section handles the initial setup, including importing necessary libraries, defining file paths, and configuring the environment for spatial clustering analysis. Custom transformers for spatial feature engineering are imported from our utilities module.\n",
    "\n",
    "## Optional: Google Colab Setup\n",
    "\n",
    "Uncomment and run this cell if working in Google Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbf5b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on Google Colab (optional)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d04a1",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import all libraries required for spatial clustering analysis, pipeline construction,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bacb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and computation\n",
    "import pandas as pd, json, os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from statistics import mean\n",
    "\n",
    "# Shapely and geographic projection\n",
    "from shapely.geometry import Point, MultiPoint, mapping\n",
    "from shapely.ops import transform as shp_transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Machine learning and clustering\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# custom transformers\n",
    "from Utilities.clustering_transformers import (\n",
    "    CategoricalPreprocessor,\n",
    "    MixedFeaturePreprocessor,\n",
    "    IdentityPreprocessor,\n",
    "    ColumnBinner,\n",
    "    CategoricalDimensionalityReducer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce085c0",
   "metadata": {},
   "source": [
    "## Configure Paths and Custom Utilities\n",
    "\n",
    "Set up file paths and import custom clustering utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb3d40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\n",
      "Data directory: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\Data\n",
      "Output directory: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n"
     ]
    }
   ],
   "source": [
    "# Configure working directory and paths\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '../..'))\n",
    "data_dir = os.path.join(project_root, 'Data')\n",
    "output_dir = os.path.join(project_root, 'JupyterOutputs', 'Clustering (MultidimensionalClusteringAnalysis)')\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Add utilities to Python path\n",
    "utilities_path = os.path.join(os.getcwd(), 'Utilities')\n",
    "if utilities_path not in sys.path:\n",
    "    sys.path.append(utilities_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d4450",
   "metadata": {},
   "source": [
    "## Configure Analysis Parameters\n",
    "\n",
    "Define key parameters for the clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00eda05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis parameters configured successfully!\n",
      "Primary spatial features: ['Latitude', 'Longitude']\n",
      "Primary temporal features: ['HOUR', 'WEEKDAY', 'MONTH']\n",
      "Primary categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
      "Available spatial context features: 16 POI-based features\n",
      "Available extended temporal features: 10 temporal features\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Feature columns for spatial analysis (aligned with actual dataset)\n",
    "SPATIAL_FEATURES = ['Latitude', 'Longitude']\n",
    "\n",
    "# Primary temporal features for clustering\n",
    "TEMPORAL_FEATURES = ['HOUR', 'WEEKDAY', 'MONTH']\n",
    "\n",
    "# Extended temporal features available in dataset\n",
    "EXTENDED_TEMPORAL_FEATURES = [\n",
    "    'HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', \n",
    "    'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY'\n",
    "]\n",
    "\n",
    "# Categorical features\n",
    "CATEGORICAL_FEATURES = ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
    "\n",
    "# Extended categorical features available\n",
    "EXTENDED_CATEGORICAL_FEATURES = [\n",
    "    'BORO_NM', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PREM_TYP_DESC',\n",
    "    'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'VIC_AGE_GROUP', 'VIC_RACE', 'VIC_SEX'\n",
    "]\n",
    "\n",
    "# Spatial context features (POI-based features for enhanced spatial analysis)\n",
    "SPATIAL_CONTEXT_FEATURES = [\n",
    "    'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE',\n",
    "    'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE',\n",
    "    'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT', \n",
    "    'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT', 'TOTAL_POI_COUNT',\n",
    "    'POI_DIVERSITY', 'POI_DENSITY_SCORE'\n",
    "]\n",
    "\n",
    "# Social features \n",
    "SOCIAL_FEATURES = ['SAME_AGE_GROUP', 'SAME_SEX']\n",
    "\n",
    "print(\"Analysis parameters configured successfully!\")\n",
    "print(f\"Primary spatial features: {SPATIAL_FEATURES}\")\n",
    "print(f\"Primary temporal features: {TEMPORAL_FEATURES}\")\n",
    "print(f\"Primary categorical features: {CATEGORICAL_FEATURES}\")\n",
    "print(f\"Available spatial context features: {len(SPATIAL_CONTEXT_FEATURES)} POI-based features\")\n",
    "print(f\"Available extended temporal features: {len(EXTENDED_TEMPORAL_FEATURES)} temporal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bd72f",
   "metadata": {},
   "source": [
    "## Cross-Validation Functions\n",
    "\n",
    "Define custom cross-validation functions for clustering evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf90be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_cross_validation(pipeline, X, param_grid, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Cross-validation for clustering with appropriate metrics.\n",
    "\n",
    "    Evaluates clustering quality using:\n",
    "    - Silhouette Score: Quality of clusters (intra vs inter cluster distance)\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n🔄 CROSS-VALIDATION CLUSTERING EVALUATION\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"CV folds: {cv}\")\n",
    "    print(f\"Parameter combinations: {len(list(ParameterGrid(param_grid)))}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    results = []\n",
    "\n",
    "    for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "        print(f\"\\nTesting combination {i+1}: {params}\")\n",
    "\n",
    "        # Metrics for each fold\n",
    "        fold_silhouettes = []\n",
    "        fold_inertias = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "\n",
    "            try:\n",
    "                # Fit pipeline on training fold\n",
    "                pipeline_copy = clone(pipeline)\n",
    "                pipeline_copy.set_params(**params)\n",
    "                pipeline_copy.fit(X_train)\n",
    "\n",
    "                # Predict on validation fold\n",
    "                val_labels = pipeline_copy.predict(X_val)\n",
    "\n",
    "                # Skip if only one cluster found\n",
    "                if len(np.unique(val_labels)) < 2:\n",
    "                    continue\n",
    "\n",
    "                # Get transformed validation data for metrics\n",
    "                X_val_transformed = pipeline_copy.named_steps['preprocess'].transform(X_val)\n",
    "\n",
    "                # Convert to numpy array if needed for metrics\n",
    "                if hasattr(X_val_transformed, 'values'):\n",
    "                    X_val_array = X_val_transformed.values\n",
    "                else:\n",
    "                    X_val_array = X_val_transformed\n",
    "\n",
    "                # Calculate clustering metrics\n",
    "                # Silhouette Score (range: -1 to 1, higher better)\n",
    "                sil_score = silhouette_score(X_val_array, val_labels)\n",
    "                fold_silhouettes.append(sil_score)\n",
    "\n",
    "                # Inertia (for K-Means based methods, lower better)\n",
    "                if hasattr(pipeline_copy.named_steps['cluster'], 'inertia_'):\n",
    "                    # Re-fit on validation to get inertia\n",
    "                    cluster_step = clone(pipeline_copy.named_steps['cluster'])\n",
    "                    cluster_step.set_params(**{k.replace('cluster__', ''): v \\\n",
    "                                             for k, v in params.items() \\\n",
    "                                             if k.startswith('cluster__')})\n",
    "                    cluster_step.fit(X_val_array)\n",
    "                    fold_inertias.append(cluster_step.inertia_)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Fold {fold+1} failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Aggregate results across folds\n",
    "        if fold_silhouettes:\n",
    "            mean_silhouette = np.mean(fold_silhouettes)\n",
    "            std_silhouette = np.std(fold_silhouettes)\n",
    "            mean_inertia = np.mean(fold_inertias) if fold_inertias else float('inf')\n",
    "\n",
    "            # Composite score: rely on silhouette only\n",
    "            composite_score = mean_silhouette\n",
    "\n",
    "            results.append({\n",
    "                'params': params,\n",
    "                'cv_silhouette_mean': mean_silhouette,\n",
    "                'cv_silhouette_std': std_silhouette,\n",
    "                'cv_inertia_mean': mean_inertia,\n",
    "                'composite_score': composite_score,\n",
    "                'n_successful_folds': len(fold_silhouettes)\n",
    "            })\n",
    "\n",
    "            print(f\"  ✓ CV Results:\")\n",
    "            print(f\"    Silhouette: {mean_silhouette:.3f} (±{std_silhouette:.3f})\")\n",
    "            print(f\"    Composite Score: {composite_score:.4f}\")\n",
    "            print(f\"    Successful folds: {len(fold_silhouettes)}/{cv}\")\n",
    "        else:\n",
    "            print(f\"  ❌ No successful folds for this parameter combination\")\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('composite_score', ascending=False)\n",
    "        print(f\"\\n🏆 CROSS-VALIDATION COMPLETED\")\n",
    "        print(f\"Total successful parameter combinations: {len(df_results)}\")\n",
    "        if len(df_results) > 0:\n",
    "            best_params = df_results.iloc[0]['params']\n",
    "            best_score = df_results.iloc[0]['composite_score']\n",
    "            print(f\"Best parameters: {best_params}\")\n",
    "            print(f\"Best composite score: {best_score:.4f}\")\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "def evaluate_best_pipeline(pipeline, X, best_params, method_name):\n",
    "    \"\"\"\n",
    "    Evaluate the best pipeline with full dataset and detailed metrics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n🎯 FINAL {method_name.upper()} MODEL EVALUATION\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Set best parameters and fit on full dataset\n",
    "    pipeline.set_params(**best_params)\n",
    "    t0 = time.perf_counter()\n",
    "    labels = pipeline.fit_predict(X)\n",
    "    runtime = time.perf_counter() - t0\n",
    "\n",
    "    # Get transformed data\n",
    "    X_transformed = pipeline.named_steps['preprocess'].transform(X)\n",
    "    if hasattr(X_transformed, 'values'):\n",
    "        X_array = X_transformed.values\n",
    "    else:\n",
    "        X_array = X_transformed\n",
    "\n",
    "    # Calculate final metrics\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    silhouette = silhouette_score(X_array, labels)\n",
    "\n",
    "    print(f\"✓ Model fitted successfully\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Dataset size: {len(labels):,}\")\n",
    "\n",
    "    print(f\"\\nFinal Quality Metrics:\")\n",
    "    print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
    "\n",
    "    # Cluster distribution\n",
    "    cluster_counts = pd.Series(labels).value_counts().sort_index()\n",
    "    print(f\"\\nCluster Distribution:\")\n",
    "    for cluster_id, count in cluster_counts.items():\n",
    "        percentage = (count / len(labels)) * 100\n",
    "        print(f\"  Cluster {cluster_id}: {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "    return labels, {\n",
    "        'n_clusters': n_clusters,\n",
    "        'silhouette_score': silhouette,\n",
    "        'runtime_seconds': runtime,\n",
    "        'cluster_sizes': cluster_counts.to_dict()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40acbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Loading & Feature Preparation\n",
    "\n",
    "This section loads the preprocessed crime dataset and prepares features specifically for clustering analysis. We validate coordinate accuracy, assess feature completeness, and prepare the data for various clustering algorithms.\n",
    "\n",
    "## Load Preprocessed Crime Dataset\n",
    "\n",
    "Load and validate the preprocessed crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2d3684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\Data\\final_crime_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (2493835, 44)\n",
      "Memory usage: 2453.35 MB\n",
      "\n",
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "Total records: 2,493,835\n",
      "Total features: 44\n",
      "Memory usage: 2453.35 MB\n",
      "\n",
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "Total records: 2,493,835\n",
      "Total features: 44\n"
     ]
    }
   ],
   "source": [
    "# Define data file path\n",
    "data_file = os.path.join(data_dir, 'final_crime_data.csv')\n",
    "\n",
    "# Check if data file exists\n",
    "if not os.path.exists(data_file):\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_file}\")\n",
    "\n",
    "print(f\"Loading data from: {data_file}\")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Display basic dataset information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985352a",
   "metadata": {},
   "source": [
    "## Data Cleaning and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE VALIDATION\n",
      "============================================================\n",
      "Feature availability:\n",
      "------------------------------\n",
      "Spatial features: ['Latitude', 'Longitude'] (2/2)\n",
      "Temporal features: ['HOUR', 'WEEKDAY', 'MONTH'] (3/3)\n",
      "Categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC'] (3/3)\n",
      "\n",
      "============================================================\n",
      "TEMPORAL FILTERING FOR CLUSTERING\n",
      "============================================================\n",
      "Original dataset years: [np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Total records before temporal filter: 2,493,835\n",
      "Year-Month distribution in original dataset:\n",
      "  202001: 38,695 records\n",
      "  202002: 35,446 records\n",
      "  202003: 32,679 records\n",
      "  202004: 24,907 records\n",
      "  202005: 32,023 records\n",
      "  202006: 32,604 records\n",
      "  202007: 35,531 records\n",
      "  202008: 37,524 records\n",
      "  202009: 35,983 records\n",
      "  202010: 37,403 records\n",
      "  202011: 35,148 records\n",
      "  202012: 33,516 records\n",
      "  202101: 33,217 records\n",
      "  202102: 28,332 records\n",
      "  202103: 34,612 records\n",
      "  202104: 32,619 records\n",
      "  202105: 36,711 records\n",
      "  202106: 37,516 records\n",
      "  202107: 39,402 records\n",
      "  202108: 38,945 records\n",
      "  202109: 39,906 records\n",
      "  202110: 42,994 records\n",
      "  202111: 41,346 records\n",
      "  202112: 40,867 records\n",
      "  202201: 38,353 records\n",
      "  202202: 37,375 records\n",
      "  202203: 43,490 records\n",
      "  202204: 42,508 records\n",
      "  202205: 45,910 records\n",
      "  202206: 47,001 records\n",
      "  202207: 47,372 records\n",
      "  202208: 46,725 records\n",
      "  202209: 45,251 records\n",
      "  202210: 46,394 records\n",
      "  202211: 44,264 records\n",
      "  202212: 42,026 records\n",
      "  202301: 44,708 records\n",
      "  202302: 39,552 records\n",
      "  202303: 44,804 records\n",
      "  202304: 43,964 records\n",
      "  202305: 48,408 records\n",
      "  202306: 47,341 records\n",
      "  202307: 48,413 records\n",
      "  202308: 48,049 records\n",
      "  202309: 45,104 records\n",
      "  202310: 48,281 records\n",
      "  202311: 44,798 records\n",
      "  202312: 44,998 records\n",
      "  202401: 45,803 records\n",
      "  202402: 43,186 records\n",
      "  202403: 45,948 records\n",
      "  202404: 45,040 records\n",
      "  202405: 49,493 records\n",
      "  202406: 49,021 records\n",
      "  202407: 49,961 records\n",
      "  202408: 49,280 records\n",
      "  202409: 47,853 records\n",
      "  202410: 49,267 records\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "\n",
      "Filtering for clustering analysis using classification test set period:\n",
      "Using YearMonth >= 202401 (same as classification test set)\n",
      "Year-Month distribution in original dataset:\n",
      "  202001: 38,695 records\n",
      "  202002: 35,446 records\n",
      "  202003: 32,679 records\n",
      "  202004: 24,907 records\n",
      "  202005: 32,023 records\n",
      "  202006: 32,604 records\n",
      "  202007: 35,531 records\n",
      "  202008: 37,524 records\n",
      "  202009: 35,983 records\n",
      "  202010: 37,403 records\n",
      "  202011: 35,148 records\n",
      "  202012: 33,516 records\n",
      "  202101: 33,217 records\n",
      "  202102: 28,332 records\n",
      "  202103: 34,612 records\n",
      "  202104: 32,619 records\n",
      "  202105: 36,711 records\n",
      "  202106: 37,516 records\n",
      "  202107: 39,402 records\n",
      "  202108: 38,945 records\n",
      "  202109: 39,906 records\n",
      "  202110: 42,994 records\n",
      "  202111: 41,346 records\n",
      "  202112: 40,867 records\n",
      "  202201: 38,353 records\n",
      "  202202: 37,375 records\n",
      "  202203: 43,490 records\n",
      "  202204: 42,508 records\n",
      "  202205: 45,910 records\n",
      "  202206: 47,001 records\n",
      "  202207: 47,372 records\n",
      "  202208: 46,725 records\n",
      "  202209: 45,251 records\n",
      "  202210: 46,394 records\n",
      "  202211: 44,264 records\n",
      "  202212: 42,026 records\n",
      "  202301: 44,708 records\n",
      "  202302: 39,552 records\n",
      "  202303: 44,804 records\n",
      "  202304: 43,964 records\n",
      "  202305: 48,408 records\n",
      "  202306: 47,341 records\n",
      "  202307: 48,413 records\n",
      "  202308: 48,049 records\n",
      "  202309: 45,104 records\n",
      "  202310: 48,281 records\n",
      "  202311: 44,798 records\n",
      "  202312: 44,998 records\n",
      "  202401: 45,803 records\n",
      "  202402: 43,186 records\n",
      "  202403: 45,948 records\n",
      "  202404: 45,040 records\n",
      "  202405: 49,493 records\n",
      "  202406: 49,021 records\n",
      "  202407: 49,961 records\n",
      "  202408: 49,280 records\n",
      "  202409: 47,853 records\n",
      "  202410: 49,267 records\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "\n",
      "Filtering for clustering analysis using classification test set period:\n",
      "Using YearMonth >= 202401 (same as classification test set)\n",
      "Records after temporal filter: 560,820 (22.5% of original)\n",
      "Filtered dataset year-months:\n",
      "  202401: 45,803 records\n",
      "  202402: 43,186 records\n",
      "  202403: 45,948 records\n",
      "  202404: 45,040 records\n",
      "  202405: 49,493 records\n",
      "  202406: 49,021 records\n",
      "  202407: 49,961 records\n",
      "  202408: 49,280 records\n",
      "  202409: 47,853 records\n",
      "  202410: 49,267 records\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "Records after temporal filter: 560,820 (22.5% of original)\n",
      "Filtered dataset year-months:\n",
      "  202401: 45,803 records\n",
      "  202402: 43,186 records\n",
      "  202403: 45,948 records\n",
      "  202404: 45,040 records\n",
      "  202405: 49,493 records\n",
      "  202406: 49,021 records\n",
      "  202407: 49,961 records\n",
      "  202408: 49,280 records\n",
      "  202409: 47,853 records\n",
      "  202410: 49,267 records\n",
      "  202411: 45,568 records\n",
      "  202412: 40,400 records\n",
      "\n",
      "Using filtered dataset for clustering analysis.\n",
      "This approach ensures consistency with classification methodology\n",
      "and focuses on the most recent crime patterns.\n",
      "\n",
      "Preparing dataset for spatial clustering...\n",
      "\n",
      "Using filtered dataset for clustering analysis.\n",
      "This approach ensures consistency with classification methodology\n",
      "and focuses on the most recent crime patterns.\n",
      "\n",
      "Preparing dataset for spatial clustering...\n",
      "Records with valid coordinates: 560,820 (100.00%)\n",
      "Records with valid coordinates: 560,820 (100.00%)\n",
      "Records within NYC bounds: 560,819\n",
      "\n",
      "Final dataset for clustering:\n",
      "Shape: (560819, 44)\n",
      "Coordinate coverage: 560,819 records\n",
      "Time range: 2024 - 2024\n",
      "Records within NYC bounds: 560,819\n",
      "\n",
      "Final dataset for clustering:\n",
      "Shape: (560819, 44)\n",
      "Coordinate coverage: 560,819 records\n",
      "Time range: 2024 - 2024\n",
      "Memory usage: 556.19 MB\n",
      "\n",
      "Extended features availability:\n",
      "----------------------------------------\n",
      "Spatial context features: 16/16 available\n",
      "  Available: ['BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE', 'MIN_POI_DISTANCE']...\n",
      "Extended temporal features: 10/10 available\n",
      "  Available: ['HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY']\n",
      "Extended categorical features: 11/11 available\n",
      "  Available: ['BORO_NM', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PREM_TYP_DESC']...\n",
      "Social features: 2/2 available\n",
      "  Available: ['SAME_AGE_GROUP', 'SAME_SEX']\n",
      "\n",
      "Temporal distribution in filtered dataset:\n",
      "----------------------------------------\n",
      "  2024: 560,819 records\n",
      "\n",
      "Monthly distribution for 2024:\n",
      "----------------------------------------\n",
      "  Month  1: 45,803 records\n",
      "  Month  2: 43,186 records\n",
      "  Month  3: 45,948 records\n",
      "  Month  4: 45,040 records\n",
      "  Month  5: 49,493 records\n",
      "  Month  6: 49,020 records\n",
      "  Month  7: 49,961 records\n",
      "  Month  8: 49,280 records\n",
      "  Month  9: 47,853 records\n",
      "  Month 10: 49,267 records\n",
      "  Month 11: 45,568 records\n",
      "  Month 12: 40,400 records\n",
      "\n",
      "============================================================\n",
      "CLUSTERING DATASET SUMMARY\n",
      "============================================================\n",
      "Dataset period: Gen 2024 onwards\n",
      "Total records for clustering: 560,819\n",
      "Temporal consistency: ✓ Matches classification evaluation period\n",
      "Geographic validity: ✓ NYC coordinate bounds enforced\n",
      "Memory usage: 556.19 MB\n",
      "\n",
      "Extended features availability:\n",
      "----------------------------------------\n",
      "Spatial context features: 16/16 available\n",
      "  Available: ['BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE', 'MIN_POI_DISTANCE']...\n",
      "Extended temporal features: 10/10 available\n",
      "  Available: ['HOUR', 'DAY', 'WEEKDAY', 'IS_WEEKEND', 'MONTH', 'YEAR', 'SEASON', 'TIME_BUCKET', 'IS_HOLIDAY', 'IS_PAYDAY']\n",
      "Extended categorical features: 11/11 available\n",
      "  Available: ['BORO_NM', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PREM_TYP_DESC']...\n",
      "Social features: 2/2 available\n",
      "  Available: ['SAME_AGE_GROUP', 'SAME_SEX']\n",
      "\n",
      "Temporal distribution in filtered dataset:\n",
      "----------------------------------------\n",
      "  2024: 560,819 records\n",
      "\n",
      "Monthly distribution for 2024:\n",
      "----------------------------------------\n",
      "  Month  1: 45,803 records\n",
      "  Month  2: 43,186 records\n",
      "  Month  3: 45,948 records\n",
      "  Month  4: 45,040 records\n",
      "  Month  5: 49,493 records\n",
      "  Month  6: 49,020 records\n",
      "  Month  7: 49,961 records\n",
      "  Month  8: 49,280 records\n",
      "  Month  9: 47,853 records\n",
      "  Month 10: 49,267 records\n",
      "  Month 11: 45,568 records\n",
      "  Month 12: 40,400 records\n",
      "\n",
      "============================================================\n",
      "CLUSTERING DATASET SUMMARY\n",
      "============================================================\n",
      "Dataset period: Gen 2024 onwards\n",
      "Total records for clustering: 560,819\n",
      "Temporal consistency: ✓ Matches classification evaluation period\n",
      "Geographic validity: ✓ NYC coordinate bounds enforced\n"
     ]
    }
   ],
   "source": [
    "# Validate feature availability\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check spatial features\n",
    "spatial_available = [col for col in SPATIAL_FEATURES if col in df.columns]\n",
    "temporal_available = [col for col in TEMPORAL_FEATURES if col in df.columns]\n",
    "categorical_available = [col for col in CATEGORICAL_FEATURES if col in df.columns]\n",
    "\n",
    "print(\"Feature availability:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Spatial features: {spatial_available} ({len(spatial_available)}/{len(SPATIAL_FEATURES)})\")\n",
    "print(f\"Temporal features: {temporal_available} ({len(temporal_available)}/{len(TEMPORAL_FEATURES)})\")\n",
    "print(f\"Categorical features: {categorical_available} ({len(categorical_available)}/{len(CATEGORICAL_FEATURES)})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TEMPORAL FILTERING FOR CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'YEAR' in df.columns and 'MONTH' in df.columns:\n",
    "    print(f\"Original dataset years: {sorted(df['YEAR'].unique())}\")\n",
    "    print(f\"Total records before temporal filter: {len(df):,}\")\n",
    "    \n",
    "    # Create YearMonth for filtering\n",
    "    df['YearMonth'] = df['YEAR'] * 100 + df['MONTH']\n",
    "    print(f\"Year-Month distribution in original dataset:\")\n",
    "    ym_counts = df['YearMonth'].value_counts().sort_index()\n",
    "    for ym, count in ym_counts.items():\n",
    "        print(f\"  {ym}: {count:,} records\")\n",
    "\n",
    "    # Use the temporal split point for 2024\n",
    "    test_set_start_ym = 202401  # January 2024\n",
    "    print(f\"\\nFiltering for clustering analysis with period:\")\n",
    "    print(f\"Using YearMonth >= {test_set_start_ym}\")\n",
    "    \n",
    "    # Apply filter\n",
    "    df_filtered = df[df['YearMonth'] >= test_set_start_ym].copy()\n",
    "    \n",
    "    print(f\"Records after temporal filter: {len(df_filtered):,} ({(len(df_filtered)/len(df))*100:.1f}% of original)\")\n",
    "    \n",
    "    if len(df_filtered) > 0:\n",
    "        print(f\"Filtered dataset year-months:\")\n",
    "        filtered_ym_counts = df_filtered['YearMonth'].value_counts().sort_index()\n",
    "        for ym, count in filtered_ym_counts.items():\n",
    "            print(f\"  {ym}: {count:,} records\")\n",
    "        \n",
    "        # Drop the temporary YearMonth column\n",
    "        df_filtered.drop(columns=['YearMonth'], inplace=True)\n",
    "        df.drop(columns=['YearMonth'], inplace=True)\n",
    "        \n",
    "        # Use filtered data for clustering\n",
    "        df = df_filtered\n",
    "        print(f\"\\nUsing filtered dataset for clustering analysis.\")\n",
    "    else:\n",
    "        print(f\"Warning: No data found for YearMonth >= {test_set_start_ym}\")\n",
    "        print(\"Falling back to recent years filter (YEAR >= 2023)\")\n",
    "        # Fallback to the previous approach\n",
    "        recent_years_threshold = 2023\n",
    "        df_filtered = df[df['YEAR'] >= recent_years_threshold].copy()\n",
    "        df = df_filtered\n",
    "        df.drop(columns=['YearMonth'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: YEAR or MONTH column not found. Skipping temporal filtering.\")\n",
    "    print(\"Using full dataset for clustering analysis.\")\n",
    "\n",
    "# Create clean dataset for spatial analysis\n",
    "print(f\"\\nPreparing dataset for spatial clustering...\")\n",
    "\n",
    "# Filter for valid coordinates\n",
    "if len(spatial_available) >= 2:\n",
    "    # Remove rows with missing coordinates\n",
    "    valid_coords_mask = df[spatial_available].notna().all(axis=1)\n",
    "    df_spatial = df[valid_coords_mask].copy()\n",
    "    \n",
    "    print(f\"Records with valid coordinates: {len(df_spatial):,} ({(len(df_spatial)/len(df))*100:.2f}%)\")\n",
    "    \n",
    "    # Additional coordinate validation\n",
    "    lat_col = 'Latitude'\n",
    "    lon_col = 'Longitude'\n",
    "    \n",
    "    if lat_col in df_spatial.columns and lon_col in df_spatial.columns:\n",
    "        # NYC coordinate bounds\n",
    "        nyc_bounds_mask = (\n",
    "            df_spatial[lat_col].between(40.4774, 40.9176) &\n",
    "            df_spatial[lon_col].between(-74.2591, -73.7004)\n",
    "        )\n",
    "        df_spatial = df_spatial[nyc_bounds_mask].copy()\n",
    "        \n",
    "        print(f\"Records within NYC bounds: {len(df_spatial):,}\")\n",
    "    else:\n",
    "        print(f\"Warning: Coordinate columns {lat_col}/{lon_col} not found for geographic filtering\")\n",
    "else:\n",
    "    raise ValueError(\"Insufficient spatial features for clustering analysis\")\n",
    "\n",
    "# Display final dataset summary\n",
    "print(f\"\\nFinal dataset for clustering:\")\n",
    "print(f\"Shape: {df_spatial.shape}\")\n",
    "print(f\"Coordinate coverage: {len(df_spatial):,} records\")\n",
    "print(f\"Time range: {df_spatial['YEAR'].min()} - {df_spatial['YEAR'].max()}\")\n",
    "print(f\"Memory usage: {df_spatial.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check availability of extended features\n",
    "print(f\"\\nExtended features availability:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check spatial context features (POI-based)\n",
    "spatial_context_available = [col for col in SPATIAL_CONTEXT_FEATURES if col in df.columns]\n",
    "print(f\"Spatial context features: {len(spatial_context_available)}/{len(SPATIAL_CONTEXT_FEATURES)} available\")\n",
    "if spatial_context_available:\n",
    "    print(f\"  Available: {spatial_context_available[:5]}...\")  # Show first 5\n",
    "\n",
    "# Check extended temporal features\n",
    "extended_temporal_available = [col for col in EXTENDED_TEMPORAL_FEATURES if col in df.columns]\n",
    "print(f\"Extended temporal features: {len(extended_temporal_available)}/{len(EXTENDED_TEMPORAL_FEATURES)} available\")\n",
    "if extended_temporal_available:\n",
    "    print(f\"  Available: {extended_temporal_available}\")\n",
    "\n",
    "# Check extended categorical features\n",
    "extended_categorical_available = [col for col in EXTENDED_CATEGORICAL_FEATURES if col in df.columns]\n",
    "print(f\"Extended categorical features: {len(extended_categorical_available)}/{len(EXTENDED_CATEGORICAL_FEATURES)} available\")\n",
    "if extended_categorical_available:\n",
    "    print(f\"  Available: {extended_categorical_available[:5]}...\")  # Show first 5\n",
    "\n",
    "# Check social features\n",
    "social_available = [col for col in SOCIAL_FEATURES if col in df.columns]\n",
    "print(f\"Social features: {len(social_available)}/{len(SOCIAL_FEATURES)} available\")\n",
    "if social_available:\n",
    "    print(f\"  Available: {social_available}\")\n",
    "\n",
    "# Display temporal distribution after filtering\n",
    "if 'YEAR' in df_spatial.columns and 'MONTH' in df_spatial.columns:\n",
    "    print(f\"\\nTemporal distribution in filtered dataset:\")\n",
    "    print(\"-\" * 40)\n",
    "    yearly_counts = df_spatial['YEAR'].value_counts().sort_index()\n",
    "    for year, count in yearly_counts.items():\n",
    "        print(f\"  {year}: {count:,} records\")\n",
    "    \n",
    "    # Show monthly distribution for each year in the filtered data\n",
    "    years_in_data = sorted(df_spatial['YEAR'].unique())\n",
    "    for year in years_in_data:\n",
    "        monthly_counts = df_spatial[df_spatial['YEAR'] == year]['MONTH'].value_counts().sort_index()\n",
    "        print(f\"\\nMonthly distribution for {year}:\")\n",
    "        print(\"-\" * 40)\n",
    "        for month, count in monthly_counts.items():\n",
    "            print(f\"  Month {month:2d}: {count:,} records\")\n",
    "\n",
    "# Final clustering dataset summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"CLUSTERING DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset period: Gen 2024 onwards\")\n",
    "print(f\"Total records for clustering: {len(df_spatial):,}\")\n",
    "print(f\"Geographic validity: ✓ NYC coordinate bounds enforced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "873345a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stratified sample by BORO_NM: 5,000 rows out of 560,819 total\n",
      "Stratum distribution (sample):\n",
      "  BRONX: 1,091 (0.218)\n",
      "  BROOKLYN: 1,383 (0.277)\n",
      "  MANHATTAN: 1,204 (0.241)\n",
      "  QUEENS: 1,109 (0.222)\n",
      "  STATEN ISLAND: 213 (0.043)\n",
      "Dataset created: 5000 rows out of 560819 total\n",
      "    BORO_NM  KY_CD   LAW_CAT_CD LOC_OF_OCCUR_DESC                 OFNS_DESC  \\\n",
      "0  BROOKLYN    348  MISDEMEANOR              REAR  VEHICLE AND TRAFFIC LAWS   \n",
      "\n",
      "   PD_CD PREM_TYP_DESC SUSP_AGE_GROUP SUSP_RACE SUSP_SEX VIC_AGE_GROUP  \\\n",
      "0    916        STREET        UNKNOWN   UNKNOWN        U       UNKNOWN   \n",
      "\n",
      "  VIC_RACE VIC_SEX   Latitude  Longitude  BAR_DISTANCE  NIGHTCLUB_DISTANCE  \\\n",
      "0    BLACK       E  40.653066 -73.889789    2932.76284         4077.648209   \n",
      "\n",
      "   ATM_DISTANCE  ATMS_COUNT  BARS_COUNT  BUS_STOPS_COUNT  METROS_COUNT  \\\n",
      "0   4893.870711         0.0         0.0              1.0           0.0   \n",
      "\n",
      "   NIGHTCLUBS_COUNT  SCHOOLS_COUNT  METRO_DISTANCE  MIN_POI_DISTANCE  \\\n",
      "0               0.0            0.0      812.508149        812.508149   \n",
      "\n",
      "   AVG_POI_DISTANCE  MAX_POI_DISTANCE  TOTAL_POI_COUNT  POI_DIVERSITY  \\\n",
      "0       3179.197477       4893.870711              1.0              1   \n",
      "\n",
      "   POI_DENSITY_SCORE  HOUR  DAY WEEKDAY  IS_WEEKEND  MONTH  YEAR  SEASON  \\\n",
      "0           0.111111    23   19  MONDAY           0      8  2024  SUMMER   \n",
      "\n",
      "  TIME_BUCKET  IS_HOLIDAY  IS_PAYDAY  SAME_AGE_GROUP  SAME_SEX  \\\n",
      "0     EVENING           0          0               0         0   \n",
      "\n",
      "   TO_CHECK_CITIZENS  \n",
      "0                  0  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Configuration: Full Dataset vs Sample ---\n",
    "# Set to True to use full dataset, False to use sample\n",
    "USE_FULL_DATA = False\n",
    "\n",
    "# Helper: balanced stratified sampling with shortfall redistribution\n",
    "def stratified_sample_balanced(df_in, strat_col, n_total, random_state=42):\n",
    "    if strat_col not in df_in.columns:\n",
    "        # Fallback to simple sample\n",
    "        n_take = min(n_total, len(df_in))\n",
    "        return df_in.sample(n_take, random_state=random_state)\n",
    "\n",
    "    df_in = df_in[df_in[strat_col].notna()].copy()\n",
    "    if len(df_in) == 0:\n",
    "        return df_in\n",
    "\n",
    "    total = len(df_in)\n",
    "    if n_total >= total:\n",
    "        # If asking more than available, return all rows\n",
    "        return df_in.sample(frac=1.0, random_state=random_state)\n",
    "\n",
    "    sizes = df_in[strat_col].value_counts().sort_index()\n",
    "    groups = df_in.groupby(strat_col)\n",
    "\n",
    "    # Ideal proportional allocation\n",
    "    ideal = sizes / total * n_total\n",
    "    base = np.floor(ideal).astype(int)\n",
    "\n",
    "    # Cap by availability\n",
    "    cap = sizes\n",
    "    alloc = base.clip(upper=cap)\n",
    "\n",
    "    # Largest remainder method + capacity-aware fill to reach exactly n_total\n",
    "    remaining = int(n_total - alloc.sum())\n",
    "    remainders = (ideal - base)\n",
    "\n",
    "    # First pass: distribute by largest remainders\n",
    "    for key in remainders.sort_values(ascending=False).index:\n",
    "        if remaining == 0:\n",
    "            break\n",
    "        if alloc[key] < cap[key]:\n",
    "            alloc[key] += 1\n",
    "            remaining -= 1\n",
    "\n",
    "    # If still remaining, do capacity-aware round-robin until filled or no capacity left\n",
    "    while remaining > 0:\n",
    "        progressed = False\n",
    "        for key in remainders.sort_values(ascending=False).index:\n",
    "            if remaining == 0:\n",
    "                break\n",
    "            if alloc[key] < cap[key]:\n",
    "                alloc[key] += 1\n",
    "                remaining -= 1\n",
    "                progressed = True\n",
    "        if not progressed:\n",
    "            break  # No more capacity anywhere\n",
    "\n",
    "    # Draw samples per stratum deterministically\n",
    "    parts = []\n",
    "    for key, g in groups:\n",
    "        k = int(alloc.get(key, 0))\n",
    "        if k <= 0:\n",
    "            continue\n",
    "        if k >= len(g):\n",
    "            parts.append(g)\n",
    "        else:\n",
    "            parts.append(g.sample(n=k, random_state=random_state))\n",
    "\n",
    "    out = pd.concat(parts, axis=0)\n",
    "    # Final shuffle for randomness while preserving reproducibility\n",
    "    out = out.sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Safety: trim in rare case of over-allocation due to concurrency of caps\n",
    "    if len(out) > n_total:\n",
    "        out = out.iloc[:n_total].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "# Configure dataset based on flag\n",
    "if USE_FULL_DATA:\n",
    "    df = df_spatial.copy()\n",
    "    print(f\"Using full dataset: {df.shape[0]:,} rows\")\n",
    "else:\n",
    "    N_SAMPLE = 5_000  # target number of rows to take\n",
    "    if 'BORO_NM' in df_spatial.columns and df_spatial['BORO_NM'].notna().any():\n",
    "        df = stratified_sample_balanced(df_spatial, 'BORO_NM', N_SAMPLE, random_state=RANDOM_STATE).copy()\n",
    "        print(f\"Using stratified sample by BORO_NM: {df.shape[0]:,} rows out of {df_spatial.shape[0]:,} total\")\n",
    "        try:\n",
    "            counts = df['BORO_NM'].value_counts().sort_index()\n",
    "            props = (counts / len(df)).round(3)\n",
    "            print(\"Stratum distribution (sample):\")\n",
    "            for name, count in counts.items():\n",
    "                print(f\"  {name}: {count:,} ({props[name]:.3f})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    else:\n",
    "        n_take = min(N_SAMPLE, len(df_spatial))\n",
    "        df = df_spatial.sample(n_take, random_state=RANDOM_STATE).copy()\n",
    "        print(f\"Using simple sample: {df.shape[0]:,} rows out of {df_spatial.shape[0]:,} total\")\n",
    "\n",
    "print(f\"Dataset created: {df.shape[0]} rows out of {df_spatial.shape[0]} total\")\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 44)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92631f25",
   "metadata": {},
   "source": [
    "## 3. K-Modes for Categorical Crime Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a50ce7",
   "metadata": {},
   "source": [
    "### Categorical Feature Preparation for K-Modes\n",
    "\n",
    "K-Modes clustering is specifically designed for categorical data. We prepare our categorical features for pattern discovery in crime types, locations, and demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL FEATURE PREPARATION FOR K-MODES ===\n",
      "Base categorical features:Base categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
      "Added operational categorical features: ['TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY']\n",
      "Added POI/context bins: [np.str_('METRO_DISTANCE_BIN'), np.str_('TOTAL_POI_COUNT_BIN'), np.str_('POI_DENSITY_SCORE_BIN')]\n",
      "Added demographics (race excluded): ['SUSP_SEX', 'SUSP_AGE_GROUP', 'VIC_SEX', 'VIC_AGE_GROUP']\n",
      "Total categorical features for K-Modes: 13\n",
      "Rows available for K-Modes after base-feature check: 5,000\n",
      "Feature matrix shape: (5000, 13)\n",
      "First feature columns: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC', 'TIME_BUCKET', 'IS_WEEKEND']\n",
      " ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
      "Added operational categorical features: ['TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY']\n",
      "Added POI/context bins: [np.str_('METRO_DISTANCE_BIN'), np.str_('TOTAL_POI_COUNT_BIN'), np.str_('POI_DENSITY_SCORE_BIN')]\n",
      "Added demographics (race excluded): ['SUSP_SEX', 'SUSP_AGE_GROUP', 'VIC_SEX', 'VIC_AGE_GROUP']\n",
      "Total categorical features for K-Modes: 13\n",
      "Rows available for K-Modes after base-feature check: 5,000\n",
      "Feature matrix shape: (5000, 13)\n",
      "First feature columns: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC', 'TIME_BUCKET', 'IS_WEEKEND']\n"
     ]
    }
   ],
   "source": [
    "# Define categorical features for K-Modes clustering\n",
    "# Base, highly interpretable police features\n",
    "BASE_KMODES_FEATURES = ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC']\n",
    "\n",
    "# Additional categorical features directly useful for operations\n",
    "# Kept: severity, detailed location, coarse time bucket, weekend/holiday flags\n",
    "# Commented out: WEEKDAY (redundant with TIME_BUCKET), IS_PAYDAY (low impact), SAME_* flags (low operational signal)\n",
    "EXTRA_CATEGORICAL_FEATURES = [\n",
    "    # 'LAW_CAT_CD',               # Optional: not useful having OFNS_DESC\n",
    "    # 'LOC_OF_OCCUR_DESC',        # Optional: not useful having PREM_TYP_DESC\n",
    "    'TIME_BUCKET',              # Coarse time-of-day buckets\n",
    "    'IS_WEEKEND', 'IS_HOLIDAY', # Operationally meaningful flags\n",
    "    # 'WEEKDAY',               # Optional: more granular temporal, commented to reduce noise\n",
    "    # 'IS_PAYDAY',            # Optional: typically low impact\n",
    "    # 'SAME_AGE_GROUP',       # Optional: low operational value\n",
    "    # 'SAME_SEX',             # Optional: low operational value\n",
    "]\n",
    "\n",
    "# Demographics: keep age/sex; exclude race to avoid bias and improve fairness\n",
    "DEMOGRAPHIC_CATEGORICAL = [\n",
    "    'SUSP_SEX', 'SUSP_AGE_GROUP',\n",
    "    'VIC_SEX', 'VIC_AGE_GROUP',\n",
    "    # 'SUSP_RACE', 'VIC_RACE',   # Excluded intentionally\n",
    "]\n",
    "\n",
    "# Numeric POI/distances transformed into interpretable categories\n",
    "DISTANCE_COLS = [\n",
    "    'METRO_DISTANCE',\n",
    "    # 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE',\n",
    "    # 'MIN_POI_DISTANCE', 'AVG_POI_DISTANCE', 'MAX_POI_DISTANCE',\n",
    "]\n",
    "COUNT_COLS = [\n",
    "    # 'TOTAL_POI_COUNT',\n",
    "    # 'ATMS_COUNT', 'BARS_COUNT', 'BUS_STOPS_COUNT', 'METROS_COUNT',\n",
    "    # 'NIGHTCLUBS_COUNT', 'SCHOOLS_COUNT',\n",
    "]\n",
    "SCORE_COLS = [\n",
    "    'POI_DENSITY_SCORE',\n",
    "    # 'POI_DIVERSITY',\n",
    "]\n",
    "\n",
    "print(\"=== CATEGORICAL FEATURE PREPARATION FOR K-MODES ===\")\n",
    "\n",
    "# Use the configured dataset\n",
    "_df = df.copy()\n",
    "\n",
    "def top_k_map(series, k=10):\n",
    "    if series.isna().all():\n",
    "        return series.fillna('Unknown')\n",
    "    vc = series.value_counts()\n",
    "    top = set(vc.head(k).index)\n",
    "    return series.where(series.isin(top), 'OTHER').astype(str).fillna('Unknown')\n",
    "\n",
    "# Use ColumnBinner instead of inline binning helpers\n",
    "binner_config = {\n",
    "    'METRO_DISTANCE': {\n",
    "        'kind': 'distance',\n",
    "        'bins': [-np.inf, 250, 1000, np.inf],\n",
    "        'labels': ['Near', 'Mid', 'Far']\n",
    "    },\n",
    "    'TOTAL_POI_COUNT': {\n",
    "        'kind': 'count',\n",
    "        'quantiles': 4,\n",
    "        'labels': ['Low', 'Medium', 'High', 'VeryHigh'],\n",
    "        'zero_label': 'Zero'\n",
    "    },\n",
    "    'POI_DENSITY_SCORE': {\n",
    "        'kind': 'score',\n",
    "        'quantiles': 4,\n",
    "        'labels': ['Low', 'Medium', 'High', 'VeryHigh']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Instantiate and apply binner\n",
    "column_binner = ColumnBinner(config=binner_config, suffix=\"_BIN\", fill_unknown=\"Unknown\")\n",
    "column_binner.fit(_df)\n",
    "_df = column_binner.transform(_df)\n",
    "\n",
    "# Track created bins consistently\n",
    "created_bins = [col for col in column_binner.get_feature_names_out() if col in _df.columns]\n",
    "\n",
    "# Apply top-K mapping to selected demographics (race excluded)\n",
    "for col in DEMOGRAPHIC_CATEGORICAL:\n",
    "    if col in _df.columns:\n",
    "        k = 10\n",
    "        _df[col] = top_k_map(_df[col].astype(str), k=k)\n",
    "\n",
    "# Ensure core categoricals are strings and filled\n",
    "for col in BASE_KMODES_FEATURES + EXTRA_CATEGORICAL_FEATURES:\n",
    "    if col in _df.columns:\n",
    "        _df[col] = _df[col].astype(str).fillna('Unknown')\n",
    "\n",
    "# Compose the final feature list for K-Modes\n",
    "CATEGORICAL_FEATURES_KMODES = BASE_KMODES_FEATURES + [\n",
    "    c for c in EXTRA_CATEGORICAL_FEATURES if c in _df.columns\n",
    "] + created_bins + [c for c in DEMOGRAPHIC_CATEGORICAL if c in _df.columns]\n",
    "\n",
    "print(\"Base categorical features:\", BASE_KMODES_FEATURES)\n",
    "print(\"Added operational categorical features:\", [c for c in EXTRA_CATEGORICAL_FEATURES if c in _df.columns])\n",
    "print(\"Added POI/context bins:\", created_bins)\n",
    "print(\"Added demographics (race excluded):\", [c for c in DEMOGRAPHIC_CATEGORICAL if c in _df.columns])\n",
    "\n",
    "# Check feature availability\n",
    "categorical_available = [col for col in CATEGORICAL_FEATURES_KMODES if col in _df.columns]\n",
    "print(f\"Total categorical features for K-Modes: {len(categorical_available)}\")\n",
    "\n",
    "# Prepare dataset holders used downstream\n",
    "if not categorical_available:\n",
    "    raise ValueError(\"No categorical features available for K-Modes clustering\")\n",
    "\n",
    "# Keep a wide copy for labeling/ops; drop rows only if core/base features are missing\n",
    "# (to avoid losing useful non-feature columns like HOUR, IS_WEEKEND later)\n",
    "df_kmodes_input = _df.copy()\n",
    "required_for_row = [c for c in BASE_KMODES_FEATURES if c in df_kmodes_input.columns]\n",
    "df_kmodes = df_kmodes_input.dropna(subset=required_for_row).copy() if required_for_row else df_kmodes_input.copy()\n",
    "\n",
    "# Build X_categorical as the feature matrix used by the pipeline\n",
    "CATEGORICAL_FEATURES_KMODES_AVAILABLE = [c for c in CATEGORICAL_FEATURES_KMODES if c in df_kmodes.columns]\n",
    "X_categorical = df_kmodes[CATEGORICAL_FEATURES_KMODES_AVAILABLE].astype(str).fillna('Unknown')\n",
    "\n",
    "print(f\"Rows available for K-Modes after base-feature check: {len(df_kmodes):,}\")\n",
    "print(f\"Feature matrix shape: {X_categorical.shape}\")\n",
    "print(f\"First feature columns: {CATEGORICAL_FEATURES_KMODES_AVAILABLE[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b8023",
   "metadata": {},
   "source": [
    "### K-Modes Pipeline Construction\n",
    "\n",
    "Following the same modular pipeline approach as SpatialHotspotAnalysis, we create a preprocessing pipeline for categorical features and K-Modes clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01eef35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES PIPELINE CONSTRUCTION ===\n",
      "✓ K-Modes pipeline constructed successfully\n",
      "Pipeline steps: ['preprocess', 'cluster']\n",
      "Parameter grid defined:\n",
      "  n_clusters: [3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  init methods: ['Huang', 'Cao']\n",
      "  n_init: [5, 10]\n",
      "Total combinations: 32\n",
      "\n",
      "=== DATA PREPARATION FOR K-MODES ===\n",
      "Processed data shape: (5000, 13)\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "First few samples:\n",
      "  Sample 1: ['BROOKLYN' 'VEHICLE AND TRAFFIC LAWS' 'STREET' 'EVENING' '0' '0' 'Mid'\n",
      " 'High' 'High' 'U' 'UNKNOWN' 'E' 'UNKNOWN']\n",
      "  Sample 2: ['MANHATTAN' 'HARRASSMENT 2' 'COMMERCIAL BUILDING' 'MORNING' '0' '0'\n",
      " 'Near' 'High' 'High' 'M' '25-44' 'F' '25-44']\n",
      "  Sample 3: ['MANHATTAN' 'HARRASSMENT 2' 'STREET' 'AFTERNOON' '0' '0' 'Mid' 'Low'\n",
      " 'Low' 'F' 'UNKNOWN' 'M' '<18']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== K-MODES PIPELINE CONSTRUCTION ===\")\n",
    "\n",
    "# Create preprocessing pipeline (following SpatialHotspotAnalysis structure)\n",
    "# CategoricalPreprocessor is now imported from clustering_transformers\n",
    "categorical_preprocessor = CategoricalPreprocessor(handle_missing='drop')\n",
    "\n",
    "# K-Modes clustering pipeline (similar to DBSCAN pipeline in SpatialHotspotAnalysis)\n",
    "kmodes_pipeline = Pipeline([\n",
    "    ('preprocess', categorical_preprocessor),\n",
    "    ('cluster', KModes(n_clusters=5, init='Huang', n_init=5, verbose=1, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "print(\"✓ K-Modes pipeline constructed successfully\")\n",
    "print(f\"Pipeline steps: {[step[0] for step in kmodes_pipeline.steps]}\")\n",
    "\n",
    "# Define parameter grid for systematic exploration\n",
    "kmodes_param_grid = {\n",
    "    'cluster__n_clusters': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'cluster__init': ['Huang', 'Cao'],\n",
    "    'cluster__n_init': [5, 10]\n",
    "}\n",
    "\n",
    "print(f\"Parameter grid defined:\")\n",
    "print(f\"  n_clusters: {kmodes_param_grid['cluster__n_clusters']}\")\n",
    "print(f\"  init methods: {kmodes_param_grid['cluster__init']}\")\n",
    "print(f\"  n_init: {kmodes_param_grid['cluster__n_init']}\")\n",
    "print(f\"Total combinations: {len(list(ParameterGrid(kmodes_param_grid)))}\")\n",
    "\n",
    "# Prepare data for clustering (convert to numpy array as K-Modes expects)\n",
    "print(f\"\\n=== DATA PREPARATION FOR K-MODES ===\")\n",
    "X_categorical_processed = categorical_preprocessor.fit_transform(X_categorical)\n",
    "X_categorical_array = X_categorical_processed.values  # K-Modes requires numpy array\n",
    "\n",
    "print(f\"Processed data shape: {X_categorical_array.shape}\")\n",
    "print(f\"Data type: {type(X_categorical_array)}\")\n",
    "print(f\"First few samples:\")\n",
    "for i in range(min(3, len(X_categorical_array))):\n",
    "    print(f\"  Sample {i+1}: {X_categorical_array[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d640f5",
   "metadata": {},
   "source": [
    "### K-Modes Parameter Grid Search & Evaluation\n",
    "\n",
    "Following the same systematic parameter optimization approach as SpatialHotspotAnalysis, we perform grid search to find optimal K-Modes parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f7d85ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES PARAMETER GRID SEARCH ===\n",
      "Starting grid search with 32 parameter combinations...\n",
      "\\nTesting combination 1: n_clusters=3, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1340, cost: 30492.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1340, cost: 30492.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1797, cost: 30391.0\n",
      "Run 2, iteration: 1/100, moves: 1797, cost: 30391.0\n",
      "Run 2, iteration: 2/100, moves: 347, cost: 30391.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 2/100, moves: 347, cost: 30391.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1158, cost: 31601.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 1158, cost: 31601.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1152, cost: 30198.0\n",
      "Run 4, iteration: 1/100, moves: 1152, cost: 30198.0\n",
      "Run 4, iteration: 2/100, moves: 609, cost: 30198.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 2/100, moves: 609, cost: 30198.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1088, cost: 30221.0\n",
      "Run 5, iteration: 2/100, moves: 294, cost: 30221.0\n",
      "Best run was number 4\n",
      "Run 5, iteration: 1/100, moves: 1088, cost: 30221.0\n",
      "Run 5, iteration: 2/100, moves: 294, cost: 30221.0\n",
      "Best run was number 4\n",
      "  Runtime: 4.67s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1347-2109\n",
      "  Balance ratio: 1.57\n",
      "  Avg dissimilarity: 6.040\n",
      "  Composite score: 0.1264\n",
      "\\nTesting combination 2: n_clusters=3, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 4.67s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1347-2109\n",
      "  Balance ratio: 1.57\n",
      "  Avg dissimilarity: 6.040\n",
      "  Composite score: 0.1264\n",
      "\\nTesting combination 2: n_clusters=3, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1340, cost: 30492.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1340, cost: 30492.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1797, cost: 30391.0\n",
      "Run 2, iteration: 1/100, moves: 1797, cost: 30391.0\n",
      "Run 2, iteration: 2/100, moves: 347, cost: 30391.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 347, cost: 30391.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1158, cost: 31601.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1158, cost: 31601.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1152, cost: 30198.0\n",
      "Run 4, iteration: 2/100, moves: 609, cost: 30198.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 1/100, moves: 1152, cost: 30198.0\n",
      "Run 4, iteration: 2/100, moves: 609, cost: 30198.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1088, cost: 30221.0\n",
      "Run 5, iteration: 1/100, moves: 1088, cost: 30221.0\n",
      "Run 5, iteration: 2/100, moves: 294, cost: 30221.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 2/100, moves: 294, cost: 30221.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1212, cost: 30017.0\n",
      "Run 6, iteration: 1/100, moves: 1212, cost: 30017.0\n",
      "Run 6, iteration: 2/100, moves: 791, cost: 30017.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 2/100, moves: 791, cost: 30017.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1063, cost: 30663.0\n",
      "Run 7, iteration: 2/100, moves: 143, cost: 30663.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 1/100, moves: 1063, cost: 30663.0\n",
      "Run 7, iteration: 2/100, moves: 143, cost: 30663.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1307, cost: 29851.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1307, cost: 29851.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1567, cost: 29395.0\n",
      "Run 9, iteration: 1/100, moves: 1567, cost: 29395.0\n",
      "Run 9, iteration: 2/100, moves: 1023, cost: 29275.0\n",
      "Run 9, iteration: 3/100, moves: 28, cost: 29275.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 1023, cost: 29275.0\n",
      "Run 9, iteration: 3/100, moves: 28, cost: 29275.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1400, cost: 31995.0\n",
      "Best run was number 9\n",
      "Run 10, iteration: 1/100, moves: 1400, cost: 31995.0\n",
      "Best run was number 9\n",
      "  Runtime: 8.66s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1374-2145\n",
      "  Balance ratio: 1.56\n",
      "  Avg dissimilarity: 5.855\n",
      "  Composite score: 0.1303\n",
      "\\nTesting combination 3: n_clusters=4, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "  Runtime: 8.66s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1374-2145\n",
      "  Balance ratio: 1.56\n",
      "  Avg dissimilarity: 5.855\n",
      "  Composite score: 0.1303\n",
      "\\nTesting combination 3: n_clusters=4, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1881, cost: 28714.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 1881, cost: 28714.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1637, cost: 29606.0\n",
      "Run 2, iteration: 1/100, moves: 1637, cost: 29606.0\n",
      "Run 2, iteration: 2/100, moves: 709, cost: 29017.0\n",
      "Run 2, iteration: 2/100, moves: 709, cost: 29017.0\n",
      "Run 2, iteration: 3/100, moves: 422, cost: 28963.0\n",
      "Run 2, iteration: 3/100, moves: 422, cost: 28963.0\n",
      "Run 2, iteration: 4/100, moves: 24, cost: 28963.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 4/100, moves: 24, cost: 28963.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1802, cost: 30141.0\n",
      "Run 3, iteration: 1/100, moves: 1802, cost: 30141.0\n",
      "Run 3, iteration: 2/100, moves: 191, cost: 30090.0\n",
      "Run 3, iteration: 2/100, moves: 191, cost: 30090.0\n",
      "Run 3, iteration: 3/100, moves: 15, cost: 30090.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 3/100, moves: 15, cost: 30090.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1967, cost: 28972.0\n",
      "Run 4, iteration: 1/100, moves: 1967, cost: 28972.0\n",
      "Run 4, iteration: 2/100, moves: 859, cost: 28697.0\n",
      "Run 4, iteration: 3/100, moves: 185, cost: 28697.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 859, cost: 28697.0\n",
      "Run 4, iteration: 3/100, moves: 185, cost: 28697.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1424, cost: 29944.0\n",
      "Run 5, iteration: 1/100, moves: 1424, cost: 29944.0\n",
      "Run 5, iteration: 2/100, moves: 623, cost: 29699.0\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 29699.0\n",
      "Best run was number 4\n",
      "Run 5, iteration: 2/100, moves: 623, cost: 29699.0\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 29699.0\n",
      "Best run was number 4\n",
      "  Runtime: 7.08s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 888-1904\n",
      "  Balance ratio: 2.14\n",
      "  Avg dissimilarity: 5.739\n",
      "  Composite score: 0.1269\n",
      "\\nTesting combination 4: n_clusters=4, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 7.08s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 888-1904\n",
      "  Balance ratio: 2.14\n",
      "  Avg dissimilarity: 5.739\n",
      "  Composite score: 0.1269\n",
      "\\nTesting combination 4: n_clusters=4, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1881, cost: 28714.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 1881, cost: 28714.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1637, cost: 29606.0\n",
      "Run 2, iteration: 1/100, moves: 1637, cost: 29606.0\n",
      "Run 2, iteration: 2/100, moves: 709, cost: 29017.0\n",
      "Run 2, iteration: 2/100, moves: 709, cost: 29017.0\n",
      "Run 2, iteration: 3/100, moves: 422, cost: 28963.0\n",
      "Run 2, iteration: 4/100, moves: 24, cost: 28963.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 422, cost: 28963.0\n",
      "Run 2, iteration: 4/100, moves: 24, cost: 28963.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1802, cost: 30141.0\n",
      "Run 3, iteration: 2/100, moves: 191, cost: 30090.0\n",
      "Run 3, iteration: 1/100, moves: 1802, cost: 30141.0\n",
      "Run 3, iteration: 2/100, moves: 191, cost: 30090.0\n",
      "Run 3, iteration: 3/100, moves: 15, cost: 30090.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 3/100, moves: 15, cost: 30090.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1967, cost: 28972.0\n",
      "Run 4, iteration: 1/100, moves: 1967, cost: 28972.0\n",
      "Run 4, iteration: 2/100, moves: 859, cost: 28697.0\n",
      "Run 4, iteration: 3/100, moves: 185, cost: 28697.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 2/100, moves: 859, cost: 28697.0\n",
      "Run 4, iteration: 3/100, moves: 185, cost: 28697.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1424, cost: 29944.0\n",
      "Run 5, iteration: 2/100, moves: 623, cost: 29699.0\n",
      "Run 5, iteration: 1/100, moves: 1424, cost: 29944.0\n",
      "Run 5, iteration: 2/100, moves: 623, cost: 29699.0\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 29699.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 3/100, moves: 28, cost: 29699.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1053, cost: 28818.0\n",
      "Run 6, iteration: 1/100, moves: 1053, cost: 28818.0\n",
      "Run 6, iteration: 2/100, moves: 588, cost: 28562.0\n",
      "Run 6, iteration: 3/100, moves: 187, cost: 28562.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 588, cost: 28562.0\n",
      "Run 6, iteration: 3/100, moves: 187, cost: 28562.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1363, cost: 29494.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1363, cost: 29494.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1393, cost: 29220.0\n",
      "Run 8, iteration: 1/100, moves: 1393, cost: 29220.0\n",
      "Run 8, iteration: 2/100, moves: 691, cost: 29123.0\n",
      "Run 8, iteration: 2/100, moves: 691, cost: 29123.0\n",
      "Run 8, iteration: 3/100, moves: 135, cost: 29123.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 3/100, moves: 135, cost: 29123.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1241, cost: 29399.0\n",
      "Run 9, iteration: 1/100, moves: 1241, cost: 29399.0\n",
      "Run 9, iteration: 2/100, moves: 183, cost: 29399.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 183, cost: 29399.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1682, cost: 28199.0\n",
      "Run 10, iteration: 1/100, moves: 1682, cost: 28199.0\n",
      "Run 10, iteration: 2/100, moves: 604, cost: 28135.0\n",
      "Run 10, iteration: 3/100, moves: 14, cost: 28135.0\n",
      "Best run was number 10\n",
      "Run 10, iteration: 2/100, moves: 604, cost: 28135.0\n",
      "Run 10, iteration: 3/100, moves: 14, cost: 28135.0\n",
      "Best run was number 10\n",
      "  Runtime: 10.95s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 800-1720\n",
      "  Balance ratio: 2.15\n",
      "  Avg dissimilarity: 5.627\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 5: n_clusters=5, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "  Runtime: 10.95s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 800-1720\n",
      "  Balance ratio: 2.15\n",
      "  Avg dissimilarity: 5.627\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 5: n_clusters=5, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1248, cost: 28633.0\n",
      "Run 1, iteration: 1/100, moves: 1248, cost: 28633.0\n",
      "Run 1, iteration: 2/100, moves: 309, cost: 28633.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 309, cost: 28633.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1220, cost: 27843.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 1/100, moves: 1220, cost: 27843.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1355, cost: 28744.0\n",
      "Run 3, iteration: 2/100, moves: 530, cost: 28370.0\n",
      "Run 3, iteration: 1/100, moves: 1355, cost: 28744.0\n",
      "Run 3, iteration: 2/100, moves: 530, cost: 28370.0\n",
      "Run 3, iteration: 3/100, moves: 562, cost: 28111.0\n",
      "Run 3, iteration: 4/100, moves: 203, cost: 28111.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 3/100, moves: 562, cost: 28111.0\n",
      "Run 3, iteration: 4/100, moves: 203, cost: 28111.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1591, cost: 29318.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1591, cost: 29318.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1393, cost: 28272.0\n",
      "Run 5, iteration: 1/100, moves: 1393, cost: 28272.0\n",
      "Run 5, iteration: 2/100, moves: 961, cost: 27353.0\n",
      "Run 5, iteration: 2/100, moves: 961, cost: 27353.0\n",
      "Run 5, iteration: 3/100, moves: 458, cost: 27353.0\n",
      "Best run was number 5\n",
      "  Runtime: 6.02s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 728-1314\n",
      "  Balance ratio: 1.80\n",
      "  Avg dissimilarity: 5.471\n",
      "  Composite score: 0.1365\n",
      "\\nTesting combination 6: n_clusters=5, init=Huang, n_init=10\n",
      "Run 5, iteration: 3/100, moves: 458, cost: 27353.0\n",
      "Best run was number 5\n",
      "  Runtime: 6.02s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 728-1314\n",
      "  Balance ratio: 1.80\n",
      "  Avg dissimilarity: 5.471\n",
      "  Composite score: 0.1365\n",
      "\\nTesting combination 6: n_clusters=5, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1248, cost: 28633.0\n",
      "Run 1, iteration: 2/100, moves: 309, cost: 28633.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 1248, cost: 28633.0\n",
      "Run 1, iteration: 2/100, moves: 309, cost: 28633.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1220, cost: 27843.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1220, cost: 27843.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1355, cost: 28744.0\n",
      "Run 3, iteration: 1/100, moves: 1355, cost: 28744.0\n",
      "Run 3, iteration: 2/100, moves: 530, cost: 28370.0\n",
      "Run 3, iteration: 2/100, moves: 530, cost: 28370.0\n",
      "Run 3, iteration: 3/100, moves: 562, cost: 28111.0\n",
      "Run 3, iteration: 3/100, moves: 562, cost: 28111.0\n",
      "Run 3, iteration: 4/100, moves: 203, cost: 28111.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 4/100, moves: 203, cost: 28111.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1591, cost: 29318.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 1/100, moves: 1591, cost: 29318.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1393, cost: 28272.0\n",
      "Run 5, iteration: 1/100, moves: 1393, cost: 28272.0\n",
      "Run 5, iteration: 2/100, moves: 961, cost: 27353.0\n",
      "Run 5, iteration: 2/100, moves: 961, cost: 27353.0\n",
      "Run 5, iteration: 3/100, moves: 458, cost: 27353.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 3/100, moves: 458, cost: 27353.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 902, cost: 29566.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 902, cost: 29566.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1353, cost: 28415.0\n",
      "Run 7, iteration: 1/100, moves: 1353, cost: 28415.0\n",
      "Run 7, iteration: 2/100, moves: 814, cost: 27648.0\n",
      "Run 7, iteration: 2/100, moves: 814, cost: 27648.0\n",
      "Run 7, iteration: 3/100, moves: 333, cost: 27648.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 3/100, moves: 333, cost: 27648.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1585, cost: 27423.0\n",
      "Run 8, iteration: 1/100, moves: 1585, cost: 27423.0\n",
      "Run 8, iteration: 2/100, moves: 757, cost: 27156.0\n",
      "Run 8, iteration: 2/100, moves: 757, cost: 27156.0\n",
      "Run 8, iteration: 3/100, moves: 252, cost: 27156.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 3/100, moves: 252, cost: 27156.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1736, cost: 28369.0\n",
      "Run 9, iteration: 1/100, moves: 1736, cost: 28369.0\n",
      "Run 9, iteration: 2/100, moves: 258, cost: 28369.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 258, cost: 28369.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1664, cost: 28439.0\n",
      "Run 10, iteration: 2/100, moves: 29, cost: 28439.0\n",
      "Best run was number 8\n",
      "Run 10, iteration: 1/100, moves: 1664, cost: 28439.0\n",
      "Run 10, iteration: 2/100, moves: 29, cost: 28439.0\n",
      "Best run was number 8\n",
      "  Runtime: 11.94s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 694-1369\n",
      "  Balance ratio: 1.97\n",
      "  Avg dissimilarity: 5.431\n",
      "  Composite score: 0.1358\n",
      "\\nTesting combination 7: n_clusters=6, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "  Runtime: 11.94s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 694-1369\n",
      "  Balance ratio: 1.97\n",
      "  Avg dissimilarity: 5.431\n",
      "  Composite score: 0.1358\n",
      "\\nTesting combination 7: n_clusters=6, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1428, cost: 26969.0\n",
      "Run 1, iteration: 1/100, moves: 1428, cost: 26969.0\n",
      "Run 1, iteration: 2/100, moves: 357, cost: 26969.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 357, cost: 26969.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1533, cost: 26767.0\n",
      "Run 2, iteration: 1/100, moves: 1533, cost: 26767.0\n",
      "Run 2, iteration: 2/100, moves: 412, cost: 26767.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 2/100, moves: 412, cost: 26767.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1506, cost: 27166.0\n",
      "Run 3, iteration: 1/100, moves: 1506, cost: 27166.0\n",
      "Run 3, iteration: 2/100, moves: 423, cost: 27166.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 423, cost: 27166.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1386, cost: 27236.0\n",
      "Run 4, iteration: 1/100, moves: 1386, cost: 27236.0\n",
      "Run 4, iteration: 2/100, moves: 428, cost: 27236.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 428, cost: 27236.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1467, cost: 27009.0\n",
      "Run 5, iteration: 1/100, moves: 1467, cost: 27009.0\n",
      "Run 5, iteration: 2/100, moves: 352, cost: 27009.0\n",
      "Best run was number 2\n",
      "Run 5, iteration: 2/100, moves: 352, cost: 27009.0\n",
      "Best run was number 2\n",
      "  Runtime: 7.04s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 354-1392\n",
      "  Balance ratio: 3.93\n",
      "  Avg dissimilarity: 5.353\n",
      "  Composite score: 0.1181\n",
      "\\nTesting combination 8: n_clusters=6, init=Huang, n_init=10\n",
      "  Runtime: 7.04s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 354-1392\n",
      "  Balance ratio: 3.93\n",
      "  Avg dissimilarity: 5.353\n",
      "  Composite score: 0.1181\n",
      "\\nTesting combination 8: n_clusters=6, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1428, cost: 26969.0\n",
      "Run 1, iteration: 1/100, moves: 1428, cost: 26969.0\n",
      "Run 1, iteration: 2/100, moves: 357, cost: 26969.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 357, cost: 26969.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1533, cost: 26767.0\n",
      "Run 2, iteration: 1/100, moves: 1533, cost: 26767.0\n",
      "Run 2, iteration: 2/100, moves: 412, cost: 26767.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 412, cost: 26767.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1506, cost: 27166.0\n",
      "Run 3, iteration: 1/100, moves: 1506, cost: 27166.0\n",
      "Run 3, iteration: 2/100, moves: 423, cost: 27166.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 423, cost: 27166.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1386, cost: 27236.0\n",
      "Run 4, iteration: 1/100, moves: 1386, cost: 27236.0\n",
      "Run 4, iteration: 2/100, moves: 428, cost: 27236.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 428, cost: 27236.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1467, cost: 27009.0\n",
      "Run 5, iteration: 1/100, moves: 1467, cost: 27009.0\n",
      "Run 5, iteration: 2/100, moves: 352, cost: 27009.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 352, cost: 27009.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1323, cost: 27536.0\n",
      "Run 6, iteration: 1/100, moves: 1323, cost: 27536.0\n",
      "Run 6, iteration: 2/100, moves: 107, cost: 27536.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 107, cost: 27536.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1635, cost: 26802.0\n",
      "Run 7, iteration: 1/100, moves: 1635, cost: 26802.0\n",
      "Run 7, iteration: 2/100, moves: 460, cost: 26671.0\n",
      "Run 7, iteration: 2/100, moves: 460, cost: 26671.0\n",
      "Run 7, iteration: 3/100, moves: 9, cost: 26671.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 3/100, moves: 9, cost: 26671.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1348, cost: 27612.0\n",
      "Run 8, iteration: 1/100, moves: 1348, cost: 27612.0\n",
      "Run 8, iteration: 2/100, moves: 491, cost: 27483.0\n",
      "Run 8, iteration: 2/100, moves: 491, cost: 27483.0\n",
      "Run 8, iteration: 3/100, moves: 88, cost: 27483.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 3/100, moves: 88, cost: 27483.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1597, cost: 28368.0\n",
      "Run 9, iteration: 2/100, moves: 36, cost: 28368.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 1597, cost: 28368.0\n",
      "Run 9, iteration: 2/100, moves: 36, cost: 28368.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1384, cost: 27021.0\n",
      "Run 10, iteration: 2/100, moves: 280, cost: 27021.0\n",
      "Best run was number 7\n",
      "  Runtime: 26.13s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 443-1309\n",
      "  Balance ratio: 2.95\n",
      "  Avg dissimilarity: 5.334\n",
      "  Composite score: 0.1283\n",
      "\\nTesting combination 9: n_clusters=7, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1384, cost: 27021.0\n",
      "Run 10, iteration: 2/100, moves: 280, cost: 27021.0\n",
      "Best run was number 7\n",
      "  Runtime: 26.13s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 443-1309\n",
      "  Balance ratio: 2.95\n",
      "  Avg dissimilarity: 5.334\n",
      "  Composite score: 0.1283\n",
      "\\nTesting combination 9: n_clusters=7, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1473, cost: 26849.0\n",
      "Run 1, iteration: 1/100, moves: 1473, cost: 26849.0\n",
      "Run 1, iteration: 2/100, moves: 509, cost: 26709.0\n",
      "Run 1, iteration: 3/100, moves: 239, cost: 26606.0\n",
      "Run 1, iteration: 2/100, moves: 509, cost: 26709.0\n",
      "Run 1, iteration: 3/100, moves: 239, cost: 26606.0\n",
      "Run 1, iteration: 4/100, moves: 66, cost: 26606.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 4/100, moves: 66, cost: 26606.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2016, cost: 26406.0\n",
      "Run 2, iteration: 1/100, moves: 2016, cost: 26406.0\n",
      "Run 2, iteration: 2/100, moves: 320, cost: 26406.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 2/100, moves: 320, cost: 26406.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1833, cost: 26370.0\n",
      "Run 3, iteration: 2/100, moves: 51, cost: 26370.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 1833, cost: 26370.0\n",
      "Run 3, iteration: 2/100, moves: 51, cost: 26370.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1813, cost: 27511.0\n",
      "Run 4, iteration: 1/100, moves: 1813, cost: 27511.0\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 27511.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 27511.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1391, cost: 26144.0\n",
      "Run 5, iteration: 2/100, moves: 362, cost: 26039.0\n",
      "Run 5, iteration: 1/100, moves: 1391, cost: 26144.0\n",
      "Run 5, iteration: 2/100, moves: 362, cost: 26039.0\n",
      "Run 5, iteration: 3/100, moves: 100, cost: 26039.0\n",
      "Best run was number 5\n",
      "Run 5, iteration: 3/100, moves: 100, cost: 26039.0\n",
      "Best run was number 5\n",
      "  Runtime: 5.16s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 592-954\n",
      "  Balance ratio: 1.61\n",
      "  Avg dissimilarity: 5.208\n",
      "  Composite score: 0.1450\n",
      "\\nTesting combination 10: n_clusters=7, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 5.16s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 592-954\n",
      "  Balance ratio: 1.61\n",
      "  Avg dissimilarity: 5.208\n",
      "  Composite score: 0.1450\n",
      "\\nTesting combination 10: n_clusters=7, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1473, cost: 26849.0\n",
      "Run 1, iteration: 1/100, moves: 1473, cost: 26849.0\n",
      "Run 1, iteration: 2/100, moves: 509, cost: 26709.0\n",
      "Run 1, iteration: 2/100, moves: 509, cost: 26709.0\n",
      "Run 1, iteration: 3/100, moves: 239, cost: 26606.0\n",
      "Run 1, iteration: 3/100, moves: 239, cost: 26606.0\n",
      "Run 1, iteration: 4/100, moves: 66, cost: 26606.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 4/100, moves: 66, cost: 26606.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 2016, cost: 26406.0\n",
      "Run 2, iteration: 2/100, moves: 320, cost: 26406.0\n",
      "Init: initializing centroids\n",
      "Run 2, iteration: 1/100, moves: 2016, cost: 26406.0\n",
      "Run 2, iteration: 2/100, moves: 320, cost: 26406.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1833, cost: 26370.0\n",
      "Run 3, iteration: 2/100, moves: 51, cost: 26370.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 1833, cost: 26370.0\n",
      "Run 3, iteration: 2/100, moves: 51, cost: 26370.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1813, cost: 27511.0\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 27511.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 1813, cost: 27511.0\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 27511.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1391, cost: 26144.0\n",
      "Run 5, iteration: 2/100, moves: 362, cost: 26039.0\n",
      "Run 5, iteration: 1/100, moves: 1391, cost: 26144.0\n",
      "Run 5, iteration: 2/100, moves: 362, cost: 26039.0\n",
      "Run 5, iteration: 3/100, moves: 100, cost: 26039.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 3/100, moves: 100, cost: 26039.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1591, cost: 27137.0\n",
      "Run 6, iteration: 2/100, moves: 132, cost: 27137.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 1/100, moves: 1591, cost: 27137.0\n",
      "Run 6, iteration: 2/100, moves: 132, cost: 27137.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1428, cost: 26300.0\n",
      "Run 7, iteration: 1/100, moves: 1428, cost: 26300.0\n",
      "Run 7, iteration: 2/100, moves: 583, cost: 26229.0\n",
      "Run 7, iteration: 3/100, moves: 31, cost: 26229.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 583, cost: 26229.0\n",
      "Run 7, iteration: 3/100, moves: 31, cost: 26229.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1648, cost: 27757.0\n",
      "Run 8, iteration: 2/100, moves: 913, cost: 27334.0\n",
      "Run 8, iteration: 1/100, moves: 1648, cost: 27757.0\n",
      "Run 8, iteration: 2/100, moves: 913, cost: 27334.0\n",
      "Run 8, iteration: 3/100, moves: 72, cost: 27334.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 3/100, moves: 72, cost: 27334.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1423, cost: 27689.0\n",
      "Run 9, iteration: 1/100, moves: 1423, cost: 27689.0\n",
      "Run 9, iteration: 2/100, moves: 524, cost: 27396.0\n",
      "Run 9, iteration: 3/100, moves: 244, cost: 27396.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 524, cost: 27396.0\n",
      "Run 9, iteration: 3/100, moves: 244, cost: 27396.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2080, cost: 27298.0\n",
      "Run 10, iteration: 1/100, moves: 2080, cost: 27298.0\n",
      "Run 10, iteration: 2/100, moves: 684, cost: 26886.0\n",
      "Run 10, iteration: 2/100, moves: 684, cost: 26886.0\n",
      "Run 10, iteration: 3/100, moves: 398, cost: 26886.0\n",
      "Best run was number 5\n",
      "  Runtime: 10.51s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 592-954\n",
      "  Balance ratio: 1.61\n",
      "  Avg dissimilarity: 5.208\n",
      "  Composite score: 0.1450\n",
      "\\nTesting combination 11: n_clusters=8, init=Huang, n_init=5\n",
      "Run 10, iteration: 3/100, moves: 398, cost: 26886.0\n",
      "Best run was number 5\n",
      "  Runtime: 10.51s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 592-954\n",
      "  Balance ratio: 1.61\n",
      "  Avg dissimilarity: 5.208\n",
      "  Composite score: 0.1450\n",
      "\\nTesting combination 11: n_clusters=8, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1369, cost: 25623.0\n",
      "Run 1, iteration: 1/100, moves: 1369, cost: 25623.0\n",
      "Run 1, iteration: 2/100, moves: 328, cost: 25623.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 328, cost: 25623.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1551, cost: 25604.0\n",
      "Run 2, iteration: 1/100, moves: 1551, cost: 25604.0\n",
      "Run 2, iteration: 2/100, moves: 845, cost: 25328.0\n",
      "Run 2, iteration: 2/100, moves: 845, cost: 25328.0\n",
      "Run 2, iteration: 3/100, moves: 261, cost: 25250.0\n",
      "Run 2, iteration: 4/100, moves: 2, cost: 25250.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 261, cost: 25250.0\n",
      "Run 2, iteration: 4/100, moves: 2, cost: 25250.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1704, cost: 25670.0\n",
      "Run 3, iteration: 2/100, moves: 195, cost: 25670.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 1704, cost: 25670.0\n",
      "Run 3, iteration: 2/100, moves: 195, cost: 25670.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1833, cost: 26266.0\n",
      "Run 4, iteration: 1/100, moves: 1833, cost: 26266.0\n",
      "Run 4, iteration: 2/100, moves: 846, cost: 25856.0\n",
      "Run 4, iteration: 3/100, moves: 194, cost: 25856.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 2/100, moves: 846, cost: 25856.0\n",
      "Run 4, iteration: 3/100, moves: 194, cost: 25856.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1017, cost: 26529.0\n",
      "Run 5, iteration: 2/100, moves: 55, cost: 26529.0\n",
      "Best run was number 2\n",
      "Run 5, iteration: 1/100, moves: 1017, cost: 26529.0\n",
      "Run 5, iteration: 2/100, moves: 55, cost: 26529.0\n",
      "Best run was number 2\n",
      "  Runtime: 5.65s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 270-968\n",
      "  Balance ratio: 3.59\n",
      "  Avg dissimilarity: 5.050\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 12: n_clusters=8, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 5.65s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 270-968\n",
      "  Balance ratio: 3.59\n",
      "  Avg dissimilarity: 5.050\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 12: n_clusters=8, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1369, cost: 25623.0\n",
      "Run 1, iteration: 2/100, moves: 328, cost: 25623.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 1369, cost: 25623.0\n",
      "Run 1, iteration: 2/100, moves: 328, cost: 25623.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1551, cost: 25604.0\n",
      "Run 2, iteration: 1/100, moves: 1551, cost: 25604.0\n",
      "Run 2, iteration: 2/100, moves: 845, cost: 25328.0\n",
      "Run 2, iteration: 2/100, moves: 845, cost: 25328.0\n",
      "Run 2, iteration: 3/100, moves: 261, cost: 25250.0\n",
      "Run 2, iteration: 4/100, moves: 2, cost: 25250.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 261, cost: 25250.0\n",
      "Run 2, iteration: 4/100, moves: 2, cost: 25250.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1704, cost: 25670.0\n",
      "Run 3, iteration: 2/100, moves: 195, cost: 25670.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 1704, cost: 25670.0\n",
      "Run 3, iteration: 2/100, moves: 195, cost: 25670.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1833, cost: 26266.0\n",
      "Run 4, iteration: 1/100, moves: 1833, cost: 26266.0\n",
      "Run 4, iteration: 2/100, moves: 846, cost: 25856.0\n",
      "Run 4, iteration: 3/100, moves: 194, cost: 25856.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 846, cost: 25856.0\n",
      "Run 4, iteration: 3/100, moves: 194, cost: 25856.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1017, cost: 26529.0\n",
      "Run 5, iteration: 2/100, moves: 55, cost: 26529.0\n",
      "Init: initializing centroids\n",
      "Run 5, iteration: 1/100, moves: 1017, cost: 26529.0\n",
      "Run 5, iteration: 2/100, moves: 55, cost: 26529.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1389, cost: 26372.0\n",
      "Run 6, iteration: 1/100, moves: 1389, cost: 26372.0\n",
      "Run 6, iteration: 2/100, moves: 225, cost: 26229.0\n",
      "Run 6, iteration: 3/100, moves: 52, cost: 26229.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 2/100, moves: 225, cost: 26229.0\n",
      "Run 6, iteration: 3/100, moves: 52, cost: 26229.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1576, cost: 26218.0\n",
      "Run 7, iteration: 1/100, moves: 1576, cost: 26218.0\n",
      "Run 7, iteration: 2/100, moves: 360, cost: 26042.0\n",
      "Run 7, iteration: 2/100, moves: 360, cost: 26042.0\n",
      "Run 7, iteration: 3/100, moves: 198, cost: 26042.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 3/100, moves: 198, cost: 26042.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1953, cost: 26232.0\n",
      "Run 8, iteration: 2/100, moves: 163, cost: 26232.0\n",
      "Init: initializing centroids\n",
      "Run 8, iteration: 1/100, moves: 1953, cost: 26232.0\n",
      "Run 8, iteration: 2/100, moves: 163, cost: 26232.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1192, cost: 26127.0\n",
      "Run 9, iteration: 2/100, moves: 10, cost: 26127.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 1192, cost: 26127.0\n",
      "Run 9, iteration: 2/100, moves: 10, cost: 26127.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1468, cost: 26314.0\n",
      "Run 10, iteration: 1/100, moves: 1468, cost: 26314.0\n",
      "Run 10, iteration: 2/100, moves: 494, cost: 26164.0\n",
      "Run 10, iteration: 2/100, moves: 494, cost: 26164.0\n",
      "Run 10, iteration: 3/100, moves: 268, cost: 26005.0\n",
      "Run 10, iteration: 4/100, moves: 27, cost: 26005.0\n",
      "Best run was number 2\n",
      "Run 10, iteration: 3/100, moves: 268, cost: 26005.0\n",
      "Run 10, iteration: 4/100, moves: 27, cost: 26005.0\n",
      "Best run was number 2\n",
      "  Runtime: 12.26s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 270-968\n",
      "  Balance ratio: 3.59\n",
      "  Avg dissimilarity: 5.050\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 13: n_clusters=9, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 12.26s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 270-968\n",
      "  Balance ratio: 3.59\n",
      "  Avg dissimilarity: 5.050\n",
      "  Composite score: 0.1294\n",
      "\\nTesting combination 13: n_clusters=9, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1552, cost: 25137.0\n",
      "Run 1, iteration: 1/100, moves: 1552, cost: 25137.0\n",
      "Run 1, iteration: 2/100, moves: 129, cost: 25100.0\n",
      "Run 1, iteration: 2/100, moves: 129, cost: 25100.0\n",
      "Run 1, iteration: 3/100, moves: 6, cost: 25100.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 3/100, moves: 6, cost: 25100.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1710, cost: 26297.0\n",
      "Run 2, iteration: 1/100, moves: 1710, cost: 26297.0\n",
      "Run 2, iteration: 2/100, moves: 856, cost: 26154.0\n",
      "Run 2, iteration: 2/100, moves: 856, cost: 26154.0\n",
      "Run 2, iteration: 3/100, moves: 229, cost: 26154.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 229, cost: 26154.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1637, cost: 26126.0\n",
      "Run 3, iteration: 1/100, moves: 1637, cost: 26126.0\n",
      "Run 3, iteration: 2/100, moves: 359, cost: 25952.0\n",
      "Run 3, iteration: 2/100, moves: 359, cost: 25952.0\n",
      "Run 3, iteration: 3/100, moves: 249, cost: 25801.0\n",
      "Run 3, iteration: 3/100, moves: 249, cost: 25801.0\n",
      "Run 3, iteration: 4/100, moves: 16, cost: 25801.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 4/100, moves: 16, cost: 25801.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1122, cost: 25467.0\n",
      "Run 4, iteration: 1/100, moves: 1122, cost: 25467.0\n",
      "Run 4, iteration: 2/100, moves: 124, cost: 25467.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 124, cost: 25467.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1678, cost: 25847.0\n",
      "Run 5, iteration: 1/100, moves: 1678, cost: 25847.0\n",
      "Run 5, iteration: 2/100, moves: 828, cost: 25461.0\n",
      "Run 5, iteration: 2/100, moves: 828, cost: 25461.0\n",
      "Run 5, iteration: 3/100, moves: 329, cost: 25461.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 3/100, moves: 329, cost: 25461.0\n",
      "Best run was number 1\n",
      "  Runtime: 17.01s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 275-788\n",
      "  Balance ratio: 2.87\n",
      "  Avg dissimilarity: 5.020\n",
      "  Composite score: 0.1375\n",
      "\\nTesting combination 14: n_clusters=9, init=Huang, n_init=10\n",
      "  Runtime: 17.01s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 275-788\n",
      "  Balance ratio: 2.87\n",
      "  Avg dissimilarity: 5.020\n",
      "  Composite score: 0.1375\n",
      "\\nTesting combination 14: n_clusters=9, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1552, cost: 25137.0\n",
      "Run 1, iteration: 1/100, moves: 1552, cost: 25137.0\n",
      "Run 1, iteration: 2/100, moves: 129, cost: 25100.0\n",
      "Run 1, iteration: 2/100, moves: 129, cost: 25100.0\n",
      "Run 1, iteration: 3/100, moves: 6, cost: 25100.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 3/100, moves: 6, cost: 25100.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1710, cost: 26297.0\n",
      "Run 2, iteration: 1/100, moves: 1710, cost: 26297.0\n",
      "Run 2, iteration: 2/100, moves: 856, cost: 26154.0\n",
      "Run 2, iteration: 2/100, moves: 856, cost: 26154.0\n",
      "Run 2, iteration: 3/100, moves: 229, cost: 26154.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 229, cost: 26154.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1637, cost: 26126.0\n",
      "Run 3, iteration: 1/100, moves: 1637, cost: 26126.0\n",
      "Run 3, iteration: 2/100, moves: 359, cost: 25952.0\n",
      "Run 3, iteration: 2/100, moves: 359, cost: 25952.0\n",
      "Run 3, iteration: 3/100, moves: 249, cost: 25801.0\n",
      "Run 3, iteration: 3/100, moves: 249, cost: 25801.0\n",
      "Run 3, iteration: 4/100, moves: 16, cost: 25801.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 4/100, moves: 16, cost: 25801.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1122, cost: 25467.0\n",
      "Run 4, iteration: 1/100, moves: 1122, cost: 25467.0\n",
      "Run 4, iteration: 2/100, moves: 124, cost: 25467.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 124, cost: 25467.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1678, cost: 25847.0\n",
      "Run 5, iteration: 1/100, moves: 1678, cost: 25847.0\n",
      "Run 5, iteration: 2/100, moves: 828, cost: 25461.0\n",
      "Run 5, iteration: 2/100, moves: 828, cost: 25461.0\n",
      "Run 5, iteration: 3/100, moves: 329, cost: 25461.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 3/100, moves: 329, cost: 25461.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1662, cost: 25190.0\n",
      "Run 6, iteration: 1/100, moves: 1662, cost: 25190.0\n",
      "Run 6, iteration: 2/100, moves: 299, cost: 25092.0\n",
      "Run 6, iteration: 2/100, moves: 299, cost: 25092.0\n",
      "Run 6, iteration: 3/100, moves: 62, cost: 25092.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 3/100, moves: 62, cost: 25092.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1437, cost: 25933.0\n",
      "Run 7, iteration: 1/100, moves: 1437, cost: 25933.0\n",
      "Run 7, iteration: 2/100, moves: 114, cost: 25933.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 114, cost: 25933.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1570, cost: 26692.0\n",
      "Run 8, iteration: 1/100, moves: 1570, cost: 26692.0\n",
      "Run 8, iteration: 2/100, moves: 170, cost: 26692.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 2/100, moves: 170, cost: 26692.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1563, cost: 26152.0\n",
      "Run 9, iteration: 1/100, moves: 1563, cost: 26152.0\n",
      "Run 9, iteration: 2/100, moves: 208, cost: 26152.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 208, cost: 26152.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2039, cost: 25850.0\n",
      "Run 10, iteration: 1/100, moves: 2039, cost: 25850.0\n",
      "Run 10, iteration: 2/100, moves: 338, cost: 25598.0\n",
      "Run 10, iteration: 2/100, moves: 338, cost: 25598.0\n",
      "Run 10, iteration: 3/100, moves: 210, cost: 25598.0\n",
      "Best run was number 6\n",
      "Run 10, iteration: 3/100, moves: 210, cost: 25598.0\n",
      "Best run was number 6\n",
      "  Runtime: 31.57s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 248-755\n",
      "  Balance ratio: 3.04\n",
      "  Avg dissimilarity: 5.018\n",
      "  Composite score: 0.1357\n",
      "\\nTesting combination 15: n_clusters=10, init=Huang, n_init=5\n",
      "  Runtime: 31.57s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 248-755\n",
      "  Balance ratio: 3.04\n",
      "  Avg dissimilarity: 5.018\n",
      "  Composite score: 0.1357\n",
      "\\nTesting combination 15: n_clusters=10, init=Huang, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Best run was number 1\n",
      "  Runtime: 15.51s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 169-872\n",
      "  Balance ratio: 5.16\n",
      "  Avg dissimilarity: 5.019\n",
      "  Composite score: 0.1145\n",
      "\\nTesting combination 16: n_clusters=10, init=Huang, n_init=10\n",
      "  Runtime: 15.51s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 169-872\n",
      "  Balance ratio: 5.16\n",
      "  Avg dissimilarity: 5.019\n",
      "  Composite score: 0.1145\n",
      "\\nTesting combination 16: n_clusters=10, init=Huang, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1695, cost: 25114.0\n",
      "Run 6, iteration: 1/100, moves: 1695, cost: 25114.0\n",
      "Run 6, iteration: 2/100, moves: 548, cost: 25114.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 2/100, moves: 548, cost: 25114.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1282, cost: 24901.0\n",
      "Run 7, iteration: 1/100, moves: 1282, cost: 24901.0\n",
      "Run 7, iteration: 2/100, moves: 223, cost: 24901.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 223, cost: 24901.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1462, cost: 24781.0\n",
      "Run 8, iteration: 1/100, moves: 1462, cost: 24781.0\n",
      "Run 8, iteration: 2/100, moves: 273, cost: 24781.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 2/100, moves: 273, cost: 24781.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1305, cost: 25718.0\n",
      "Run 9, iteration: 1/100, moves: 1305, cost: 25718.0\n",
      "Run 9, iteration: 2/100, moves: 503, cost: 25676.0\n",
      "Run 9, iteration: 2/100, moves: 503, cost: 25676.0\n",
      "Run 9, iteration: 3/100, moves: 14, cost: 25676.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 3/100, moves: 14, cost: 25676.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2056, cost: 24756.0\n",
      "Run 10, iteration: 1/100, moves: 2056, cost: 24756.0\n",
      "Run 10, iteration: 2/100, moves: 312, cost: 24700.0\n",
      "Run 10, iteration: 2/100, moves: 312, cost: 24700.0\n",
      "Run 10, iteration: 3/100, moves: 76, cost: 24700.0\n",
      "Best run was number 10\n",
      "Run 10, iteration: 3/100, moves: 76, cost: 24700.0\n",
      "Best run was number 10\n",
      "  Runtime: 31.17s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 344-739\n",
      "  Balance ratio: 2.15\n",
      "  Avg dissimilarity: 4.940\n",
      "  Composite score: 0.1469\n",
      "\\nTesting combination 17: n_clusters=3, init=Cao, n_init=5\n",
      "  Runtime: 31.17s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 344-739\n",
      "  Balance ratio: 2.15\n",
      "  Avg dissimilarity: 4.940\n",
      "  Composite score: 0.1469\n",
      "\\nTesting combination 17: n_clusters=3, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Best run was number 1\n",
      "  Runtime: 7.75s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1096-2307\n",
      "  Balance ratio: 2.10\n",
      "  Avg dissimilarity: 6.051\n",
      "  Composite score: 0.1208\n",
      "\\nTesting combination 18: n_clusters=3, init=Cao, n_init=10\n",
      "  Runtime: 7.75s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1096-2307\n",
      "  Balance ratio: 2.10\n",
      "  Avg dissimilarity: 6.051\n",
      "  Composite score: 0.1208\n",
      "\\nTesting combination 18: n_clusters=3, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Run 7, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Best run was number 1\n",
      "Run 10, iteration: 1/100, moves: 722, cost: 30255.0\n",
      "Best run was number 1\n",
      "  Runtime: 15.37s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1096-2307\n",
      "  Balance ratio: 2.10\n",
      "  Avg dissimilarity: 6.051\n",
      "  Composite score: 0.1208\n",
      "\\nTesting combination 19: n_clusters=4, init=Cao, n_init=5\n",
      "  Runtime: 15.37s\n",
      "  Clusters: 3\n",
      "  Cluster sizes: 1096-2307\n",
      "  Balance ratio: 2.10\n",
      "  Avg dissimilarity: 6.051\n",
      "  Composite score: 0.1208\n",
      "\\nTesting combination 19: n_clusters=4, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 1, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 1, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 2, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 2, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 3, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 3, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 4, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 4, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 5, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 5, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.81s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 766-1869\n",
      "  Balance ratio: 2.44\n",
      "  Avg dissimilarity: 5.747\n",
      "  Composite score: 0.1238\n",
      "\\nTesting combination 20: n_clusters=4, init=Cao, n_init=10\n",
      "  Runtime: 11.81s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 766-1869\n",
      "  Balance ratio: 2.44\n",
      "  Avg dissimilarity: 5.747\n",
      "  Composite score: 0.1238\n",
      "\\nTesting combination 20: n_clusters=4, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 1, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 1, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 2, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 2, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 2, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 3, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 3, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 4, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 4, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 5, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 5, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 6, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 6, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 7, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 7, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 8, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 8, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 9, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 9, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 10, iteration: 1/100, moves: 821, cost: 28733.0\n",
      "Run 10, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Best run was number 1\n",
      "Run 10, iteration: 2/100, moves: 116, cost: 28733.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.60s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 766-1869\n",
      "  Balance ratio: 2.44\n",
      "  Avg dissimilarity: 5.747\n",
      "  Composite score: 0.1238\n",
      "\\nTesting combination 21: n_clusters=5, init=Cao, n_init=5\n",
      "  Runtime: 11.60s\n",
      "  Clusters: 4\n",
      "  Cluster sizes: 766-1869\n",
      "  Balance ratio: 2.44\n",
      "  Avg dissimilarity: 5.747\n",
      "  Composite score: 0.1238\n",
      "\\nTesting combination 21: n_clusters=5, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 1, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 1, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 2, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 2, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 3, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 3, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 4, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 4, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 5, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 5, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.22s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 518-1648\n",
      "  Balance ratio: 3.18\n",
      "  Avg dissimilarity: 5.520\n",
      "  Composite score: 0.1216\n",
      "\\nTesting combination 22: n_clusters=5, init=Cao, n_init=10\n",
      "  Runtime: 5.22s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 518-1648\n",
      "  Balance ratio: 3.18\n",
      "  Avg dissimilarity: 5.520\n",
      "  Composite score: 0.1216\n",
      "\\nTesting combination 22: n_clusters=5, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 1, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 1, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 2, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 2, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 3, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 3, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 4, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 4, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 5, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 5, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 6, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 6, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 7, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Run 7, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 7, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 8, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Run 8, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 8, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 9, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 9, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 10, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Best run was number 1\n",
      "Run 10, iteration: 1/100, moves: 917, cost: 27600.0\n",
      "Run 10, iteration: 2/100, moves: 153, cost: 27600.0\n",
      "Best run was number 1\n",
      "  Runtime: 9.26s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 518-1648\n",
      "  Balance ratio: 3.18\n",
      "  Avg dissimilarity: 5.520\n",
      "  Composite score: 0.1216\n",
      "\\nTesting combination 23: n_clusters=6, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "  Runtime: 9.26s\n",
      "  Clusters: 5\n",
      "  Cluster sizes: 518-1648\n",
      "  Balance ratio: 3.18\n",
      "  Avg dissimilarity: 5.520\n",
      "  Composite score: 0.1216\n",
      "\\nTesting combination 23: n_clusters=6, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 1, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 1, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 2, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 2, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 3, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 3, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 4, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 4, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 5, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 5, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.15s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 420-1439\n",
      "  Balance ratio: 3.43\n",
      "  Avg dissimilarity: 5.358\n",
      "  Composite score: 0.1230\n",
      "\\nTesting combination 24: n_clusters=6, init=Cao, n_init=10\n",
      "  Runtime: 5.15s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 420-1439\n",
      "  Balance ratio: 3.43\n",
      "  Avg dissimilarity: 5.358\n",
      "  Composite score: 0.1230\n",
      "\\nTesting combination 24: n_clusters=6, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 1, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 1, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 2, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 2, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 3, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 3, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 4, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 4, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 5, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 5, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 6, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 6, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 7, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 7, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 8, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 8, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 8, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 9, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 9, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 10, iteration: 1/100, moves: 1104, cost: 26788.0\n",
      "Run 10, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Best run was number 1\n",
      "Run 10, iteration: 2/100, moves: 64, cost: 26788.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.72s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 420-1439\n",
      "  Balance ratio: 3.43\n",
      "  Avg dissimilarity: 5.358\n",
      "  Composite score: 0.1230\n",
      "\\nTesting combination 25: n_clusters=7, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "  Runtime: 11.72s\n",
      "  Clusters: 6\n",
      "  Cluster sizes: 420-1439\n",
      "  Balance ratio: 3.43\n",
      "  Avg dissimilarity: 5.358\n",
      "  Composite score: 0.1230\n",
      "\\nTesting combination 25: n_clusters=7, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 1, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 1, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 2, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 2, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 3, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 3, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 4, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 4, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 5, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 5, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.79s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 350-1301\n",
      "  Balance ratio: 3.72\n",
      "  Avg dissimilarity: 5.241\n",
      "  Composite score: 0.1231\n",
      "\\nTesting combination 26: n_clusters=7, init=Cao, n_init=10\n",
      "Run 5, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.79s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 350-1301\n",
      "  Balance ratio: 3.72\n",
      "  Avg dissimilarity: 5.241\n",
      "  Composite score: 0.1231\n",
      "\\nTesting combination 26: n_clusters=7, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 1, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 1, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 2, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 2, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 3, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 3, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 4, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 4, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 5, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 5, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 6, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 6, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 7, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Run 7, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 7, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 8, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 8, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 9, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 9, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 10, iteration: 1/100, moves: 1124, cost: 26203.0\n",
      "Run 10, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.53s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 350-1301\n",
      "  Balance ratio: 3.72\n",
      "  Avg dissimilarity: 5.241\n",
      "  Composite score: 0.1231\n",
      "\\nTesting combination 27: n_clusters=8, init=Cao, n_init=5\n",
      "Run 10, iteration: 2/100, moves: 310, cost: 26203.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.53s\n",
      "  Clusters: 7\n",
      "  Cluster sizes: 350-1301\n",
      "  Balance ratio: 3.72\n",
      "  Avg dissimilarity: 5.241\n",
      "  Composite score: 0.1231\n",
      "\\nTesting combination 27: n_clusters=8, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 1, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 1, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 2, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Run 2, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 2, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 3, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 3, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 4, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 5, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 5, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.91s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 343-1213\n",
      "  Balance ratio: 3.54\n",
      "  Avg dissimilarity: 5.169\n",
      "  Composite score: 0.1267\n",
      "\\nTesting combination 28: n_clusters=8, init=Cao, n_init=10\n",
      "Run 5, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.91s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 343-1213\n",
      "  Balance ratio: 3.54\n",
      "  Avg dissimilarity: 5.169\n",
      "  Composite score: 0.1267\n",
      "\\nTesting combination 28: n_clusters=8, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 1, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 1, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 2, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 2, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 3, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 3, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 4, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 5, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 5, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 6, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 6, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 6, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 7, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 7, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 8, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 8, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 9, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 9, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 10, iteration: 1/100, moves: 1171, cost: 25844.0\n",
      "Run 10, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.84s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 343-1213\n",
      "  Balance ratio: 3.54\n",
      "  Avg dissimilarity: 5.169\n",
      "  Composite score: 0.1267\n",
      "\\nTesting combination 29: n_clusters=9, init=Cao, n_init=5\n",
      "Run 10, iteration: 2/100, moves: 101, cost: 25844.0\n",
      "Best run was number 1\n",
      "  Runtime: 11.84s\n",
      "  Clusters: 8\n",
      "  Cluster sizes: 343-1213\n",
      "  Balance ratio: 3.54\n",
      "  Avg dissimilarity: 5.169\n",
      "  Composite score: 0.1267\n",
      "\\nTesting combination 29: n_clusters=9, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 1, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 1, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 2, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 2, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 3, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 3, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 4, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 4, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 5, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 5, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Best run was number 1\n",
      "  Runtime: 6.60s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 219-1192\n",
      "  Balance ratio: 5.44\n",
      "  Avg dissimilarity: 5.099\n",
      "  Composite score: 0.1095\n",
      "\\nTesting combination 30: n_clusters=9, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "  Runtime: 6.60s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 219-1192\n",
      "  Balance ratio: 5.44\n",
      "  Avg dissimilarity: 5.099\n",
      "  Composite score: 0.1095\n",
      "\\nTesting combination 30: n_clusters=9, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 1, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 1, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 2, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 2, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 2, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 3, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 3, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 4, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 4, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 5, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 5, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 5, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 6, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 6, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 7, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 7, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 8, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 8, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 8, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 9, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 9, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 10, iteration: 1/100, moves: 1181, cost: 25497.0\n",
      "Run 10, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Best run was number 1\n",
      "  Runtime: 10.95s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 219-1192\n",
      "  Balance ratio: 5.44\n",
      "  Avg dissimilarity: 5.099\n",
      "  Composite score: 0.1095\n",
      "\\nTesting combination 31: n_clusters=10, init=Cao, n_init=5\n",
      "Run 10, iteration: 2/100, moves: 81, cost: 25497.0\n",
      "Best run was number 1\n",
      "  Runtime: 10.95s\n",
      "  Clusters: 9\n",
      "  Cluster sizes: 219-1192\n",
      "  Balance ratio: 5.44\n",
      "  Avg dissimilarity: 5.099\n",
      "  Composite score: 0.1095\n",
      "\\nTesting combination 31: n_clusters=10, init=Cao, n_init=5\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 1, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 1, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 1, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 2, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 2, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 3, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 3, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 4, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 4, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 5, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Best run was number 1\n",
      "Run 5, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 5, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Best run was number 1\n",
      "  Runtime: 5.83s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 220-1128\n",
      "  Balance ratio: 5.13\n",
      "  Avg dissimilarity: 5.035\n",
      "  Composite score: 0.1144\n",
      "\\nTesting combination 32: n_clusters=10, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "  Runtime: 5.83s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 220-1128\n",
      "  Balance ratio: 5.13\n",
      "  Avg dissimilarity: 5.035\n",
      "  Composite score: 0.1144\n",
      "\\nTesting combination 32: n_clusters=10, init=Cao, n_init=10\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 1, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 1, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 2, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 2, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 3, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 3, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 3, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 4, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 4, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 4, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 5, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 5, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 6, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 6, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 6, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 7, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 7, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 7, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 8, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 8, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 8, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 9, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Run 9, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 9, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 10, iteration: 1/100, moves: 1187, cost: 25174.0\n",
      "Run 10, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Best run was number 1\n",
      "Run 10, iteration: 2/100, moves: 193, cost: 25174.0\n",
      "Best run was number 1\n",
      "  Runtime: 12.52s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 220-1128\n",
      "  Balance ratio: 5.13\n",
      "  Avg dissimilarity: 5.035\n",
      "  Composite score: 0.1144\n",
      "\\n=== K-MODES GRID SEARCH RESULTS ===\n",
      "Total successful runs: 32\n",
      "Best composite score: 0.1469\n",
      "Best parameters: {'cluster__init': 'Huang', 'cluster__n_clusters': 10, 'cluster__n_init': 10}\n",
      "\\nTop 5 parameter combinations:\n",
      "    n_clusters init_method  n_init  composite_score  min_cluster_size  \\\n",
      "15          10       Huang      10           0.1469               344   \n",
      "8            7       Huang       5           0.1450               592   \n",
      "9            7       Huang      10           0.1450               592   \n",
      "12           9       Huang       5           0.1375               275   \n",
      "4            5       Huang       5           0.1365               728   \n",
      "\n",
      "    max_cluster_size  avg_dissimilarity  \n",
      "15               739             4.9400  \n",
      "8                954             5.2078  \n",
      "9                954             5.2078  \n",
      "12               788             5.0200  \n",
      "4               1314             5.4706  \n",
      "  Runtime: 12.52s\n",
      "  Clusters: 10\n",
      "  Cluster sizes: 220-1128\n",
      "  Balance ratio: 5.13\n",
      "  Avg dissimilarity: 5.035\n",
      "  Composite score: 0.1144\n",
      "\\n=== K-MODES GRID SEARCH RESULTS ===\n",
      "Total successful runs: 32\n",
      "Best composite score: 0.1469\n",
      "Best parameters: {'cluster__init': 'Huang', 'cluster__n_clusters': 10, 'cluster__n_init': 10}\n",
      "\\nTop 5 parameter combinations:\n",
      "    n_clusters init_method  n_init  composite_score  min_cluster_size  \\\n",
      "15          10       Huang      10           0.1469               344   \n",
      "8            7       Huang       5           0.1450               592   \n",
      "9            7       Huang      10           0.1450               592   \n",
      "12           9       Huang       5           0.1375               275   \n",
      "4            5       Huang       5           0.1365               728   \n",
      "\n",
      "    max_cluster_size  avg_dissimilarity  \n",
      "15               739             4.9400  \n",
      "8                954             5.2078  \n",
      "9                954             5.2078  \n",
      "12               788             5.0200  \n",
      "4               1314             5.4706  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== K-MODES PARAMETER GRID SEARCH ===\")\n",
    "\n",
    "# Grid search implementation (following SpatialHotspotAnalysis methodology)\n",
    "kmodes_results = []\n",
    "best_params = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Custom evaluation metric for categorical clustering\n",
    "def evaluate_kmodes_clustering(X, labels, centroids):\n",
    "    \"\"\"\n",
    "    Evaluate K-Modes clustering quality using multiple metrics.\n",
    "    Similar to the evaluation approach in SpatialHotspotAnalysis.\n",
    "    \"\"\"\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    n_samples = len(labels)\n",
    "    \n",
    "    # Basic cluster statistics\n",
    "    cluster_sizes = pd.Series(labels).value_counts().sort_index()\n",
    "    min_cluster_size = cluster_sizes.min()\n",
    "    max_cluster_size = cluster_sizes.max()\n",
    "    \n",
    "    # Cluster balance (smaller is better for balanced clusters)\n",
    "    cluster_balance = max_cluster_size / max(min_cluster_size, 1)\n",
    "    \n",
    "    # Intra-cluster homogeneity (categorical version of compactness)\n",
    "    total_dissimilarity = 0\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        if cluster_mask.sum() > 1:\n",
    "            cluster_data = X[cluster_mask]\n",
    "            centroid = centroids[cluster_id]\n",
    "            \n",
    "            # Calculate dissimilarity to centroid for categorical data\n",
    "            for sample in cluster_data:\n",
    "                dissimilarity = np.sum(sample != centroid)\n",
    "                total_dissimilarity += dissimilarity\n",
    "    \n",
    "    avg_dissimilarity = total_dissimilarity / max(n_samples, 1)\n",
    "    \n",
    "    return {\n",
    "        'n_clusters': n_clusters,\n",
    "        'min_cluster_size': min_cluster_size,\n",
    "        'max_cluster_size': max_cluster_size,\n",
    "        'cluster_balance': cluster_balance,\n",
    "        'avg_dissimilarity': avg_dissimilarity\n",
    "    }\n",
    "\n",
    "print(f\"Starting grid search with {len(list(ParameterGrid(kmodes_param_grid)))} parameter combinations...\")\n",
    "\n",
    "# Execute grid search\n",
    "for i, params in enumerate(ParameterGrid(kmodes_param_grid)):\n",
    "    print(f\"\\\\nTesting combination {i+1}: n_clusters={params['cluster__n_clusters']}, \"\n",
    "          f\"init={params['cluster__init']}, n_init={params['cluster__n_init']}\")\n",
    "    \n",
    "    try:\n",
    "        # Set parameters and fit model\n",
    "        kmodes_pipeline.set_params(**params)\n",
    "        t0 = time.perf_counter()\n",
    "        labels = kmodes_pipeline.fit_predict(X_categorical)\n",
    "        runtime = time.perf_counter() - t0\n",
    "        \n",
    "        # Get centroids from the fitted model\n",
    "        centroids = kmodes_pipeline.named_steps['cluster'].cluster_centroids_\n",
    "        \n",
    "        # Evaluate clustering quality\n",
    "        eval_metrics = evaluate_kmodes_clustering(X_categorical_array, labels, centroids)\n",
    "        \n",
    "        # Calculate composite score (similar to SpatialHotspotAnalysis approach)\n",
    "        # Lower dissimilarity and better balance = higher score\n",
    "        composite_score = 1.0 / (1.0 + eval_metrics['avg_dissimilarity']) - eval_metrics['cluster_balance'] / 100.0\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'n_clusters': params['cluster__n_clusters'],\n",
    "            'init_method': params['cluster__init'],\n",
    "            'n_init': params['cluster__n_init'],\n",
    "            'runtime_s': runtime,\n",
    "            'composite_score': composite_score,\n",
    "            **eval_metrics\n",
    "        }\n",
    "        \n",
    "        kmodes_results.append(result)\n",
    "        \n",
    "        # Track best parameters\n",
    "        if composite_score > best_score:\n",
    "            best_score = composite_score\n",
    "            best_params = params.copy()\n",
    "        \n",
    "        print(f\"  Runtime: {runtime:.2f}s\")\n",
    "        print(f\"  Clusters: {eval_metrics['n_clusters']}\")\n",
    "        print(f\"  Cluster sizes: {eval_metrics['min_cluster_size']}-{eval_metrics['max_cluster_size']}\")\n",
    "        print(f\"  Balance ratio: {eval_metrics['cluster_balance']:.2f}\")\n",
    "        print(f\"  Avg dissimilarity: {eval_metrics['avg_dissimilarity']:.3f}\")\n",
    "        print(f\"  Composite score: {composite_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Convert results to DataFrame for analysis (following SpatialHotspotAnalysis approach)\n",
    "df_kmodes_results = pd.DataFrame(kmodes_results)\n",
    "\n",
    "if not df_kmodes_results.empty:\n",
    "    print(f\"\\\\n=== K-MODES GRID SEARCH RESULTS ===\")\n",
    "    print(f\"Total successful runs: {len(df_kmodes_results)}\")\n",
    "    print(f\"Best composite score: {best_score:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Display top results\n",
    "    top_results = df_kmodes_results.nlargest(5, 'composite_score')\n",
    "    print(f\"\\\\nTop 5 parameter combinations:\")\n",
    "    print(top_results[['n_clusters', 'init_method', 'n_init', 'composite_score', \n",
    "                      'min_cluster_size', 'max_cluster_size', 'avg_dissimilarity']].round(4))\n",
    "else:\n",
    "    print(\"❌ No successful K-Modes runs completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ccb95e",
   "metadata": {},
   "source": [
    "### K-Modes Results Analysis & Pattern Discovery\n",
    "\n",
    "We analyze the discovered categorical crime patterns and create detailed cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "321d4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-MODES FINAL MODEL & PATTERN ANALYSIS ===\n",
      "Fitting final K-Modes model with best parameters...\n",
      "Best parameters: {'cluster__init': 'Huang', 'cluster__n_clusters': 10, 'cluster__n_init': 10}\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 1/100, moves: 1609, cost: 25724.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 2/100, moves: 967, cost: 25240.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 3/100, moves: 523, cost: 25095.0\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 1, iteration: 4/100, moves: 106, cost: 25095.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 1/100, moves: 1397, cost: 25557.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 2/100, moves: 558, cost: 25488.0\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 2, iteration: 3/100, moves: 23, cost: 25488.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 1/100, moves: 1607, cost: 25351.0\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 3, iteration: 2/100, moves: 375, cost: 25351.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 1/100, moves: 1975, cost: 25498.0\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 4, iteration: 2/100, moves: 238, cost: 25498.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 5, iteration: 1/100, moves: 1451, cost: 25995.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 1695, cost: 25114.0\n",
      "Run 6, iteration: 1/100, moves: 1695, cost: 25114.0\n",
      "Run 6, iteration: 2/100, moves: 548, cost: 25114.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 2/100, moves: 548, cost: 25114.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 1282, cost: 24901.0\n",
      "Run 7, iteration: 1/100, moves: 1282, cost: 24901.0\n",
      "Run 7, iteration: 2/100, moves: 223, cost: 24901.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 7, iteration: 2/100, moves: 223, cost: 24901.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 1462, cost: 24781.0\n",
      "Run 8, iteration: 1/100, moves: 1462, cost: 24781.0\n",
      "Run 8, iteration: 2/100, moves: 273, cost: 24781.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 2/100, moves: 273, cost: 24781.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1305, cost: 25718.0\n",
      "Run 9, iteration: 1/100, moves: 1305, cost: 25718.0\n",
      "Run 9, iteration: 2/100, moves: 503, cost: 25676.0\n",
      "Run 9, iteration: 2/100, moves: 503, cost: 25676.0\n",
      "Run 9, iteration: 3/100, moves: 14, cost: 25676.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Run 9, iteration: 3/100, moves: 14, cost: 25676.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 2056, cost: 24756.0\n",
      "Run 10, iteration: 1/100, moves: 2056, cost: 24756.0\n",
      "Run 10, iteration: 2/100, moves: 312, cost: 24700.0\n",
      "Run 10, iteration: 3/100, moves: 76, cost: 24700.0\n",
      "Best run was number 10\n",
      "Run 10, iteration: 2/100, moves: 312, cost: 24700.0\n",
      "Run 10, iteration: 3/100, moves: 76, cost: 24700.0\n",
      "Best run was number 10\n",
      "✓ Final model fitted successfully\n",
      "Number of clusters: 10\n",
      "Cluster distribution:\n",
      "  Cluster 0: 571 samples (11.4%)\n",
      "  Cluster 1: 629 samples (12.6%)\n",
      "  Cluster 2: 344 samples (6.9%)\n",
      "  Cluster 3: 572 samples (11.4%)\n",
      "  Cluster 4: 385 samples (7.7%)\n",
      "  Cluster 5: 739 samples (14.8%)\n",
      "  Cluster 6: 543 samples (10.9%)\n",
      "  Cluster 7: 508 samples (10.2%)\n",
      "  Cluster 8: 363 samples (7.3%)\n",
      "  Cluster 9: 346 samples (6.9%)\n",
      "\n",
      "=== CATEGORICAL CRIME PATTERN PROFILES ===\n",
      "\n",
      "--- CLUSTER 0 PROFILE ---\n",
      "Size: 571 samples (11.4%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: GRAND LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 48.2%\n",
      "  BROOKLYN: 24.5%\n",
      "  BRONX: 12.4%\n",
      "  QUEENS: 12.1%\n",
      "  STATEN ISLAND: 2.8%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 48.7%\n",
      "  RESIDENCE - APT. HOUSE: 11.6%\n",
      "  TRANSIT - NYC SUBWAY: 3.7%\n",
      "  RESIDENCE - PUBLIC HOUSING: 3.3%\n",
      "  RESIDENCE-HOUSE: 3.0%\n",
      "Top OFNS_DESC:\n",
      "  GRAND LARCENY: 34.5%\n",
      "  HARRASSMENT 2: 13.0%\n",
      "  PETIT LARCENY: 10.9%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 7.5%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 6.7%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 35.9%\n",
      "  AFTERNOON: 28.4%\n",
      "  MORNING: 18.2%\n",
      "  NIGHT: 17.5%\n",
      "Top IS_WEEKEND:\n",
      "  0: 78.1%\n",
      "  1: 21.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 63.0%\n",
      "  Mid: 29.1%\n",
      "  Far: 7.9%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 64.6%\n",
      "  Low: 16.6%\n",
      "  High: 11.9%\n",
      "  Medium: 6.8%\n",
      "\n",
      "--- CLUSTER 1 PROFILE ---\n",
      "Size: 629 samples (12.6%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 49.1%\n",
      "  MANHATTAN: 17.2%\n",
      "  BRONX: 14.8%\n",
      "  QUEENS: 13.7%\n",
      "  STATEN ISLAND: 5.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 40.5%\n",
      "  RESIDENCE - APT. HOUSE: 20.7%\n",
      "  RESIDENCE-HOUSE: 10.5%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.8%\n",
      "  TRANSIT - NYC SUBWAY: 3.8%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 33.9%\n",
      "  HARRASSMENT 2: 10.2%\n",
      "  FELONY ASSAULT: 9.7%\n",
      "  ROBBERY: 5.4%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 4.8%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 37.2%\n",
      "  AFTERNOON: 22.4%\n",
      "  MORNING: 21.0%\n",
      "  NIGHT: 19.4%\n",
      "Top IS_WEEKEND:\n",
      "  0: 70.0%\n",
      "  1: 30.0%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.3%\n",
      "  1: 3.7%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 51.2%\n",
      "  Mid: 33.2%\n",
      "  Far: 15.6%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 64.7%\n",
      "  High: 16.7%\n",
      "  Low: 11.8%\n",
      "  VeryHigh: 6.8%\n",
      "\n",
      "--- CLUSTER 2 PROFILE ---\n",
      "Size: 344 samples (6.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - PUBLIC HOUSING\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: F\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  QUEENS: 41.6%\n",
      "  MANHATTAN: 18.9%\n",
      "  BRONX: 16.9%\n",
      "  BROOKLYN: 15.7%\n",
      "  STATEN ISLAND: 7.0%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - PUBLIC HOUSING: 29.7%\n",
      "  RESIDENCE - APT. HOUSE: 25.3%\n",
      "  RESIDENCE-HOUSE: 19.5%\n",
      "  STREET: 7.3%\n",
      "  HOMELESS SHELTER: 3.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 43.0%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 10.2%\n",
      "  FELONY ASSAULT: 9.9%\n",
      "  MISCELLANEOUS PENAL LAW: 7.6%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 5.2%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 42.4%\n",
      "  AFTERNOON: 22.4%\n",
      "  MORNING: 22.1%\n",
      "  NIGHT: 13.1%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.6%\n",
      "  1: 22.4%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 98.3%\n",
      "  1: 1.7%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 76.2%\n",
      "  Far: 18.6%\n",
      "  Near: 5.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 73.3%\n",
      "  High: 11.6%\n",
      "  Low: 10.2%\n",
      "  VeryHigh: 4.9%\n",
      "\n",
      "--- CLUSTER 3 PROFILE ---\n",
      "Size: 572 samples (11.4%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  BRONX: 44.8%\n",
      "  BROOKLYN: 23.6%\n",
      "  QUEENS: 17.1%\n",
      "  MANHATTAN: 12.2%\n",
      "  STATEN ISLAND: 2.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 52.1%\n",
      "  RESIDENCE - APT. HOUSE: 14.9%\n",
      "  RESIDENCE-HOUSE: 8.9%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.4%\n",
      "  GROCERY/BODEGA: 2.3%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 35.7%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 11.9%\n",
      "  GRAND LARCENY: 10.7%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 9.8%\n",
      "  HARRASSMENT 2: 6.1%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 38.5%\n",
      "  AFTERNOON: 26.7%\n",
      "  MORNING: 20.1%\n",
      "  NIGHT: 14.7%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.8%\n",
      "  1: 22.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.6%\n",
      "  1: 2.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 75.7%\n",
      "  Near: 13.3%\n",
      "  Far: 11.0%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 65.6%\n",
      "  Low: 24.7%\n",
      "  High: 6.6%\n",
      "  VeryHigh: 3.1%\n",
      "\n",
      "--- CLUSTER 4 PROFILE ---\n",
      "Size: 385 samples (7.7%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  QUEENS: 42.1%\n",
      "  BROOKLYN: 19.2%\n",
      "  BRONX: 19.2%\n",
      "  MANHATTAN: 16.9%\n",
      "  STATEN ISLAND: 2.6%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 36.4%\n",
      "  TRANSIT - NYC SUBWAY: 19.2%\n",
      "  STREET: 11.4%\n",
      "  RESIDENCE-HOUSE: 7.5%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.7%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 33.0%\n",
      "  MISCELLANEOUS PENAL LAW: 9.4%\n",
      "  OTHER OFFENSES RELATED TO THEFT: 8.8%\n",
      "  HARRASSMENT 2: 8.8%\n",
      "  FELONY ASSAULT: 7.3%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 45.7%\n",
      "  MORNING: 19.0%\n",
      "  AFTERNOON: 18.2%\n",
      "  NIGHT: 17.1%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.4%\n",
      "  1: 23.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 59.2%\n",
      "  Mid: 27.0%\n",
      "  Far: 13.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 63.9%\n",
      "  Low: 20.3%\n",
      "  High: 14.8%\n",
      "  Medium: 1.0%\n",
      "\n",
      "--- CLUSTER 5 PROFILE ---\n",
      "Size: 739 samples (14.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: D\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 50.1%\n",
      "  BROOKLYN: 20.3%\n",
      "  QUEENS: 18.0%\n",
      "  BRONX: 9.5%\n",
      "  STATEN ISLAND: 2.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 28.3%\n",
      "  DEPARTMENT STORE: 13.1%\n",
      "  TRANSIT - NYC SUBWAY: 12.4%\n",
      "  DRUG STORE: 8.0%\n",
      "  STREET: 6.8%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 57.0%\n",
      "  OTHER OFFENSES RELATED TO THEFT: 7.4%\n",
      "  GRAND LARCENY: 6.5%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 6.0%\n",
      "  BURGLARY: 3.8%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 56.7%\n",
      "  MORNING: 21.9%\n",
      "  EVENING: 13.7%\n",
      "  NIGHT: 7.7%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.5%\n",
      "  1: 23.5%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.2%\n",
      "  1: 2.8%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 68.6%\n",
      "  Mid: 24.6%\n",
      "  Far: 6.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 61.0%\n",
      "  High: 20.3%\n",
      "  Low: 11.1%\n",
      "  Medium: 7.6%\n",
      "\n",
      "--- CLUSTER 6 PROFILE ---\n",
      "Size: 543 samples (10.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: VEHICLE AND TRAFFIC LAWS\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: Low\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: E\n",
      "Top BORO_NM:\n",
      "  BRONX: 35.5%\n",
      "  BROOKLYN: 25.8%\n",
      "  QUEENS: 17.7%\n",
      "  MANHATTAN: 14.7%\n",
      "  STATEN ISLAND: 6.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 53.8%\n",
      "  RESIDENCE - APT. HOUSE: 9.6%\n",
      "  OTHER: 7.0%\n",
      "  RESIDENCE - PUBLIC HOUSING: 6.4%\n",
      "  RESIDENCE-HOUSE: 4.8%\n",
      "Top OFNS_DESC:\n",
      "  VEHICLE AND TRAFFIC LAWS: 21.4%\n",
      "  DANGEROUS DRUGS: 10.9%\n",
      "  FELONY ASSAULT: 5.7%\n",
      "  FORGERY: 4.8%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 4.6%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 44.0%\n",
      "  AFTERNOON: 24.3%\n",
      "  NIGHT: 17.7%\n",
      "  MORNING: 14.0%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.8%\n",
      "  1: 23.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 68.0%\n",
      "  Near: 20.3%\n",
      "  Far: 11.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 59.9%\n",
      "  High: 20.3%\n",
      "  VeryHigh: 11.2%\n",
      "  Medium: 8.7%\n",
      "\n",
      "--- CLUSTER 7 PROFILE ---\n",
      "Size: 508 samples (10.2%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: High\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  BRONX: 40.4%\n",
      "  BROOKLYN: 22.2%\n",
      "  MANHATTAN: 18.1%\n",
      "  QUEENS: 14.6%\n",
      "  STATEN ISLAND: 4.7%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 47.4%\n",
      "  STREET: 12.6%\n",
      "  RESIDENCE-HOUSE: 10.4%\n",
      "  RESIDENCE - PUBLIC HOUSING: 9.3%\n",
      "  OTHER: 3.3%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 39.0%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 10.8%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.1%\n",
      "  GRAND LARCENY: 8.1%\n",
      "  FELONY ASSAULT: 6.1%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 47.6%\n",
      "  MORNING: 23.2%\n",
      "  EVENING: 15.9%\n",
      "  NIGHT: 13.2%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.8%\n",
      "  1: 22.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 69.1%\n",
      "  Near: 20.7%\n",
      "  Far: 10.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 77.8%\n",
      "  Low: 10.6%\n",
      "  Medium: 8.9%\n",
      "  VeryHigh: 2.8%\n",
      "\n",
      "--- CLUSTER 8 PROFILE ---\n",
      "Size: 363 samples (7.3%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Far\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: High\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  QUEENS: 55.1%\n",
      "  BROOKLYN: 22.3%\n",
      "  MANHATTAN: 10.5%\n",
      "  STATEN ISLAND: 6.1%\n",
      "  BRONX: 6.1%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 50.7%\n",
      "  RESIDENCE-HOUSE: 14.6%\n",
      "  RESIDENCE - APT. HOUSE: 9.9%\n",
      "  RESIDENCE - PUBLIC HOUSING: 3.3%\n",
      "  OTHER: 2.2%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 32.2%\n",
      "  GRAND LARCENY: 10.2%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.6%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 9.1%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 7.7%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 47.9%\n",
      "  MORNING: 20.1%\n",
      "  NIGHT: 17.9%\n",
      "  EVENING: 14.0%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.7%\n",
      "  1: 27.3%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.5%\n",
      "  1: 2.5%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Far: 44.4%\n",
      "  Mid: 31.4%\n",
      "  Near: 24.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 76.0%\n",
      "  Low: 17.6%\n",
      "  VeryHigh: 4.4%\n",
      "  Medium: 1.9%\n",
      "\n",
      "--- CLUSTER 9 PROFILE ---\n",
      "Size: 346 samples (6.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 1\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: Low\n",
      "  SUSP_AGE_GROUP: F\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 54.0%\n",
      "  BRONX: 14.2%\n",
      "  QUEENS: 13.9%\n",
      "  MANHATTAN: 11.8%\n",
      "  STATEN ISLAND: 6.1%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 41.9%\n",
      "  RESIDENCE-HOUSE: 17.3%\n",
      "  STREET: 12.4%\n",
      "  RESIDENCE - PUBLIC HOUSING: 10.7%\n",
      "  HOMELESS SHELTER: 3.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 34.7%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 15.3%\n",
      "  PETIT LARCENY: 7.8%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 7.5%\n",
      "  GRAND LARCENY: 7.5%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 46.5%\n",
      "  MORNING: 25.1%\n",
      "  EVENING: 14.7%\n",
      "  NIGHT: 13.6%\n",
      "Top IS_WEEKEND:\n",
      "  1: 59.5%\n",
      "  0: 40.5%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 99.1%\n",
      "  1: 0.9%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 69.9%\n",
      "  Far: 15.3%\n",
      "  Near: 14.7%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 87.3%\n",
      "  Medium: 5.2%\n",
      "  VeryHigh: 4.3%\n",
      "  High: 3.2%\n",
      "\n",
      "Sample cluster profiles:\n",
      "   cluster  size top_boro_nm           top_prem_typ_desc  \\\n",
      "0        0   571   MANHATTAN                      STREET   \n",
      "1        1   629    BROOKLYN                      STREET   \n",
      "2        2   344      QUEENS  RESIDENCE - PUBLIC HOUSING   \n",
      "3        3   572       BRONX                      STREET   \n",
      "4        4   385      QUEENS      RESIDENCE - APT. HOUSE   \n",
      "\n",
      "                  top_ofns_desc top_time_bucket top_is_weekend top_is_holiday  \\\n",
      "0                 GRAND LARCENY         EVENING              0              0   \n",
      "1  ASSAULT 3 & RELATED OFFENSES         EVENING              0              0   \n",
      "2                 HARRASSMENT 2         EVENING              0              0   \n",
      "3                 PETIT LARCENY         EVENING              0              0   \n",
      "4  ASSAULT 3 & RELATED OFFENSES         EVENING              0              0   \n",
      "\n",
      "  top_metro_distance_bin top_poi_density_score_bin  \n",
      "0                   Near                  VeryHigh  \n",
      "1                   Near                    Medium  \n",
      "2                    Mid                    Medium  \n",
      "3                    Mid                    Medium  \n",
      "4                   Near                  VeryHigh  \n",
      "✓ Final model fitted successfully\n",
      "Number of clusters: 10\n",
      "Cluster distribution:\n",
      "  Cluster 0: 571 samples (11.4%)\n",
      "  Cluster 1: 629 samples (12.6%)\n",
      "  Cluster 2: 344 samples (6.9%)\n",
      "  Cluster 3: 572 samples (11.4%)\n",
      "  Cluster 4: 385 samples (7.7%)\n",
      "  Cluster 5: 739 samples (14.8%)\n",
      "  Cluster 6: 543 samples (10.9%)\n",
      "  Cluster 7: 508 samples (10.2%)\n",
      "  Cluster 8: 363 samples (7.3%)\n",
      "  Cluster 9: 346 samples (6.9%)\n",
      "\n",
      "=== CATEGORICAL CRIME PATTERN PROFILES ===\n",
      "\n",
      "--- CLUSTER 0 PROFILE ---\n",
      "Size: 571 samples (11.4%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: GRAND LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 48.2%\n",
      "  BROOKLYN: 24.5%\n",
      "  BRONX: 12.4%\n",
      "  QUEENS: 12.1%\n",
      "  STATEN ISLAND: 2.8%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 48.7%\n",
      "  RESIDENCE - APT. HOUSE: 11.6%\n",
      "  TRANSIT - NYC SUBWAY: 3.7%\n",
      "  RESIDENCE - PUBLIC HOUSING: 3.3%\n",
      "  RESIDENCE-HOUSE: 3.0%\n",
      "Top OFNS_DESC:\n",
      "  GRAND LARCENY: 34.5%\n",
      "  HARRASSMENT 2: 13.0%\n",
      "  PETIT LARCENY: 10.9%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 7.5%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 6.7%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 35.9%\n",
      "  AFTERNOON: 28.4%\n",
      "  MORNING: 18.2%\n",
      "  NIGHT: 17.5%\n",
      "Top IS_WEEKEND:\n",
      "  0: 78.1%\n",
      "  1: 21.9%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 63.0%\n",
      "  Mid: 29.1%\n",
      "  Far: 7.9%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 64.6%\n",
      "  Low: 16.6%\n",
      "  High: 11.9%\n",
      "  Medium: 6.8%\n",
      "\n",
      "--- CLUSTER 1 PROFILE ---\n",
      "Size: 629 samples (12.6%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 49.1%\n",
      "  MANHATTAN: 17.2%\n",
      "  BRONX: 14.8%\n",
      "  QUEENS: 13.7%\n",
      "  STATEN ISLAND: 5.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 40.5%\n",
      "  RESIDENCE - APT. HOUSE: 20.7%\n",
      "  RESIDENCE-HOUSE: 10.5%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.8%\n",
      "  TRANSIT - NYC SUBWAY: 3.8%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 33.9%\n",
      "  HARRASSMENT 2: 10.2%\n",
      "  FELONY ASSAULT: 9.7%\n",
      "  ROBBERY: 5.4%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 4.8%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 37.2%\n",
      "  AFTERNOON: 22.4%\n",
      "  MORNING: 21.0%\n",
      "  NIGHT: 19.4%\n",
      "Top IS_WEEKEND:\n",
      "  0: 70.0%\n",
      "  1: 30.0%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 96.3%\n",
      "  1: 3.7%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 51.2%\n",
      "  Mid: 33.2%\n",
      "  Far: 15.6%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 64.7%\n",
      "  High: 16.7%\n",
      "  Low: 11.8%\n",
      "  VeryHigh: 6.8%\n",
      "\n",
      "--- CLUSTER 2 PROFILE ---\n",
      "Size: 344 samples (6.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - PUBLIC HOUSING\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: F\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  QUEENS: 41.6%\n",
      "  MANHATTAN: 18.9%\n",
      "  BRONX: 16.9%\n",
      "  BROOKLYN: 15.7%\n",
      "  STATEN ISLAND: 7.0%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - PUBLIC HOUSING: 29.7%\n",
      "  RESIDENCE - APT. HOUSE: 25.3%\n",
      "  RESIDENCE-HOUSE: 19.5%\n",
      "  STREET: 7.3%\n",
      "  HOMELESS SHELTER: 3.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 43.0%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 10.2%\n",
      "  FELONY ASSAULT: 9.9%\n",
      "  MISCELLANEOUS PENAL LAW: 7.6%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 5.2%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 42.4%\n",
      "  AFTERNOON: 22.4%\n",
      "  MORNING: 22.1%\n",
      "  NIGHT: 13.1%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.6%\n",
      "  1: 22.4%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 98.3%\n",
      "  1: 1.7%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 76.2%\n",
      "  Far: 18.6%\n",
      "  Near: 5.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 73.3%\n",
      "  High: 11.6%\n",
      "  Low: 10.2%\n",
      "  VeryHigh: 4.9%\n",
      "\n",
      "--- CLUSTER 3 PROFILE ---\n",
      "Size: 572 samples (11.4%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Medium\n",
      "  SUSP_SEX: Medium\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  BRONX: 44.8%\n",
      "  BROOKLYN: 23.6%\n",
      "  QUEENS: 17.1%\n",
      "  MANHATTAN: 12.2%\n",
      "  STATEN ISLAND: 2.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 52.1%\n",
      "  RESIDENCE - APT. HOUSE: 14.9%\n",
      "  RESIDENCE-HOUSE: 8.9%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.4%\n",
      "  GROCERY/BODEGA: 2.3%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 35.7%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 11.9%\n",
      "  GRAND LARCENY: 10.7%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 9.8%\n",
      "  HARRASSMENT 2: 6.1%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 38.5%\n",
      "  AFTERNOON: 26.7%\n",
      "  MORNING: 20.1%\n",
      "  NIGHT: 14.7%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.8%\n",
      "  1: 22.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.6%\n",
      "  1: 2.4%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 75.7%\n",
      "  Near: 13.3%\n",
      "  Far: 11.0%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Medium: 65.6%\n",
      "  Low: 24.7%\n",
      "  High: 6.6%\n",
      "  VeryHigh: 3.1%\n",
      "\n",
      "--- CLUSTER 4 PROFILE ---\n",
      "Size: 385 samples (7.7%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: ASSAULT 3 & RELATED OFFENSES\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  QUEENS: 42.1%\n",
      "  BROOKLYN: 19.2%\n",
      "  BRONX: 19.2%\n",
      "  MANHATTAN: 16.9%\n",
      "  STATEN ISLAND: 2.6%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 36.4%\n",
      "  TRANSIT - NYC SUBWAY: 19.2%\n",
      "  STREET: 11.4%\n",
      "  RESIDENCE-HOUSE: 7.5%\n",
      "  RESIDENCE - PUBLIC HOUSING: 4.7%\n",
      "Top OFNS_DESC:\n",
      "  ASSAULT 3 & RELATED OFFENSES: 33.0%\n",
      "  MISCELLANEOUS PENAL LAW: 9.4%\n",
      "  OTHER OFFENSES RELATED TO THEFT: 8.8%\n",
      "  HARRASSMENT 2: 8.8%\n",
      "  FELONY ASSAULT: 7.3%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 45.7%\n",
      "  MORNING: 19.0%\n",
      "  AFTERNOON: 18.2%\n",
      "  NIGHT: 17.1%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.4%\n",
      "  1: 23.6%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 59.2%\n",
      "  Mid: 27.0%\n",
      "  Far: 13.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 63.9%\n",
      "  Low: 20.3%\n",
      "  High: 14.8%\n",
      "  Medium: 1.0%\n",
      "\n",
      "--- CLUSTER 5 PROFILE ---\n",
      "Size: 739 samples (14.8%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: MANHATTAN\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: CHAIN STORE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Near\n",
      "  POI_DENSITY_SCORE_BIN: VeryHigh\n",
      "  SUSP_SEX: VeryHigh\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: D\n",
      "Top BORO_NM:\n",
      "  MANHATTAN: 50.1%\n",
      "  BROOKLYN: 20.3%\n",
      "  QUEENS: 18.0%\n",
      "  BRONX: 9.5%\n",
      "  STATEN ISLAND: 2.2%\n",
      "Top PREM_TYP_DESC:\n",
      "  CHAIN STORE: 28.3%\n",
      "  DEPARTMENT STORE: 13.1%\n",
      "  TRANSIT - NYC SUBWAY: 12.4%\n",
      "  DRUG STORE: 8.0%\n",
      "  STREET: 6.8%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 57.0%\n",
      "  OTHER OFFENSES RELATED TO THEFT: 7.4%\n",
      "  GRAND LARCENY: 6.5%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 6.0%\n",
      "  BURGLARY: 3.8%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 56.7%\n",
      "  MORNING: 21.9%\n",
      "  EVENING: 13.7%\n",
      "  NIGHT: 7.7%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.5%\n",
      "  1: 23.5%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.2%\n",
      "  1: 2.8%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Near: 68.6%\n",
      "  Mid: 24.6%\n",
      "  Far: 6.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  VeryHigh: 61.0%\n",
      "  High: 20.3%\n",
      "  Low: 11.1%\n",
      "  Medium: 7.6%\n",
      "\n",
      "--- CLUSTER 6 PROFILE ---\n",
      "Size: 543 samples (10.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: VEHICLE AND TRAFFIC LAWS\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: EVENING\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: Low\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: 25-44\n",
      "  VIC_AGE_GROUP: E\n",
      "Top BORO_NM:\n",
      "  BRONX: 35.5%\n",
      "  BROOKLYN: 25.8%\n",
      "  QUEENS: 17.7%\n",
      "  MANHATTAN: 14.7%\n",
      "  STATEN ISLAND: 6.3%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 53.8%\n",
      "  RESIDENCE - APT. HOUSE: 9.6%\n",
      "  OTHER: 7.0%\n",
      "  RESIDENCE - PUBLIC HOUSING: 6.4%\n",
      "  RESIDENCE-HOUSE: 4.8%\n",
      "Top OFNS_DESC:\n",
      "  VEHICLE AND TRAFFIC LAWS: 21.4%\n",
      "  DANGEROUS DRUGS: 10.9%\n",
      "  FELONY ASSAULT: 5.7%\n",
      "  FORGERY: 4.8%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 4.6%\n",
      "Top TIME_BUCKET:\n",
      "  EVENING: 44.0%\n",
      "  AFTERNOON: 24.3%\n",
      "  NIGHT: 17.7%\n",
      "  MORNING: 14.0%\n",
      "Top IS_WEEKEND:\n",
      "  0: 76.8%\n",
      "  1: 23.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 68.0%\n",
      "  Near: 20.3%\n",
      "  Far: 11.8%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 59.9%\n",
      "  High: 20.3%\n",
      "  VeryHigh: 11.2%\n",
      "  Medium: 8.7%\n",
      "\n",
      "--- CLUSTER 7 PROFILE ---\n",
      "Size: 508 samples (10.2%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BRONX\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: High\n",
      "  SUSP_AGE_GROUP: M\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  BRONX: 40.4%\n",
      "  BROOKLYN: 22.2%\n",
      "  MANHATTAN: 18.1%\n",
      "  QUEENS: 14.6%\n",
      "  STATEN ISLAND: 4.7%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 47.4%\n",
      "  STREET: 12.6%\n",
      "  RESIDENCE-HOUSE: 10.4%\n",
      "  RESIDENCE - PUBLIC HOUSING: 9.3%\n",
      "  OTHER: 3.3%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 39.0%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 10.8%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.1%\n",
      "  GRAND LARCENY: 8.1%\n",
      "  FELONY ASSAULT: 6.1%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 47.6%\n",
      "  MORNING: 23.2%\n",
      "  EVENING: 15.9%\n",
      "  NIGHT: 13.2%\n",
      "Top IS_WEEKEND:\n",
      "  0: 77.8%\n",
      "  1: 22.2%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.4%\n",
      "  1: 2.6%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 69.1%\n",
      "  Near: 20.7%\n",
      "  Far: 10.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 77.8%\n",
      "  Low: 10.6%\n",
      "  Medium: 8.9%\n",
      "  VeryHigh: 2.8%\n",
      "\n",
      "--- CLUSTER 8 PROFILE ---\n",
      "Size: 363 samples (7.3%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: QUEENS\n",
      "  OFNS_DESC: PETIT LARCENY\n",
      "  PREM_TYP_DESC: STREET\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 0\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Far\n",
      "  POI_DENSITY_SCORE_BIN: High\n",
      "  SUSP_SEX: High\n",
      "  SUSP_AGE_GROUP: U\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: M\n",
      "Top BORO_NM:\n",
      "  QUEENS: 55.1%\n",
      "  BROOKLYN: 22.3%\n",
      "  MANHATTAN: 10.5%\n",
      "  STATEN ISLAND: 6.1%\n",
      "  BRONX: 6.1%\n",
      "Top PREM_TYP_DESC:\n",
      "  STREET: 50.7%\n",
      "  RESIDENCE-HOUSE: 14.6%\n",
      "  RESIDENCE - APT. HOUSE: 9.9%\n",
      "  RESIDENCE - PUBLIC HOUSING: 3.3%\n",
      "  OTHER: 2.2%\n",
      "Top OFNS_DESC:\n",
      "  PETIT LARCENY: 32.2%\n",
      "  GRAND LARCENY: 10.2%\n",
      "  CRIMINAL MISCHIEF & RELATED OF: 9.6%\n",
      "  GRAND LARCENY OF MOTOR VEHICLE: 9.1%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 7.7%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 47.9%\n",
      "  MORNING: 20.1%\n",
      "  NIGHT: 17.9%\n",
      "  EVENING: 14.0%\n",
      "Top IS_WEEKEND:\n",
      "  0: 72.7%\n",
      "  1: 27.3%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 97.5%\n",
      "  1: 2.5%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Far: 44.4%\n",
      "  Mid: 31.4%\n",
      "  Near: 24.2%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  High: 76.0%\n",
      "  Low: 17.6%\n",
      "  VeryHigh: 4.4%\n",
      "  Medium: 1.9%\n",
      "\n",
      "--- CLUSTER 9 PROFILE ---\n",
      "Size: 346 samples (6.9%)\n",
      "Centroid pattern:\n",
      "  BORO_NM: BROOKLYN\n",
      "  OFNS_DESC: HARRASSMENT 2\n",
      "  PREM_TYP_DESC: RESIDENCE - APT. HOUSE\n",
      "  TIME_BUCKET: AFTERNOON\n",
      "  IS_WEEKEND: 1\n",
      "  IS_HOLIDAY: 0\n",
      "  METRO_DISTANCE_BIN: Mid\n",
      "  POI_DENSITY_SCORE_BIN: Low\n",
      "  SUSP_SEX: Low\n",
      "  SUSP_AGE_GROUP: F\n",
      "  VIC_SEX: UNKNOWN\n",
      "  VIC_AGE_GROUP: F\n",
      "Top BORO_NM:\n",
      "  BROOKLYN: 54.0%\n",
      "  BRONX: 14.2%\n",
      "  QUEENS: 13.9%\n",
      "  MANHATTAN: 11.8%\n",
      "  STATEN ISLAND: 6.1%\n",
      "Top PREM_TYP_DESC:\n",
      "  RESIDENCE - APT. HOUSE: 41.9%\n",
      "  RESIDENCE-HOUSE: 17.3%\n",
      "  STREET: 12.4%\n",
      "  RESIDENCE - PUBLIC HOUSING: 10.7%\n",
      "  HOMELESS SHELTER: 3.2%\n",
      "Top OFNS_DESC:\n",
      "  HARRASSMENT 2: 34.7%\n",
      "  ASSAULT 3 & RELATED OFFENSES: 15.3%\n",
      "  PETIT LARCENY: 7.8%\n",
      "  OFF. AGNST PUB ORD SENSBLTY &: 7.5%\n",
      "  GRAND LARCENY: 7.5%\n",
      "Top TIME_BUCKET:\n",
      "  AFTERNOON: 46.5%\n",
      "  MORNING: 25.1%\n",
      "  EVENING: 14.7%\n",
      "  NIGHT: 13.6%\n",
      "Top IS_WEEKEND:\n",
      "  1: 59.5%\n",
      "  0: 40.5%\n",
      "Top IS_HOLIDAY:\n",
      "  0: 99.1%\n",
      "  1: 0.9%\n",
      "Top METRO_DISTANCE_BIN:\n",
      "  Mid: 69.9%\n",
      "  Far: 15.3%\n",
      "  Near: 14.7%\n",
      "Top POI_DENSITY_SCORE_BIN:\n",
      "  Low: 87.3%\n",
      "  Medium: 5.2%\n",
      "  VeryHigh: 4.3%\n",
      "  High: 3.2%\n",
      "\n",
      "Sample cluster profiles:\n",
      "   cluster  size top_boro_nm           top_prem_typ_desc  \\\n",
      "0        0   571   MANHATTAN                      STREET   \n",
      "1        1   629    BROOKLYN                      STREET   \n",
      "2        2   344      QUEENS  RESIDENCE - PUBLIC HOUSING   \n",
      "3        3   572       BRONX                      STREET   \n",
      "4        4   385      QUEENS      RESIDENCE - APT. HOUSE   \n",
      "\n",
      "                  top_ofns_desc top_time_bucket top_is_weekend top_is_holiday  \\\n",
      "0                 GRAND LARCENY         EVENING              0              0   \n",
      "1  ASSAULT 3 & RELATED OFFENSES         EVENING              0              0   \n",
      "2                 HARRASSMENT 2         EVENING              0              0   \n",
      "3                 PETIT LARCENY         EVENING              0              0   \n",
      "4  ASSAULT 3 & RELATED OFFENSES         EVENING              0              0   \n",
      "\n",
      "  top_metro_distance_bin top_poi_density_score_bin  \n",
      "0                   Near                  VeryHigh  \n",
      "1                   Near                    Medium  \n",
      "2                    Mid                    Medium  \n",
      "3                    Mid                    Medium  \n",
      "4                   Near                  VeryHigh  \n"
     ]
    }
   ],
   "source": [
    "if 'df_kmodes_results' in locals() and not df_kmodes_results.empty:\n",
    "    print(\"=== K-MODES FINAL MODEL & PATTERN ANALYSIS ===\")\n",
    "    \n",
    "    # Fit best model (following SpatialHotspotAnalysis approach)\n",
    "    print(f\"Fitting final K-Modes model with best parameters...\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Create and fit final pipeline\n",
    "    final_kmodes_pipeline = Pipeline([\n",
    "        ('preprocess', CategoricalPreprocessor(handle_missing='drop')),\n",
    "        ('cluster', KModes(\n",
    "            n_clusters=best_params['cluster__n_clusters'],\n",
    "            init=best_params['cluster__init'],\n",
    "            n_init=best_params['cluster__n_init'],\n",
    "            verbose=1,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Fit and predict\n",
    "    final_labels = final_kmodes_pipeline.fit_predict(X_categorical)\n",
    "    final_centroids = final_kmodes_pipeline.named_steps['cluster'].cluster_centroids_\n",
    "    \n",
    "    # Add cluster labels to original dataframe for analysis\n",
    "    df_kmodes_labeled = df_kmodes.copy()\n",
    "    df_kmodes_labeled['cluster'] = final_labels\n",
    "    \n",
    "    print(f\"✓ Final model fitted successfully\")\n",
    "    print(f\"Number of clusters: {len(np.unique(final_labels))}\")\n",
    "    print(f\"Cluster distribution:\")\n",
    "    cluster_counts = pd.Series(final_labels).value_counts().sort_index()\n",
    "    for cluster_id, count in cluster_counts.items():\n",
    "        print(f\"  Cluster {cluster_id}: {count} samples ({(count/len(final_labels))*100:.1f}%)\")\n",
    "    \n",
    "    # Create detailed cluster profiles (similar to SpatialHotspotAnalysis cluster profiling)\n",
    "    print(f\"\\n=== CATEGORICAL CRIME PATTERN PROFILES ===\")\n",
    "    \n",
    "    cluster_profiles = []\n",
    "    feature_names = [f for f in X_categorical.columns.tolist() if f != 'TOTAL_POI_COUNT_BIN']\n",
    "    \n",
    "    for cluster_id in sorted(np.unique(final_labels)):\n",
    "        cluster_mask = final_labels == cluster_id\n",
    "        cluster_data = df_kmodes_labeled[cluster_mask]\n",
    "        cluster_size = cluster_mask.sum()\n",
    "        \n",
    "        print(f\"\\n--- CLUSTER {cluster_id} PROFILE ---\")\n",
    "        print(f\"Size: {cluster_size} samples ({(cluster_size/len(final_labels))*100:.1f}%)\")\n",
    "        \n",
    "        # Get centroid pattern\n",
    "        centroid = final_centroids[cluster_id]\n",
    "        print(f\"Centroid pattern:\")\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            print(f\"  {feature}: {centroid[i]}\")\n",
    "        \n",
    "        # Top distributions per key features\n",
    "        summary_cols = [\n",
    "            'BORO_NM', 'PREM_TYP_DESC', 'OFNS_DESC',\n",
    "            'TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY',\n",
    "            'METRO_DISTANCE_BIN', 'POI_DENSITY_SCORE_BIN',\n",
    "        ]\n",
    "        summary_cols = [c for c in summary_cols if c in cluster_data.columns]\n",
    "        for col in summary_cols:\n",
    "            dist = cluster_data[col].value_counts(normalize=True).head(5)\n",
    "            print(f\"Top {col}:\")\n",
    "            for val, pct in dist.items():\n",
    "                print(f\"  {val}: {pct*100:.1f}%\")\n",
    "        \n",
    "        # Store a compact profile\n",
    "        profile = {\n",
    "            'cluster': int(cluster_id),\n",
    "            'size': int(cluster_size),\n",
    "        }\n",
    "        for col in summary_cols:\n",
    "            top_val = cluster_data[col].value_counts().idxmax()\n",
    "            profile[f'top_{col.lower()}'] = str(top_val)\n",
    "        cluster_profiles.append(profile)\n",
    "    \n",
    "    df_cluster_profiles = pd.DataFrame(cluster_profiles)\n",
    "    print(\"\\nSample cluster profiles:\")\n",
    "    print(df_cluster_profiles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248adafa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Police-Focused Crime Intelligence Analysis\n",
    "\n",
    "This section transforms the K-Modes clustering results into **actionable intelligence** for law enforcement operations. We create operational crime profiles, tactical recommendations, and priority assessment for police deployment.\n",
    "\n",
    "## Crime Pattern Intelligence Reports\n",
    "\n",
    "Transform abstract clustering results into concrete operational insights for police commanders and patrol units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d49b32",
   "metadata": {},
   "source": [
    "### 4.A Operational cluster summaries (concise tables)\n",
    "\n",
    "The tables below summarize clusters for police operations without narrative: top patterns and cross-tabs by borough, crime type, time, premises, weekend/holiday, and demographics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top clusters (by priority, volume, concentration):\n",
      " cluster_id    priority  crime_count primary_borough                primary_crime           primary_premises primary_time_bucket\n",
      "          5        HIGH          739       MANHATTAN                PETIT LARCENY                CHAIN STORE           AFTERNOON\n",
      "          1        HIGH          629        BROOKLYN ASSAULT 3 & RELATED OFFENSES                     STREET             EVENING\n",
      "          4         LOW          385          QUEENS ASSAULT 3 & RELATED OFFENSES     RESIDENCE - APT. HOUSE             EVENING\n",
      "          8         LOW          363          QUEENS                PETIT LARCENY                     STREET           AFTERNOON\n",
      "          9         LOW          346        BROOKLYN                HARRASSMENT 2     RESIDENCE - APT. HOUSE           AFTERNOON\n",
      "          2         LOW          344          QUEENS                HARRASSMENT 2 RESIDENCE - PUBLIC HOUSING             EVENING\n",
      "          6      MEDIUM          543           BRONX     VEHICLE AND TRAFFIC LAWS                     STREET             EVENING\n",
      "          7      MEDIUM          508           BRONX                HARRASSMENT 2     RESIDENCE - APT. HOUSE           AFTERNOON\n",
      "          3 MEDIUM-HIGH          572           BRONX                PETIT LARCENY                     STREET             EVENING\n",
      "          0 MEDIUM-HIGH          571       MANHATTAN                GRAND LARCENY                     STREET             EVENING\n",
      "\n",
      "Borough x Priority\n",
      "priority       HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "BORO_NM                                       \n",
      "BRONX          0.15  0.19    0.36         0.30\n",
      "BROOKLYN       0.33  0.29    0.18         0.20\n",
      "MANHATTAN      0.40  0.17    0.14         0.29\n",
      "QUEENS         0.20  0.50    0.15         0.15\n",
      "STATEN ISLAND  0.23  0.36    0.27         0.14\n",
      "\n",
      "Top Crime Types x Priority (top 12)\n",
      "priority                        HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "OFNS_DESC                                                      \n",
      "ASSAULT 3 & RELATED OFFENSES    0.36  0.40    0.13         0.11\n",
      "BURGLARY                        0.32  0.25    0.21         0.22\n",
      "CRIMINAL MISCHIEF & RELATED OF  0.22  0.26    0.20         0.33\n",
      "DANGEROUS DRUGS                 0.34  0.09    0.48         0.09\n",
      "FELONY ASSAULT                  0.24  0.35    0.23         0.17\n",
      "GRAND LARCENY                   0.15  0.17    0.12         0.56\n",
      "HARRASSMENT 2                   0.10  0.44    0.30         0.15\n",
      "MISCELLANEOUS PENAL LAW         0.17  0.49    0.25         0.09\n",
      "OFF. AGNST PUB ORD SENSBLTY &   0.15  0.47    0.27         0.11\n",
      "OTHER                           0.30  0.25    0.27         0.18\n",
      "PETIT LARCENY                   0.48  0.18    0.05         0.29\n",
      "ROBBERY                         0.33  0.24    0.20         0.24\n",
      "VEHICLE AND TRAFFIC LAWS        0.06  0.13    0.59         0.21\n",
      "\n",
      "Premises x Priority (top 12)\n",
      "priority                    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "PREM_TYP_DESC                                              \n",
      "CHAIN STORE                 0.82  0.07    0.04         0.06\n",
      "COMMERCIAL BUILDING         0.41  0.22    0.11         0.26\n",
      "DEPARTMENT STORE            0.76  0.08    0.08         0.08\n",
      "DRUG STORE                  0.83  0.10    0.03         0.04\n",
      "GROCERY/BODEGA              0.40  0.13    0.16         0.31\n",
      "HOMELESS SHELTER            0.31  0.38    0.15         0.15\n",
      "OTHER                       0.31  0.23    0.20         0.25\n",
      "RESIDENCE - APT. HOUSE      0.14  0.41    0.30         0.15\n",
      "RESIDENCE - PUBLIC HOUSING  0.11  0.51    0.25         0.13\n",
      "RESIDENCE-HOUSE             0.16  0.49    0.19         0.16\n",
      "STREET                      0.20  0.19    0.23         0.38\n",
      "TRANSIT - NYC SUBWAY        0.47  0.33    0.11         0.09\n",
      "\n",
      "Time Bucket x Priority\n",
      "priority     HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "TIME_BUCKET                                 \n",
      "AFTERNOON    0.32  0.28    0.22         0.18\n",
      "EVENING      0.22  0.28    0.21         0.28\n",
      "MORNING      0.29  0.30    0.19         0.22\n",
      "NIGHT        0.24  0.30    0.22         0.25\n",
      "\n",
      "Weekend x Priority\n",
      "priority    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "IS_WEEKEND                                 \n",
      "0           0.27  0.26    0.22         0.24\n",
      "1           0.27  0.36    0.18         0.19\n",
      "\n",
      "Holiday x Priority\n",
      "priority    HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "IS_HOLIDAY                                 \n",
      "0           0.27  0.29    0.21         0.23\n",
      "1           0.34  0.22    0.21         0.23\n",
      "\n",
      "Suspect Sex x Priority\n",
      "priority  HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "SUSP_SEX                                 \n",
      "F         0.21  0.53    0.18         0.09\n",
      "M         0.41  0.23    0.29         0.07\n",
      "U         0.08  0.27    0.09         0.56\n",
      "\n",
      "Suspect Age x Priority\n",
      "priority        HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "SUSP_AGE_GROUP                                 \n",
      "18-24           0.31  0.28    0.35         0.06\n",
      "25-44           0.36  0.35    0.26         0.03\n",
      "45-64           0.39  0.25    0.31         0.05\n",
      "65+             0.28  0.37    0.32         0.04\n",
      "<18             0.26  0.36    0.30         0.07\n",
      "UNKNOWN         0.20  0.25    0.13         0.42\n",
      "\n",
      "Victim Sex x Priority\n",
      "priority  HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "VIC_SEX                                  \n",
      "D         0.77  0.07    0.08         0.08\n",
      "E         0.28  0.15    0.50         0.07\n",
      "F         0.08  0.45    0.23         0.24\n",
      "L         0.14  0.27    0.32         0.27\n",
      "M         0.24  0.28    0.12         0.35\n",
      "\n",
      "Victim Age x Priority\n",
      "priority       HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "VIC_AGE_GROUP                                 \n",
      "18-24          0.16  0.38    0.20         0.26\n",
      "25-44          0.17  0.41    0.10         0.32\n",
      "45-64          0.13  0.27    0.31         0.29\n",
      "65+            0.15  0.34    0.19         0.32\n",
      "<18            0.18  0.42    0.23         0.17\n",
      "UNKNOWN        0.52  0.12    0.28         0.08\n",
      "\n",
      "Victim Age x Priority\n",
      "priority       HIGH   LOW  MEDIUM  MEDIUM-HIGH\n",
      "VIC_AGE_GROUP                                 \n",
      "18-24          0.16  0.38    0.20         0.26\n",
      "25-44          0.17  0.41    0.10         0.32\n",
      "45-64          0.13  0.27    0.31         0.29\n",
      "65+            0.15  0.34    0.19         0.32\n",
      "<18            0.18  0.42    0.23         0.17\n",
      "UNKNOWN        0.52  0.12    0.28         0.08\n"
     ]
    }
   ],
   "source": [
    "# Build ops (operational) dataframe and produce concise police-focused tables\n",
    "# Helper: mode with safe fallback\n",
    "_def = lambda s, default='Unknown': (s.mode().iloc[0] if not s.mode().empty else default)\n",
    "\n",
    "# 1) Build ops\n",
    "ops = None\n",
    "try:\n",
    "    if 'df_operational' in locals() and isinstance(df_operational, pd.DataFrame) and not df_operational.empty:\n",
    "        ops = df_operational.copy()\n",
    "    elif 'df_cluster_profiles' in locals() and isinstance(df_cluster_profiles, pd.DataFrame) and not df_cluster_profiles.empty:\n",
    "        # Derive a minimal ops from profiles\n",
    "        dfp = df_cluster_profiles.copy()\n",
    "        rename_map = {\n",
    "            'cluster': 'cluster_id',\n",
    "            'top_ofns_desc': 'primary_crime',\n",
    "            'top_boro_nm': 'primary_borough',\n",
    "            'top_prem_typ_desc': 'primary_premises',\n",
    "            'top_time_bucket': 'primary_time_bucket',\n",
    "            'crime_count': 'crime_count',\n",
    "            'concentration_score': 'concentration_score'\n",
    "        }\n",
    "        for col in list(rename_map):\n",
    "            if col not in dfp.columns:\n",
    "                # try to infer common names\n",
    "                if col == 'crime_count' and 'size' in dfp.columns:\n",
    "                    dfp['crime_count'] = dfp['size']\n",
    "                elif col == 'concentration_score' and 'composite_score' in dfp.columns:\n",
    "                    dfp['concentration_score'] = dfp['composite_score']\n",
    "                elif col == 'top_ofns_desc' and 'OFNS_DESC' in dfp.columns:\n",
    "                    dfp['top_ofns_desc'] = dfp['OFNS_DESC']\n",
    "                elif col == 'top_boro_nm' and 'BORO_NM' in dfp.columns:\n",
    "                    dfp['top_boro_nm'] = dfp['BORO_NM']\n",
    "                elif col == 'top_prem_typ_desc' and 'PREM_TYP_DESC' in dfp.columns:\n",
    "                    dfp['top_prem_typ_desc'] = dfp['PREM_TYP_DESC']\n",
    "                elif col == 'top_time_bucket' and 'TIME_BUCKET' in dfp.columns:\n",
    "                    dfp['top_time_bucket'] = dfp['TIME_BUCKET']\n",
    "        ops = dfp.rename(columns={k: v for k, v in rename_map.items() if k in dfp.columns})\n",
    "    elif 'df_kmodes_labeled' in locals() and isinstance(df_kmodes_labeled, pd.DataFrame) and not df_kmodes_labeled.empty:\n",
    "        g = df_kmodes_labeled.groupby('cluster')\n",
    "        rows = []\n",
    "        for cid, grp in g:\n",
    "            rows.append({\n",
    "                'cluster_id': int(cid),\n",
    "                'primary_crime': _def(grp['OFNS_DESC']) if 'OFNS_DESC' in grp.columns else 'Unknown',\n",
    "                'primary_borough': _def(grp['BORO_NM']) if 'BORO_NM' in grp.columns else 'Unknown',\n",
    "                'primary_premises': _def(grp['PREM_TYP_DESC']) if 'PREM_TYP_DESC' in grp.columns else 'Unknown',\n",
    "                'primary_time_bucket': _def(grp['TIME_BUCKET']) if 'TIME_BUCKET' in grp.columns else 'Unknown',\n",
    "                'crime_count': int(len(grp))\n",
    "            })\n",
    "        ops = pd.DataFrame(rows)\n",
    "    else:\n",
    "        ops = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    ops = pd.DataFrame()\n",
    "\n",
    "# Normalize to canonical column names if imported schema differs\n",
    "if not ops.empty:\n",
    "    def ensure_col(dst, target, candidates, transform=None, default_val=np.nan):\n",
    "        if target in dst.columns:\n",
    "            return\n",
    "        for c in candidates:\n",
    "            if c in dst.columns:\n",
    "                dst[target] = dst[c] if transform is None else transform(dst[c])\n",
    "                return\n",
    "        dst[target] = default_val\n",
    "\n",
    "    ensure_col(ops, 'cluster_id', ['cluster', 'cid'], transform=lambda s: s.astype('Int64'))\n",
    "    ensure_col(ops, 'primary_borough', ['BORO_NM', 'borough', 'top_boro_nm'])\n",
    "    ensure_col(ops, 'primary_crime', ['OFNS_DESC', 'crime_type', 'top_ofns_desc'])\n",
    "    ensure_col(ops, 'primary_premises', ['PREM_TYP_DESC', 'premises', 'top_prem_typ_desc'])\n",
    "    ensure_col(ops, 'primary_time_bucket', ['TIME_BUCKET', 'time_bucket', 'top_time_bucket'])\n",
    "\n",
    "ops['crime_count'] = ops.get('crime_count', pd.Series(dtype=int)).fillna(0).astype(int)\n",
    "if 'concentration_score' not in ops.columns:\n",
    "    # approximate concentration from within-cluster dominance if labeled data available\n",
    "    if 'df_kmodes_labeled' in locals() and not df_kmodes_labeled.empty and 'cluster' in df_kmodes_labeled.columns:\n",
    "        conc_vals = []\n",
    "        for _, r in ops.iterrows():\n",
    "            cid = r.get('cluster_id', None)\n",
    "            if pd.isna(cid): conc_vals.append(np.nan); continue\n",
    "            grp = df_kmodes_labeled[df_kmodes_labeled['cluster'] == cid]\n",
    "            if grp.empty or 'OFNS_DESC' not in grp.columns:\n",
    "                conc_vals.append(np.nan); continue\n",
    "            top_frac = grp['OFNS_DESC'].value_counts(normalize=True).max()\n",
    "            conc_vals.append(top_frac)\n",
    "        ops['concentration_score'] = conc_vals\n",
    "    else:\n",
    "        ops['concentration_score'] = np.nan\n",
    "\n",
    "# Priority tiers by crime_count with concentration as tiebreaker\n",
    "q80 = ops['crime_count'].quantile(0.8) if len(ops) else 0\n",
    "q60 = ops['crime_count'].quantile(0.6) if len(ops) else 0\n",
    "q40 = ops['crime_count'].quantile(0.4) if len(ops) else 0\n",
    "\n",
    "def pr_rank(row):\n",
    "    if row['crime_count'] >= q80: return 'HIGH'\n",
    "    if row['crime_count'] >= q60: return 'MEDIUM-HIGH'\n",
    "    if row['crime_count'] >= q40: return 'MEDIUM'\n",
    "    return 'LOW'\n",
    "\n",
    "if not ops.empty:\n",
    "    ops['priority'] = ops.apply(pr_rank, axis=1)\n",
    "else:\n",
    "    ops['priority'] = []\n",
    "\n",
    "# 2) Print concise tables\n",
    "if not ops.empty:\n",
    "    display_cols = ['cluster_id','priority','crime_count','primary_borough','primary_crime','primary_premises','primary_time_bucket']\n",
    "    missing = [c for c in display_cols if c not in ops.columns]\n",
    "    for c in missing:\n",
    "        ops[c] = 'Unknown'\n",
    "    top_clusters = ops.sort_values(['priority','crime_count','concentration_score'], ascending=[True, False, False])\n",
    "    top_clusters = top_clusters[display_cols].head(12)\n",
    "    print('Top clusters (by priority, volume, concentration):')\n",
    "    print(top_clusters.to_string(index=False))\n",
    "\n",
    "    # Map priority to labeled data for cross-tabs\n",
    "    if 'df_kmodes_labeled' in locals() and not df_kmodes_labeled.empty:\n",
    "        pr_map = dict(zip(ops['cluster_id'], ops['priority']))\n",
    "        base = df_kmodes_labeled.copy()\n",
    "        base['priority'] = base['cluster'].map(pr_map).fillna('LOW')\n",
    "\n",
    "        def ctab(col, top_k=None, title=None):\n",
    "            if col not in base.columns:\n",
    "                return None\n",
    "            s = base[col].astype(str)\n",
    "            if top_k:\n",
    "                top = s.value_counts().head(top_k).index\n",
    "                s = s.where(s.isin(top), 'OTHER')\n",
    "            t = pd.crosstab(s, base['priority'], normalize='index').round(2)\n",
    "            if title:\n",
    "                print('\\n'+title)\n",
    "            print(t)\n",
    "            return t\n",
    "\n",
    "        borough_priority = ctab('BORO_NM', title='Borough x Priority')\n",
    "        crime_priority = ctab('OFNS_DESC', top_k=12, title='Top Crime Types x Priority (top 12)')\n",
    "        premises_priority = ctab('PREM_TYP_DESC', top_k=12, title='Premises x Priority (top 12)')\n",
    "        time_priority = ctab('TIME_BUCKET', title='Time Bucket x Priority')\n",
    "        weekend_priority = ctab('IS_WEEKEND', title='Weekend x Priority')\n",
    "        holiday_priority = ctab('IS_HOLIDAY', title='Holiday x Priority')\n",
    "        suspsex_priority = ctab('SUSP_SEX', top_k=6, title='Suspect Sex x Priority')\n",
    "        suspage_priority = ctab('SUSP_AGE_GROUP', top_k=6, title='Suspect Age x Priority')\n",
    "        vicsex_priority = ctab('VIC_SEX', top_k=6, title='Victim Sex x Priority')\n",
    "        vicage_priority = ctab('VIC_AGE_GROUP', top_k=6, title='Victim Age x Priority')\n",
    "\n",
    "        # Hold for optional export later in Section 4\n",
    "        ops_export = ops.copy()\n",
    "        export_cols = display_cols + ['concentration_score']\n",
    "        ops_export = ops_export[export_cols]\n",
    "else:\n",
    "    print('No operational data available for concise tables.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e06f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\police_operational_intelligence_enriched.csv\n",
      "JSON saved: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\executive_crime_summary_enriched.json\n"
     ]
    }
   ],
   "source": [
    "# Optional: export concise ops and executive summary (enriched)\n",
    "try:\n",
    "    csv_path = os.path.join(output_dir, 'police_operational_intelligence_enriched.csv')\n",
    "    json_path = os.path.join(output_dir, 'executive_crime_summary_enriched.json')\n",
    "\n",
    "    if 'ops_export' in locals() and not ops_export.empty:\n",
    "        ops_export.to_csv(csv_path, index=False)\n",
    "        print(f'CSV saved: {csv_path}')\n",
    "\n",
    "    if 'executive_summary' in locals() and isinstance(executive_summary, dict):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(executive_summary, f, indent=2)\n",
    "        print(f'JSON saved: {json_path}')\n",
    "except Exception as e:\n",
    "    print('Export skipped/error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acaf8b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added POI/context bins: [np.str_('METRO_DISTANCE_BIN'), np.str_('POI_DENSITY_SCORE_BIN')]\n",
      "X_categorical shape: (5000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create binned context features (drop TOTAL_POI_COUNT_BIN entirely)\n",
    "created_bins = []\n",
    "if 'column_binner' in locals():\n",
    "    _df = df_kmodes.copy()\n",
    "    _df = column_binner.fit_transform(_df)\n",
    "    created_bins = [col for col in column_binner.get_feature_names_out() if col in _df.columns]\n",
    "    # Remove any accidental legacy bins\n",
    "    created_bins = [c for c in created_bins if c != 'TOTAL_POI_COUNT_BIN']\n",
    "    df_kmodes = _df\n",
    "\n",
    "# Print concise list of bins actually used\n",
    "print(\"Added POI/context bins:\", [c for c in created_bins])\n",
    "\n",
    "# Build final categorical feature list for kmodes (no TOTAL_POI_COUNT_BIN)\n",
    "CATEGORICAL_FEATURES_KMODES = [\n",
    "    *[c for c in BASE_KMODES_FEATURES if c in df_kmodes.columns],\n",
    "    *[c for c in EXTRA_CATEGORICAL_FEATURES if c in df_kmodes.columns],\n",
    "    *[c for c in DEMOGRAPHIC_CATEGORICAL if c in df_kmodes.columns],\n",
    "    *[c for c in created_bins if c in df_kmodes.columns]\n",
    "]\n",
    "\n",
    "# Ensure TOTAL_POI_COUNT_BIN is not present\n",
    "CATEGORICAL_FEATURES_KMODES = [c for c in CATEGORICAL_FEATURES_KMODES if c != 'TOTAL_POI_COUNT_BIN']\n",
    "\n",
    "# Prepare X for K-Modes\n",
    "X_categorical = df_kmodes[CATEGORICAL_FEATURES_KMODES].astype(str).fillna('Unknown')\n",
    "X_categorical_processed = X_categorical\n",
    "X_categorical_array = X_categorical_processed.values\n",
    "print(f\"X_categorical shape: {X_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ede7a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binner config: drop TOTAL_POI_COUNT completely\n",
    "binner_config = {\n",
    "    'METRO_DISTANCE': {\n",
    "        'kind': 'distance',\n",
    "        'bins': [0, 250, 1000, np.inf],\n",
    "        'labels': ['Near', 'Mid', 'Far']\n",
    "    },\n",
    "    'POI_DENSITY_SCORE': {\n",
    "        'kind': 'score', 'quantiles': 4,\n",
    "        'labels': ['Low','Medium','High','VeryHigh']\n",
    "    }\n",
    "}\n",
    "\n",
    "column_binner = ColumnBinner(config=binner_config, suffix=\"_BIN\", fill_unknown=\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbc90f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📊 EXECUTIVE CRIME INTELLIGENCE DASHBOARD\n",
      "============================================================\n",
      "\n",
      "📈 EXECUTIVE SUMMARY\n",
      "   🔢 Total Crimes Analyzed: 5,000\n",
      "   🎯 Crime Patterns Identified: 10\n",
      "   🚨 High Priority Patterns: 2\n",
      "   📊 High Priority Crime Volume: 1,368 (27.4%)\n",
      "\n",
      "🔍 KEY INSIGHTS\n",
      "   🎯 Most Concentrated Pattern: PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "      └── 57% concentration, 739 crimes\n",
      "   📈 Highest Volume Pattern: PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "      └── 739 crimes (14.8% of total)\n",
      "\n",
      "🗺️ BOROUGH CRIME INTELLIGENCE\n",
      "   📍 MANHATTAN:\n",
      "      └── Total: 1,204 | High Priority: 478 (39.7%)\n",
      "   📍 BROOKLYN:\n",
      "      └── Total: 1,383 | High Priority: 459 (33.2%)\n",
      "   📍 QUEENS:\n",
      "      └── Total: 1,109 | High Priority: 219 (19.7%)\n",
      "   📍 BRONX:\n",
      "      └── Total: 1,091 | High Priority: 163 (14.9%)\n",
      "   📍 STATEN ISLAND:\n",
      "      └── Total: 213 | High Priority: 49 (23.0%)\n",
      "\n",
      "⚡ IMMEDIATE ACTION ITEMS\n",
      "   🚨 DEPLOY IMMEDIATELY:\n",
      "      1. ASSAULT 3 & RELATED OFFENSES • BROOKLYN • STREET • EVENING • Weekday • SUSP: M 25-44 | VIC: M 25-44\n",
      "         └── 629 crimes, 34% concentration\n",
      "      2. PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "         └── 739 crimes, 57% concentration\n",
      "   📋 PLAN ENHANCED OPERATIONS:\n",
      "\n",
      "📈 EXECUTIVE SUMMARY\n",
      "   🔢 Total Crimes Analyzed: 5,000\n",
      "   🎯 Crime Patterns Identified: 10\n",
      "   🚨 High Priority Patterns: 2\n",
      "   📊 High Priority Crime Volume: 1,368 (27.4%)\n",
      "\n",
      "🔍 KEY INSIGHTS\n",
      "   🎯 Most Concentrated Pattern: PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "      └── 57% concentration, 739 crimes\n",
      "   📈 Highest Volume Pattern: PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "      └── 739 crimes (14.8% of total)\n",
      "\n",
      "🗺️ BOROUGH CRIME INTELLIGENCE\n",
      "   📍 MANHATTAN:\n",
      "      └── Total: 1,204 | High Priority: 478 (39.7%)\n",
      "   📍 BROOKLYN:\n",
      "      └── Total: 1,383 | High Priority: 459 (33.2%)\n",
      "   📍 QUEENS:\n",
      "      └── Total: 1,109 | High Priority: 219 (19.7%)\n",
      "   📍 BRONX:\n",
      "      └── Total: 1,091 | High Priority: 163 (14.9%)\n",
      "   📍 STATEN ISLAND:\n",
      "      └── Total: 213 | High Priority: 49 (23.0%)\n",
      "\n",
      "⚡ IMMEDIATE ACTION ITEMS\n",
      "   🚨 DEPLOY IMMEDIATELY:\n",
      "      1. ASSAULT 3 & RELATED OFFENSES • BROOKLYN • STREET • EVENING • Weekday • SUSP: M 25-44 | VIC: M 25-44\n",
      "         └── 629 crimes, 34% concentration\n",
      "      2. PETIT LARCENY • MANHATTAN • CHAIN STORE • AFTERNOON • Weekday • SUSP: M UNKNOWN | VIC: D UNKNOWN\n",
      "         └── 739 crimes, 57% concentration\n",
      "   📋 PLAN ENHANCED OPERATIONS:\n",
      "      1. GRAND LARCENY • MANHATTAN • STREET • EVENING • Weekday • SUSP: U UNKNOWN | VIC: F 25-44\n",
      "         └── 571 crimes\n",
      "      2. PETIT LARCENY • BRONX • STREET • EVENING • Weekday • SUSP: U UNKNOWN | VIC: M 25-44\n",
      "         └── 572 crimes\n",
      "\n",
      "💰 RESOURCE ALLOCATION RECOMMENDATION\n",
      "   🎯 Focus 80% of resources on 4 patterns\n",
      "   📊 Targeting 2,511 crimes (50.2% of total volume)\n",
      "   💡 Expected Result: Maximum impact with focused deployment\n",
      "\n",
      "✅ Executive summary saved to: executive_crime_summary.json\n",
      "📁 All police intelligence reports saved to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n",
      "      1. GRAND LARCENY • MANHATTAN • STREET • EVENING • Weekday • SUSP: U UNKNOWN | VIC: F 25-44\n",
      "         └── 571 crimes\n",
      "      2. PETIT LARCENY • BRONX • STREET • EVENING • Weekday • SUSP: U UNKNOWN | VIC: M 25-44\n",
      "         └── 572 crimes\n",
      "\n",
      "💰 RESOURCE ALLOCATION RECOMMENDATION\n",
      "   🎯 Focus 80% of resources on 4 patterns\n",
      "   📊 Targeting 2,511 crimes (50.2% of total volume)\n",
      "   💡 Expected Result: Maximum impact with focused deployment\n",
      "\n",
      "✅ Executive summary saved to: executive_crime_summary.json\n",
      "📁 All police intelligence reports saved to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n"
     ]
    }
   ],
   "source": [
    "# === POLICE EXECUTIVE DASHBOARD ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 EXECUTIVE CRIME INTELLIGENCE DASHBOARD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def _safe_mode(s, default=\"Unknown\"):\n",
    "    try:\n",
    "        m = s.mode(dropna=True)\n",
    "        return m.iloc[0] if not m.empty else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "# Build a compact signature using cluster-level top attributes\n",
    "# Falls back to row fields when detailed data isn't available\n",
    "\n",
    "def signature_for_cluster(cluster_id=None, row=None, base_df=None):\n",
    "    # Initialize fields from row fallbacks\n",
    "    crime = (row.get('primary_crime') if isinstance(row, dict) else getattr(row, 'primary_crime', None)) or \"Unknown\"\n",
    "    borough = (row.get('primary_borough') if isinstance(row, dict) else getattr(row, 'primary_borough', None)) or \"Unknown\"\n",
    "    premises = (row.get('primary_premises') if isinstance(row, dict) else getattr(row, 'primary_premises', None)) or None\n",
    "    time_bucket = (row.get('primary_time_bucket') if isinstance(row, dict) else getattr(row, 'primary_time_bucket', None)) or None\n",
    "\n",
    "    weekend_tok = None\n",
    "    holiday_tok = None\n",
    "    susp_sex = None\n",
    "    susp_age = None\n",
    "    vic_sex = None\n",
    "    vic_age = None\n",
    "\n",
    "    if base_df is not None and cluster_id is not None and 'cluster' in base_df.columns:\n",
    "        g = base_df[base_df['cluster'] == cluster_id]\n",
    "        if not g.empty:\n",
    "            # Prefer actual cluster modes when available\n",
    "            if 'OFNS_DESC' in g.columns:\n",
    "                crime = _safe_mode(g['OFNS_DESC'], crime)\n",
    "            if 'BORO_NM' in g.columns:\n",
    "                borough = _safe_mode(g['BORO_NM'], borough)\n",
    "            if 'PREM_TYP_DESC' in g.columns:\n",
    "                premises = _safe_mode(g['PREM_TYP_DESC'], premises)\n",
    "            if 'TIME_BUCKET' in g.columns:\n",
    "                time_bucket = _safe_mode(g['TIME_BUCKET'], time_bucket)\n",
    "            if 'IS_WEEKEND' in g.columns:\n",
    "                w = _safe_mode(g['IS_WEEKEND'], None)\n",
    "                if pd.isna(w):\n",
    "                    weekend_tok = None\n",
    "                else:\n",
    "                    weekend_tok = 'Weekend' if str(w).lower() in ['1', 'true', 'yes'] else 'Weekday'\n",
    "            if 'IS_HOLIDAY' in g.columns:\n",
    "                h = _safe_mode(g['IS_HOLIDAY'], None)\n",
    "                if pd.isna(h):\n",
    "                    holiday_tok = None\n",
    "                else:\n",
    "                    holiday_tok = 'Holiday' if str(h).lower() in ['1', 'true', 'yes'] else None\n",
    "            if 'SUSP_SEX' in g.columns:\n",
    "                susp_sex = _safe_mode(g['SUSP_SEX'], None)\n",
    "            if 'SUSP_AGE_GROUP' in g.columns:\n",
    "                susp_age = _safe_mode(g['SUSP_AGE_GROUP'], None)\n",
    "            if 'VIC_SEX' in g.columns:\n",
    "                vic_sex = _safe_mode(g['VIC_SEX'], None)\n",
    "            if 'VIC_AGE_GROUP' in g.columns:\n",
    "                vic_age = _safe_mode(g['VIC_AGE_GROUP'], None)\n",
    "\n",
    "    tokens = [str(crime), str(borough)]\n",
    "    if premises and str(premises) != 'Unknown':\n",
    "        tokens.append(str(premises))\n",
    "    if time_bucket and str(time_bucket) != 'Unknown':\n",
    "        tokens.append(str(time_bucket))\n",
    "    if weekend_tok:\n",
    "        tokens.append(weekend_tok)\n",
    "    if holiday_tok:\n",
    "        tokens.append(holiday_tok)\n",
    "\n",
    "    demo_parts = []\n",
    "    if susp_sex or susp_age:\n",
    "        demo_parts.append(f\"SUSP: {susp_sex or '?'} {susp_age or ''}\".strip())\n",
    "    if vic_sex or vic_age:\n",
    "        demo_parts.append(f\"VIC: {vic_sex or '?'} {vic_age or ''}\".strip())\n",
    "    if demo_parts:\n",
    "        tokens.append(\" | \".join(demo_parts))\n",
    "\n",
    "    return \" • \".join([t for t in tokens if t and str(t).strip()])\n",
    "\n",
    "# Prefer df_operational; fallback to previously built 'ops'; then to saved enriched CSV\n",
    "ops_df = None\n",
    "if 'df_operational' in locals() and isinstance(df_operational, pd.DataFrame) and not df_operational.empty:\n",
    "    ops_df = df_operational.copy()\n",
    "elif 'ops' in locals() and isinstance(ops, pd.DataFrame) and not ops.empty:\n",
    "    ops_df = ops.copy()\n",
    "else:\n",
    "    try:\n",
    "        export_dir = os.path.join(project_root, 'JupyterOutputs', 'Final')\n",
    "        csv_path = os.path.join(export_dir, 'police_operational_intelligence_enriched.csv')\n",
    "        if os.path.exists(csv_path):\n",
    "            ops_df = pd.read_csv(csv_path)\n",
    "    except Exception as _e:\n",
    "        ops_df = None\n",
    "\n",
    "if ops_df is not None and not ops_df.empty:\n",
    "    # Ensure expected columns exist\n",
    "    for col in ['cluster_id','primary_crime','primary_borough','primary_premises','primary_time_bucket','crime_count']:\n",
    "        if col not in ops_df.columns:\n",
    "            ops_df[col] = np.nan\n",
    "\n",
    "    # Executive summary statistics\n",
    "    total_crimes = int(ops_df.get('crime_count', pd.Series(dtype=int)).sum()) if 'crime_count' in ops_df.columns else int(len(ops_df))\n",
    "    high_priority_patterns = int((ops_df.get('priority', pd.Series([])) == 'HIGH').sum()) if 'priority' in ops_df.columns else 0\n",
    "    high_priority_crimes = int(ops_df[ops_df.get('priority','') == 'HIGH']['crime_count'].sum()) if 'crime_count' in ops_df.columns and 'priority' in ops_df.columns else 0\n",
    "\n",
    "    # Identify key patterns\n",
    "    if 'concentration_score' in ops_df.columns and pd.api.types.is_numeric_dtype(ops_df['concentration_score']):\n",
    "        most_concentrated = ops_df.loc[ops_df['concentration_score'].astype(float).idxmax()]\n",
    "    else:\n",
    "        # Fallback: use highest volume as proxy\n",
    "        most_concentrated = ops_df.loc[ops_df['crime_count'].idxmax()]\n",
    "    highest_volume = ops_df.loc[ops_df['crime_count'].idxmax()] if 'crime_count' in ops_df.columns else ops_df.iloc[0]\n",
    "\n",
    "    # Base dataframe for cluster-level modes\n",
    "    base_df = df_kmodes_labeled.copy() if 'df_kmodes_labeled' in locals() and isinstance(df_kmodes_labeled, pd.DataFrame) and not df_kmodes_labeled.empty else None\n",
    "\n",
    "    # Compact signatures\n",
    "    mc_sig = signature_for_cluster(cluster_id=int(most_concentrated.get('cluster_id')) if 'cluster_id' in most_concentrated else None,\n",
    "                                   row=most_concentrated.to_dict() if hasattr(most_concentrated, 'to_dict') else most_concentrated,\n",
    "                                   base_df=base_df)\n",
    "    hv_sig = signature_for_cluster(cluster_id=int(highest_volume.get('cluster_id')) if 'cluster_id' in highest_volume else None,\n",
    "                                   row=highest_volume.to_dict() if hasattr(highest_volume, 'to_dict') else highest_volume,\n",
    "                                   base_df=base_df)\n",
    "\n",
    "    print(f\"\\n📈 EXECUTIVE SUMMARY\")\n",
    "    print(f\"   🔢 Total Crimes Analyzed: {total_crimes:,}\")\n",
    "    print(f\"   🎯 Crime Patterns Identified: {len(ops_df)}\")\n",
    "    print(f\"   🚨 High Priority Patterns: {high_priority_patterns}\")\n",
    "    if total_crimes > 0 and high_priority_crimes:\n",
    "        print(f\"   📊 High Priority Crime Volume: {high_priority_crimes:,} ({(high_priority_crimes/total_crimes)*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\n🔍 KEY INSIGHTS\")\n",
    "    if 'concentration_score' in ops_df.columns:\n",
    "        conc_pct = most_concentrated.get('concentration_score')\n",
    "        conc_str = f\"{float(conc_pct):.0%}\" if pd.notna(conc_pct) else \"N/A\"\n",
    "        print(f\"   🎯 Most Concentrated Pattern: {mc_sig}\")\n",
    "        print(f\"      └── {conc_str} concentration, {int(most_concentrated.get('crime_count', 0)):,} crimes\")\n",
    "    else:\n",
    "        print(f\"   🎯 Key Pattern: {mc_sig}\")\n",
    "        print(f\"      └── {int(most_concentrated.get('crime_count', 0)):,} crimes\")\n",
    "    hv_pct = (highest_volume.get('crime_count', 0) / total_crimes * 100) if total_crimes else 0\n",
    "    print(f\"   📈 Highest Volume Pattern: {hv_sig}\")\n",
    "    print(f\"      └── {int(highest_volume.get('crime_count', 0)):,} crimes ({hv_pct:.1f}% of total)\")\n",
    "\n",
    "    # Borough-level intelligence\n",
    "    if base_df is not None and 'BORO_NM' in base_df.columns:\n",
    "        print(f\"\\n🗺️ BOROUGH CRIME INTELLIGENCE\")\n",
    "        # Map priority to labeled data\n",
    "        pr_map = dict(zip(ops_df['cluster_id'], ops_df.get('priority', '')))\n",
    "        cluster_data_all = base_df.copy()\n",
    "        cluster_data_all['priority'] = cluster_data_all['cluster'].map(pr_map)\n",
    "\n",
    "        borough_intelligence = cluster_data_all.groupby('BORO_NM').agg({\n",
    "            'cluster': 'count',\n",
    "            'priority': lambda x: (x == 'HIGH').sum()\n",
    "        }).rename(columns={'cluster': 'total_crimes', 'priority': 'high_priority_crimes'})\n",
    "        borough_intelligence['high_priority_pct'] = (borough_intelligence['high_priority_crimes'] /\n",
    "                                                     borough_intelligence['total_crimes'] * 100).round(1)\n",
    "        borough_intelligence = borough_intelligence.sort_values('high_priority_crimes', ascending=False)\n",
    "        for borough, stats in borough_intelligence.iterrows():\n",
    "            print(f\"   📍 {borough}:\")\n",
    "            print(f\"      └── Total: {int(stats['total_crimes']):,} | High Priority: {int(stats['high_priority_crimes']):,} ({stats['high_priority_pct']:.1f}%)\")\n",
    "\n",
    "    # Operational recommendations summary\n",
    "    print(f\"\\n⚡ IMMEDIATE ACTION ITEMS\")\n",
    "    high_priority_df = ops_df[ops_df.get('priority','') == 'HIGH'].head(3) if 'priority' in ops_df.columns else pd.DataFrame()\n",
    "    if not high_priority_df.empty:\n",
    "        print(\"   🚨 DEPLOY IMMEDIATELY:\")\n",
    "        for i, (_, pattern) in enumerate(high_priority_df.iterrows(), 1):\n",
    "            sig = signature_for_cluster(cluster_id=int(pattern.get('cluster_id')) if 'cluster_id' in pattern else None,\n",
    "                                        row=pattern.to_dict(), base_df=base_df)\n",
    "            print(f\"      {i}. {sig}\")\n",
    "            extra = []\n",
    "            if 'crime_count' in pattern:\n",
    "                extra.append(f\"{int(pattern['crime_count']):,} crimes\")\n",
    "            if 'concentration_score' in pattern and pd.notna(pattern['concentration_score']):\n",
    "                extra.append(f\"{float(pattern['concentration_score']):.0%} concentration\")\n",
    "            if extra:\n",
    "                print(f\"         └── {', '.join(extra)}\")\n",
    "\n",
    "    medium_priority_df = ops_df[ops_df.get('priority','').isin(['MEDIUM-HIGH', 'MEDIUM'])].head(2) if 'priority' in ops_df.columns else pd.DataFrame()\n",
    "    if not medium_priority_df.empty:\n",
    "        print(\"   📋 PLAN ENHANCED OPERATIONS:\")\n",
    "        for i, (_, pattern) in enumerate(medium_priority_df.iterrows(), 1):\n",
    "            sig = signature_for_cluster(cluster_id=int(pattern.get('cluster_id')) if 'cluster_id' in pattern else None,\n",
    "                                        row=pattern.to_dict(), base_df=base_df)\n",
    "            print(f\"      {i}. {sig}\")\n",
    "            if 'crime_count' in pattern:\n",
    "                print(f\"         └── {int(pattern['crime_count']):,} crimes\")\n",
    "\n",
    "    # Resource allocation recommendation\n",
    "    print(f\"\\n💰 RESOURCE ALLOCATION RECOMMENDATION\")\n",
    "    focus_mask = ops_df.get('priority','').isin(['HIGH', 'MEDIUM-HIGH']) if 'priority' in ops_df.columns else pd.Series([False]*len(ops_df))\n",
    "    total_budget_crimes = int(ops_df.loc[focus_mask, 'crime_count'].sum()) if 'crime_count' in ops_df.columns else 0\n",
    "    print(f\"   🎯 Focus 80% of resources on {int(focus_mask.sum())} patterns\")\n",
    "    if total_crimes:\n",
    "        print(f\"   📊 Targeting {total_budget_crimes:,} crimes ({(total_budget_crimes/total_crimes)*100:.1f}% of total volume)\")\n",
    "    print(f\"   💡 Expected Result: Maximum impact with focused deployment\")\n",
    "\n",
    "    # Structured details for the two key patterns (where available)\n",
    "    def structured_details(row_obj):\n",
    "        cid = int(row_obj.get('cluster_id')) if 'cluster_id' in row_obj else None\n",
    "        # derive modes from base_df if possible\n",
    "        details = {}\n",
    "        if base_df is not None and cid is not None:\n",
    "            g = base_df[base_df['cluster'] == cid]\n",
    "            if not g.empty:\n",
    "                details.update({\n",
    "                    'crime_type': _safe_mode(g['OFNS_DESC']) if 'OFNS_DESC' in g.columns else row_obj.get('primary_crime', 'Unknown'),\n",
    "                    'borough': _safe_mode(g['BORO_NM']) if 'BORO_NM' in g.columns else row_obj.get('primary_borough', 'Unknown'),\n",
    "                    'premises': _safe_mode(g['PREM_TYP_DESC']) if 'PREM_TYP_DESC' in g.columns else row_obj.get('primary_premises', 'Unknown'),\n",
    "                    'time_bucket': _safe_mode(g['TIME_BUCKET']) if 'TIME_BUCKET' in g.columns else row_obj.get('primary_time_bucket', 'Unknown'),\n",
    "                    'is_weekend_mode': bool(str(_safe_mode(g['IS_WEEKEND'], 'False')).lower() in ['1','true','yes']) if 'IS_WEEKEND' in g.columns else None,\n",
    "                    'is_holiday_mode': bool(str(_safe_mode(g['IS_HOLIDAY'], 'False')).lower() in ['1','true','yes']) if 'IS_HOLIDAY' in g.columns else None,\n",
    "                    'suspect_sex_mode': _safe_mode(g['SUSP_SEX']) if 'SUSP_SEX' in g.columns else None,\n",
    "                    'suspect_age_mode': _safe_mode(g['SUSP_AGE_GROUP']) if 'SUSP_AGE_GROUP' in g.columns else None,\n",
    "                    'victim_sex_mode': _safe_mode(g['VIC_SEX']) if 'VIC_SEX' in g.columns else None,\n",
    "                    'victim_age_mode': _safe_mode(g['VIC_AGE_GROUP']) if 'VIC_AGE_GROUP' in g.columns else None,\n",
    "                })\n",
    "        else:\n",
    "            details.update({\n",
    "                'crime_type': row_obj.get('primary_crime', 'Unknown'),\n",
    "                'borough': row_obj.get('primary_borough', 'Unknown'),\n",
    "                'premises': row_obj.get('primary_premises', 'Unknown'),\n",
    "                'time_bucket': row_obj.get('primary_time_bucket', 'Unknown'),\n",
    "            })\n",
    "        # Always add volume metrics\n",
    "        details['volume'] = int(row_obj.get('crime_count', 0))\n",
    "        if 'concentration_score' in row_obj and pd.notna(row_obj['concentration_score']):\n",
    "            details['concentration'] = f\"{float(row_obj['concentration_score']):.0%}\"\n",
    "        return details\n",
    "\n",
    "    most_concentrated = most_concentrated if isinstance(most_concentrated, dict) else most_concentrated.to_dict()\n",
    "    highest_volume = highest_volume if isinstance(highest_volume, dict) else highest_volume.to_dict()\n",
    "    mc_details = structured_details(most_concentrated)\n",
    "    hv_details = structured_details(highest_volume)\n",
    "\n",
    "    # Create executive summary for export\n",
    "    executive_summary = {\n",
    "        'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        'total_crimes_analyzed': int(total_crimes),\n",
    "        'patterns_identified': int(len(ops_df)),\n",
    "        'high_priority_patterns': int(high_priority_patterns),\n",
    "        'high_priority_crime_percentage': round((high_priority_crimes/total_crimes)*100, 1) if total_crimes else 0.0,\n",
    "        'most_concentrated_pattern_signature': mc_sig,\n",
    "        'highest_volume_pattern_signature': hv_sig,\n",
    "        'most_concentrated_pattern': mc_details,\n",
    "        'highest_volume_pattern': hv_details,\n",
    "        'immediate_deployment_needed': high_priority_patterns > 0,\n",
    "        'resource_focus_patterns': int(focus_mask.sum()) if isinstance(focus_mask, pd.Series) else 0\n",
    "    }\n",
    "\n",
    "    # Save executive summary\n",
    "    with open(os.path.join(output_dir, 'executive_crime_summary.json'), 'w') as f:\n",
    "        json.dump(executive_summary, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"\\n✅ Executive summary saved to: executive_crime_summary.json\")\n",
    "    print(f\"📁 All police intelligence reports saved to: {output_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No operational data available for executive dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📋 POLICE-READY DELIVERABLES GENERATED\n",
      "============================================================\n",
      "\n",
      "🎯 The following actionable intelligence reports have been generated:\n",
      "\n",
      "1. 📊 OPERATIONAL INTELLIGENCE REPORT\n",
      "   📁 File: police_operational_intelligence.csv\n",
      "   📝 Content: Crime patterns with priority levels, concentration scores, and volume analysis\n",
      "   👮 Use: Daily briefings, resource allocation planning, patrol deployment decisions\n",
      "\n",
      "2. 🎯 TACTICAL RECOMMENDATIONS\n",
      "   📁 File: tactical_recommendations.json\n",
      "   📝 Content: Specific tactical advice for each crime pattern (deployment strategies, focus areas)\n",
      "   👮 Use: Field operations planning, specialized unit deployment, tactical decision making\n",
      "\n",
      "3. 📈 EXECUTIVE SUMMARY\n",
      "   📁 File: executive_crime_summary.json\n",
      "   📝 Content: High-level intelligence summary for command staff\n",
      "   👮 Use: Budget planning, strategic decisions, performance metrics, public reporting\n",
      "\n",
      "4. 🗂️ DETAILED CLUSTER DATA\n",
      "   📁 File: kmodes_clustered_data.csv\n",
      "   📝 Content: Full crime dataset with cluster assignments for detailed analysis\n",
      "   👮 Use: Detective investigations, pattern analysis, evidence correlation\n",
      "\n",
      "📍 All files saved to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\n",
      "\n",
      "📁 FILE STATUS:\n",
      "   ❌ police_operational_intelligence.csv (not found)\n",
      "   ❌ tactical_recommendations.json (not found)\n",
      "   ✅ executive_crime_summary.json (1.4 KB)\n",
      "   ❌ kmodes_clustered_data.csv (not found)\n",
      "\n",
      "🚀 NEXT STEPS FOR POLICE IMPLEMENTATION:\n",
      "   1. 📋 Review operational intelligence report for immediate deployment decisions\n",
      "   2. 🎯 Implement tactical recommendations for high-priority patterns\n",
      "   3. 📊 Use executive summary for resource allocation and strategic planning\n",
      "   4. 🔄 Establish regular analysis schedule (weekly/monthly) for updated intelligence\n",
      "   5. 📈 Track effectiveness of deployments and adjust strategies based on results\n"
     ]
    }
   ],
   "source": [
    "# === POLICE-READY DELIVERABLES SUMMARY ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 POLICE-READY DELIVERABLES GENERATED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n🎯 The following actionable intelligence reports have been generated:\")\n",
    "print(\"\\n1. 📊 OPERATIONAL INTELLIGENCE REPORT\")\n",
    "print(\"   📁 File: police_operational_intelligence.csv\") \n",
    "print(\"   📝 Content: Crime patterns with priority levels, concentration scores, and volume analysis\")\n",
    "print(\"   👮 Use: Daily briefings, resource allocation planning, patrol deployment decisions\")\n",
    "\n",
    "print(\"\\n2. 🎯 TACTICAL RECOMMENDATIONS\")\n",
    "print(\"   📁 File: tactical_recommendations.json\")\n",
    "print(\"   📝 Content: Specific tactical advice for each crime pattern (deployment strategies, focus areas)\")\n",
    "print(\"   👮 Use: Field operations planning, specialized unit deployment, tactical decision making\")\n",
    "\n",
    "print(\"\\n3. 📈 EXECUTIVE SUMMARY\")\n",
    "print(\"   📁 File: executive_crime_summary.json\")\n",
    "print(\"   📝 Content: High-level intelligence summary for command staff\")\n",
    "print(\"   👮 Use: Budget planning, strategic decisions, performance metrics, public reporting\")\n",
    "\n",
    "print(\"\\n4. 🗂️ DETAILED CLUSTER DATA\")\n",
    "print(\"   📁 File: kmodes_clustered_data.csv\")\n",
    "print(\"   📝 Content: Full crime dataset with cluster assignments for detailed analysis\")\n",
    "print(\"   👮 Use: Detective investigations, pattern analysis, evidence correlation\")\n",
    "\n",
    "print(f\"\\n📍 All files saved to: {output_dir}\")\n",
    "\n",
    "# Quick verification of file sizes\n",
    "files_info = []\n",
    "expected_files = [\n",
    "    'police_operational_intelligence.csv',\n",
    "    'tactical_recommendations.json', \n",
    "    'executive_crime_summary.json',\n",
    "    'kmodes_clustered_data.csv'\n",
    "]\n",
    "\n",
    "for filename in expected_files:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size_kb = os.path.getsize(filepath) / 1024\n",
    "        files_info.append(f\"   ✅ {filename} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        files_info.append(f\"   ❌ {filename} (not found)\")\n",
    "\n",
    "print(f\"\\n📁 FILE STATUS:\")\n",
    "for info in files_info:\n",
    "    print(info)\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS FOR POLICE IMPLEMENTATION:\")\n",
    "print(\"   1. 📋 Review operational intelligence report for immediate deployment decisions\")\n",
    "print(\"   2. 🎯 Implement tactical recommendations for high-priority patterns\")\n",
    "print(\"   3. 📊 Use executive summary for resource allocation and strategic planning\")\n",
    "print(\"   4. 🔄 Establish regular analysis schedule (weekly/monthly) for updated intelligence\")\n",
    "print(\"   5. 📈 Track effectiveness of deployments and adjust strategies based on results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211c9d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Advanced Clustering Methods\n",
    "\n",
    "This section explores advanced clustering techniques for discovering complex crime patterns that might be missed by traditional methods. These approaches complement the operational analysis above and provide research-grade insights for academic and advanced analytical purposes.\n",
    "\n",
    "\n",
    "## Categorical Dimensionality Reduction + Clustering\n",
    "\n",
    "Categorical dimensionality reduction transforms high-cardinality categorical data into a lower-dimensional continuous space, enabling the application of distance-based clustering algorithms while preserving the essential categorical relationships. \n",
    "\n",
    "The **Categorical Dimensionality Reduction Pipeline** follows our established architecture and uses a robust **OneHot + PCA approach** instead of traditional MCA:\n",
    "\n",
    "`CategoricalPreprocessor → CategoricalDimensionalityReducer → KMeans`\n",
    "\n",
    "**Why OneHot + PCA instead of MCA?**\n",
    "- **Numerical Stability**: No NaN values produced during transformation\n",
    "- **Robust Implementation**: Well-tested sklearn components\n",
    "- **Consistent Results**: Reproducible across different data distributions\n",
    "- **Better Performance**: More efficient and scalable for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL DIMENSIONALITY REDUCTION + KMEANS ===\n",
      "✓ Pipeline constructed\n",
      "Grid ready: {'dimred__n_components': [3, 5, 8], 'cluster__n_clusters': [3, 4, 5, 6, 7, 8], 'cluster__n_init': [5, 10]}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CATEGORICAL DIMENSIONALITY REDUCTION + KMEANS ===\")\n",
    "\n",
    "# Ensure Utilities path is available\n",
    "if 'utilities_path' in globals():\n",
    "    if utilities_path not in sys.path and os.path.isdir(utilities_path):\n",
    "        sys.path.append(utilities_path)\n",
    "else:\n",
    "    # Fallbacks\n",
    "    for candidate in [\n",
    "        os.path.join(os.getcwd(), \"Notebooks\", \"Clustering\", \"Utilities\"),\n",
    "        os.path.join(os.path.dirname(os.getcwd()), \"Notebooks\", \"Clustering\", \"Utilities\")\n",
    "    ]:\n",
    "        if os.path.isdir(candidate) and candidate not in sys.path:\n",
    "            sys.path.append(candidate)\n",
    "\n",
    "# Pipeline: OneHot+PCA-like reducer + KMeans\n",
    "categorical_dimred_pipeline = Pipeline([\n",
    "    ('dimred', CategoricalDimensionalityReducer(n_components=5, random_state=RANDOM_STATE)),\n",
    "    ('cluster', KMeans(n_clusters=5, n_init=10, random_state=RANDOM_STATE))\n",
    "])\n",
    "print(\"✓ Pipeline constructed\")\n",
    "\n",
    "# Parameter grid\n",
    "cat_dimred_param_grid = {\n",
    "    'dimred__n_components': [3, 5, 8],\n",
    "    'cluster__n_clusters': [3, 4, 5, 6, 7, 8],\n",
    "    'cluster__n_init': [5, 10]\n",
    "}\n",
    "print(\"Grid ready:\", cat_dimred_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fd09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL DIMENSIONALITY REDUCTION + KMEANS EVALUATION ===\n",
      "Grid combinations: 36 | Data shape: (5000, 12)\n",
      "Grid combinations: 36 | Data shape: (5000, 12)\n",
      "  [1] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3561\n",
      "  [1] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3561\n",
      "  [2] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2501\n",
      "  [2] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2501\n",
      "  [3] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1791\n",
      "  [3] params={'cluster__n_clusters': 3, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1791\n",
      "  [4] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3561\n",
      "  [4] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3561\n",
      "  [5] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2502\n",
      "  [5] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2502\n",
      "  [6] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1791\n",
      "  [6] params={'cluster__n_clusters': 3, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1791\n",
      "  [7] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3341\n",
      "  [7] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3341\n",
      "  [8] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2425\n",
      "  [8] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2425\n",
      "  [9] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1654\n",
      "  [9] params={'cluster__n_clusters': 4, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1654\n",
      "  [10] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3341\n",
      "  [10] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3341\n",
      "  [11] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2425\n",
      "  [11] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2425\n",
      "  [12] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1654\n",
      "  [12] params={'cluster__n_clusters': 4, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1654\n",
      "  [13] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3173\n",
      "  [13] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3173\n",
      "  [14] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2544\n",
      "  [14] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2544\n",
      "  [15] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1712\n",
      "  [15] params={'cluster__n_clusters': 5, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1712\n",
      "  [16] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3139\n",
      "  [16] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3139\n",
      "  [17] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2522\n",
      "  [17] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2522\n",
      "  [18] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1712\n",
      "  [18] params={'cluster__n_clusters': 5, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1712\n",
      "  [19] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3045\n",
      "  [19] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3045\n",
      "  [20] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2498\n",
      "  [20] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2498\n",
      "  [21] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1772\n",
      "  [21] params={'cluster__n_clusters': 6, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1772\n",
      "  [22] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3045\n",
      "  [22] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3045\n",
      "  [23] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2500\n",
      "  [23] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2500\n",
      "  [24] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1772\n",
      "  [24] params={'cluster__n_clusters': 6, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1772\n",
      "  [25] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3040\n",
      "  [25] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.3040\n",
      "  [26] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2393\n",
      "  [26] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2393\n",
      "  [27] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1749\n",
      "  [27] params={'cluster__n_clusters': 7, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1749\n",
      "  [28] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3037\n",
      "  [28] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.3037\n",
      "  [29] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2393\n",
      "  [29] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2393\n",
      "  [30] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1749\n",
      "  [30] params={'cluster__n_clusters': 7, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1749\n",
      "  [31] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.2979\n",
      "  [31] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 3} -> silhouette=0.2979\n",
      "  [32] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2623\n",
      "  [32] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 5} -> silhouette=0.2623\n",
      "  [33] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1715\n",
      "  [33] params={'cluster__n_clusters': 8, 'cluster__n_init': 5, 'dimred__n_components': 8} -> silhouette=0.1715\n",
      "  [34] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.2914\n",
      "  [34] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 3} -> silhouette=0.2914\n",
      "  [35] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2715\n",
      "  [35] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 5} -> silhouette=0.2715\n",
      "  [36] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1764\n",
      "\n",
      "Top results (silhouette):\n",
      "                                               params  silhouette\n",
      "0   {'cluster__n_clusters': 3, 'cluster__n_init': ...    0.356143\n",
      "3   {'cluster__n_clusters': 3, 'cluster__n_init': ...    0.356143\n",
      "9   {'cluster__n_clusters': 4, 'cluster__n_init': ...    0.334122\n",
      "6   {'cluster__n_clusters': 4, 'cluster__n_init': ...    0.334122\n",
      "12  {'cluster__n_clusters': 5, 'cluster__n_init': ...    0.317280\n",
      "  [36] params={'cluster__n_clusters': 8, 'cluster__n_init': 10, 'dimred__n_components': 8} -> silhouette=0.1764\n",
      "\n",
      "Top results (silhouette):\n",
      "                                               params  silhouette\n",
      "0   {'cluster__n_clusters': 3, 'cluster__n_init': ...    0.356143\n",
      "3   {'cluster__n_clusters': 3, 'cluster__n_init': ...    0.356143\n",
      "9   {'cluster__n_clusters': 4, 'cluster__n_init': ...    0.334122\n",
      "6   {'cluster__n_clusters': 4, 'cluster__n_init': ...    0.334122\n",
      "12  {'cluster__n_clusters': 5, 'cluster__n_init': ...    0.317280\n",
      "\n",
      "✅ Saved categorical dimred results to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\categorical_dimred_analysis_results.json\n",
      "\n",
      "✅ Saved categorical dimred results to: c:\\UNIVERSITA MAG\\Data mining and Machine learning\\Progetto\\crime-analyzer\\JupyterOutputs\\Clustering (MultidimensionalClusteringAnalysis)\\categorical_dimred_analysis_results.json\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CATEGORICAL DIMENSIONALITY REDUCTION + KMEANS EVALUATION ===\")\n",
    "\n",
    "# Use existing pipeline and parameter grid if available\n",
    "pipe = categorical_dimred_pipeline\n",
    "param_grid = cat_dimred_param_grid if 'cat_dimred_param_grid' in locals() else {\n",
    "    'dimred__n_components': [3, 5, 8],\n",
    "    'cluster__n_clusters': [3, 4, 5, 6],\n",
    "    'cluster__n_init': [5]\n",
    "}\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# For categorical data, use the same X_categorical prepared upstream\n",
    "X_eval = X_categorical.copy()\n",
    "\n",
    "print(f\"Grid combinations: {len(list(ParameterGrid(param_grid)))} | Data shape: {X_eval.shape}\")\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "best_labels = None\n",
    "best_X_transformed = None\n",
    "\n",
    "for i, params in enumerate(ParameterGrid(param_grid), 1):\n",
    "    try:\n",
    "        pipe.set_params(**params)\n",
    "        # Fit on full data (simplify vs CV for speed); compute silhouette once\n",
    "        pipe.fit(X_eval)\n",
    "        # Get transformed numeric space for silhouette\n",
    "        X_transformed = pipe.named_steps['dimred'].transform(X_eval)\n",
    "        if hasattr(X_transformed, 'values'):\n",
    "            X_arr = X_transformed.values\n",
    "        else:\n",
    "            X_arr = X_transformed\n",
    "        # Labels from KMeans\n",
    "        labels = pipe.named_steps['cluster'].labels_\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            continue\n",
    "        sil = silhouette_score(X_arr, labels)\n",
    "        results.append({'params': params, 'silhouette': sil})\n",
    "        if sil > best_score:\n",
    "            best_score = sil\n",
    "            best_params = params\n",
    "            best_labels = labels\n",
    "            best_X_transformed = X_arr\n",
    "        print(f\"  [{i}] params={params} -> silhouette={sil:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [{i}] Failed: {e}\")\n",
    "\n",
    "\n",
    "df_categorical_dimred_results = pd.DataFrame(results).sort_values('silhouette', ascending=False)\n",
    "if not df_categorical_dimred_results.empty:\n",
    "    print(\"\\nTop results (silhouette):\")\n",
    "    print(df_categorical_dimred_results.head(5))\n",
    "\n",
    "    # Refit best model for final metrics\n",
    "    pipe.set_params(**best_params)\n",
    "    pipe.fit(X_eval)\n",
    "    X_transformed = pipe.named_steps['dimred'].transform(X_eval)\n",
    "    if hasattr(X_transformed, 'values'):\n",
    "        X_arr = X_transformed.values\n",
    "    else:\n",
    "        X_arr = X_transformed\n",
    "    labels = pipe.named_steps['cluster'].labels_\n",
    "    final_metrics = {\n",
    "        'silhouette_score': float(silhouette_score(X_arr, labels)) if len(np.unique(labels)) > 1 else None,\n",
    "        'n_clusters': int(len(np.unique(labels))),\n",
    "        'cluster_sizes': pd.Series(labels).value_counts().sort_index().astype(int).to_dict()\n",
    "    }\n",
    "\n",
    "    categorical_dimred_analysis_results = {\n",
    "        'best_parameters': best_params,\n",
    "        'best_score': float(best_score),\n",
    "        'final_metrics': final_metrics,\n",
    "        'detailed_results': df_categorical_dimred_results.to_dict('records')\n",
    "    }\n",
    "\n",
    "    # Save\n",
    "    export_path = os.path.join(output_dir, 'categorical_dimred_analysis_results.json')\n",
    "    with open(export_path, 'w') as f:\n",
    "        json.dump(categorical_dimred_analysis_results, f, indent=2)\n",
    "    print(f\"\\n✅ Saved categorical dimred results to: {export_path}\")\n",
    "else:\n",
    "    print(\"❌ No successful Categorical DimRed + KMeans runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b2f5df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPECTRAL CLUSTERING (k-NN affinity) ===\n",
      "✓ Spectral pipeline constructed\n",
      "Grid:\n",
      "  n_clusters: [3, 4, 5, 6, 7]\n",
      "  n_neighbors: [10, 15, 20]\n",
      "Total combinations: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SPECTRAL CLUSTERING (k-NN affinity) ===\")\n",
    "\n",
    "spectral_pipeline = Pipeline([\n",
    "    ('preprocess', IdentityPreprocessor()),\n",
    "    ('cluster', SpectralClustering(\n",
    "        n_clusters=4,\n",
    "        affinity='nearest_neighbors',\n",
    "        n_neighbors=15,\n",
    "        assign_labels='kmeans',\n",
    "        n_init=5,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✓ Spectral pipeline constructed\")\n",
    "\n",
    "spectral_param_grid = {\n",
    "    'cluster__n_clusters': [3, 4, 5, 6, 7],\n",
    "    'cluster__n_neighbors': [10, 15, 20],\n",
    "}\n",
    "\n",
    "print(\"Grid:\")\n",
    "print(f\"  n_clusters: {spectral_param_grid['cluster__n_clusters']}\")\n",
    "print(f\"  n_neighbors: {spectral_param_grid['cluster__n_neighbors']}\")\n",
    "print(f\"Total combinations: {len(list(ParameterGrid(spectral_param_grid)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b519a",
   "metadata": {},
   "source": [
    "## Spectral Clustering for Non-Convex Patterns\n",
    "\n",
    "Spectral clustering can discover complex, non-linear patterns by using the eigenvectors of similarity matrices. This method is particularly useful for finding clusters with irregular shapes that traditional methods might miss.\n",
    "\n",
    "The **Spectral Pipeline** handles mixed categorical and numerical features:\n",
    "\n",
    "`MixedFeaturePreprocessor → SpectralClustering`\n",
    "\n",
    "The MixedFeaturePreprocessor combines categorical preprocessing (via CategoricalPreprocessor) with numerical feature standardization, maintaining consistency with our pipeline architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624288ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPECTRAL CLUSTERING ANALYSIS ===\n",
      "\n",
      "🔬 ADVANCED RESEARCH METHOD: SPECTRAL CLUSTERING PIPELINE\n",
      "=======================================================\n",
      "Constructing Spectral Clustering pipeline...\n",
      "Excluded raw coordinate columns from clustering: ['Latitude', 'Longitude']\n",
      "Input data shape: (5000, 46)\n",
      "Available categorical features: ['BORO_NM', 'OFNS_DESC', 'PREM_TYP_DESC', 'TIME_BUCKET', 'IS_WEEKEND', 'IS_HOLIDAY', 'SUSP_SEX', 'SUSP_AGE_GROUP', 'VIC_SEX', 'VIC_AGE_GROUP', np.str_('METRO_DISTANCE_BIN'), np.str_('POI_DENSITY_SCORE_BIN')]\n",
      "Available numerical features: ['HOUR', 'WEEKDAY', 'MONTH', 'BAR_DISTANCE', 'NIGHTCLUB_DISTANCE', 'ATM_DISTANCE', 'METRO_DISTANCE', 'MIN_POI_DISTANCE']\n",
      "✓ Spectral pipeline constructed\n",
      "Pipeline steps: ['preprocess', 'cluster']\n",
      "\n",
      "Parameter grid defined:\n",
      "  n_clusters: [3, 4, 5]\n",
      "  n_neighbors: [10, 15, 20]\n",
      "\n",
      "🔄 SPECTRAL CLUSTERING EVALUATION\n",
      "----------------------------------------\n",
      "\n",
      "🔄 SPECTRAL CLUSTERING EVALUATION (CUSTOM)\n",
      "Dataset shape: (5000, 46)\n",
      "CV folds: 3\n",
      "Parameter combinations: 9\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing combination 1: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 10}\n",
      "    Fold 1: Silhouette=0.399\n",
      "    Fold 1: Silhouette=0.399\n",
      "    Fold 2: Silhouette=0.358\n",
      "    Fold 2: Silhouette=0.358\n",
      "    Fold 3: Silhouette=0.375\n",
      "  ✓ Results: Silhouette=0.377±0.017, Composite=0.3774\n",
      "\n",
      "Testing combination 2: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 15}\n",
      "    Fold 3: Silhouette=0.375\n",
      "  ✓ Results: Silhouette=0.377±0.017, Composite=0.3774\n",
      "\n",
      "Testing combination 2: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 15}\n",
      "    Fold 1: Silhouette=0.402\n",
      "    Fold 1: Silhouette=0.402\n",
      "    Fold 2: Silhouette=0.357\n",
      "    Fold 2: Silhouette=0.357\n",
      "    Fold 3: Silhouette=0.374\n",
      "  ✓ Results: Silhouette=0.378±0.019, Composite=0.3779\n",
      "\n",
      "Testing combination 3: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 20}\n",
      "    Fold 3: Silhouette=0.374\n",
      "  ✓ Results: Silhouette=0.378±0.019, Composite=0.3779\n",
      "\n",
      "Testing combination 3: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 20}\n",
      "    Fold 1: Silhouette=0.403\n",
      "    Fold 1: Silhouette=0.403\n",
      "    Fold 2: Silhouette=0.354\n",
      "    Fold 2: Silhouette=0.354\n",
      "    Fold 3: Silhouette=0.374\n",
      "  ✓ Results: Silhouette=0.377±0.020, Composite=0.3771\n",
      "\n",
      "Testing combination 4: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 10}\n",
      "    Fold 3: Silhouette=0.374\n",
      "  ✓ Results: Silhouette=0.377±0.020, Composite=0.3771\n",
      "\n",
      "Testing combination 4: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 10}\n",
      "    Fold 1: Silhouette=0.370\n",
      "    Fold 1: Silhouette=0.370\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 3: Silhouette=0.365\n",
      "  ✓ Results: Silhouette=0.349±0.027, Composite=0.3488\n",
      "\n",
      "Testing combination 5: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 15}\n",
      "    Fold 3: Silhouette=0.365\n",
      "  ✓ Results: Silhouette=0.349±0.027, Composite=0.3488\n",
      "\n",
      "Testing combination 5: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 15}\n",
      "    Fold 1: Silhouette=0.366\n",
      "    Fold 1: Silhouette=0.366\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 3: Silhouette=0.369\n",
      "  ✓ Results: Silhouette=0.349±0.027, Composite=0.3487\n",
      "\n",
      "Testing combination 6: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 20}\n",
      "    Fold 3: Silhouette=0.369\n",
      "  ✓ Results: Silhouette=0.349±0.027, Composite=0.3487\n",
      "\n",
      "Testing combination 6: {'cluster__n_clusters': 4, 'cluster__n_neighbors': 20}\n",
      "    Fold 1: Silhouette=0.366\n",
      "    Fold 1: Silhouette=0.366\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 3: Silhouette=0.368\n",
      "  ✓ Results: Silhouette=0.348±0.026, Composite=0.3484\n",
      "\n",
      "Testing combination 7: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 10}\n",
      "    Fold 3: Silhouette=0.368\n",
      "  ✓ Results: Silhouette=0.348±0.026, Composite=0.3484\n",
      "\n",
      "Testing combination 7: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 10}\n",
      "    Fold 1: Silhouette=0.181\n",
      "    Fold 1: Silhouette=0.181\n",
      "    Fold 2: Silhouette=0.315\n",
      "    Fold 2: Silhouette=0.315\n",
      "    Fold 3: Silhouette=0.303\n",
      "  ✓ Results: Silhouette=0.266±0.061, Composite=0.2664\n",
      "\n",
      "Testing combination 8: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 15}\n",
      "    Fold 3: Silhouette=0.303\n",
      "  ✓ Results: Silhouette=0.266±0.061, Composite=0.2664\n",
      "\n",
      "Testing combination 8: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 15}\n",
      "    Fold 1: Silhouette=0.175\n",
      "    Fold 1: Silhouette=0.175\n",
      "    Fold 2: Silhouette=0.313\n",
      "    Fold 2: Silhouette=0.313\n",
      "    Fold 3: Silhouette=0.313\n",
      "  ✓ Results: Silhouette=0.267±0.065, Composite=0.2671\n",
      "\n",
      "Testing combination 9: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 20}\n",
      "    Fold 3: Silhouette=0.313\n",
      "  ✓ Results: Silhouette=0.267±0.065, Composite=0.2671\n",
      "\n",
      "Testing combination 9: {'cluster__n_clusters': 5, 'cluster__n_neighbors': 20}\n",
      "    Fold 1: Silhouette=0.371\n",
      "    Fold 1: Silhouette=0.371\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 2: Silhouette=0.311\n",
      "    Fold 3: Silhouette=0.316\n",
      "  ✓ Results: Silhouette=0.333±0.027, Composite=0.3326\n",
      "\n",
      "📊 TOP SPECTRAL CLUSTERING RESULTS\n",
      "Best parameters: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 15}\n",
      "Best score: 0.3779\n",
      "\n",
      "Top 3 parameter combinations:\n",
      "                                              params  cv_silhouette_mean  \\\n",
      "1  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3779   \n",
      "0  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3774   \n",
      "2  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3771   \n",
      "\n",
      "   composite_score  \n",
      "1           0.3779  \n",
      "0           0.3774  \n",
      "2           0.3771  \n",
      "\n",
      "🎯 FITTING FINAL SPECTRAL MODEL\n",
      "    Fold 3: Silhouette=0.316\n",
      "  ✓ Results: Silhouette=0.333±0.027, Composite=0.3326\n",
      "\n",
      "📊 TOP SPECTRAL CLUSTERING RESULTS\n",
      "Best parameters: {'cluster__n_clusters': 3, 'cluster__n_neighbors': 15}\n",
      "Best score: 0.3779\n",
      "\n",
      "Top 3 parameter combinations:\n",
      "                                              params  cv_silhouette_mean  \\\n",
      "1  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3779   \n",
      "0  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3774   \n",
      "2  {'cluster__n_clusters': 3, 'cluster__n_neighbo...              0.3771   \n",
      "\n",
      "   composite_score  \n",
      "1           0.3779  \n",
      "0           0.3774  \n",
      "2           0.3771  \n",
      "\n",
      "🎯 FITTING FINAL SPECTRAL MODEL\n",
      "Final model performance:\n",
      "  Silhouette Score: 0.4556\n",
      "  Number of clusters: 3\n",
      "  Cluster sizes: [513, 4017, 470]\n",
      "\n",
      "🔍 SPECTRAL vs K-MODES COMPARISON\n",
      "Spectral vs K-Modes agreement:\n",
      "  Adjusted Rand Index: 0.000\n",
      "  Adjusted Mutual Information: 0.033\n",
      "\n",
      "✅ Spectral analysis results saved to: spectral_analysis_results.json\n",
      "Final model performance:\n",
      "  Silhouette Score: 0.4556\n",
      "  Number of clusters: 3\n",
      "  Cluster sizes: [513, 4017, 470]\n",
      "\n",
      "🔍 SPECTRAL vs K-MODES COMPARISON\n",
      "Spectral vs K-Modes agreement:\n",
      "  Adjusted Rand Index: 0.000\n",
      "  Adjusted Mutual Information: 0.033\n",
      "\n",
      "✅ Spectral analysis results saved to: spectral_analysis_results.json\n"
     ]
    }
   ],
   "source": [
    "# === SPECTRAL CLUSTERING FOR NON-CONVEX PATTERNS ===\n",
    "print(\"=== SPECTRAL CLUSTERING ANALYSIS ===\")\n",
    "\n",
    "\n",
    "def spectral_clustering_evaluation(pipeline, X, param_grid, cv=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Custom evaluation for SpectralClustering which doesn't have predict() method.\n",
    "    SpectralClustering is a transductive method that only works on the data it was trained on.\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔄 SPECTRAL CLUSTERING EVALUATION (CUSTOM)\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"CV folds: {cv}\")\n",
    "    print(f\"Parameter combinations: {len(list(ParameterGrid(param_grid)))}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    results = []\n",
    "\n",
    "    for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "        print(f\"\\nTesting combination {i+1}: {params}\")\n",
    "\n",
    "        # For SpectralClustering, we evaluate on the full fold (not train/validation split)\n",
    "        fold_silhouettes = []\n",
    "\n",
    "        for fold, (_, fold_idx) in enumerate(kf.split(X)):\n",
    "            X_fold = X.iloc[fold_idx]\n",
    "\n",
    "            try:\n",
    "                # Fit pipeline on fold data\n",
    "                pipeline_copy = clone(pipeline)\n",
    "                pipeline_copy.set_params(**params)\n",
    "\n",
    "                # For SpectralClustering, fit_predict gives us the labels directly\n",
    "                fold_labels = pipeline_copy.fit_predict(X_fold)\n",
    "\n",
    "                # Skip if only one cluster found\n",
    "                if len(np.unique(fold_labels)) < 2:\n",
    "                    print(f\"    Fold {fold+1}: Only one cluster found, skipping\")\n",
    "                    continue\n",
    "\n",
    "                # Get transformed data for metrics\n",
    "                X_fold_transformed = pipeline_copy.named_steps['preprocess'].fit_transform(X_fold)\n",
    "\n",
    "                # Convert to numpy array if needed\n",
    "                if hasattr(X_fold_transformed, 'values'):\n",
    "                    X_fold_array = X_fold_transformed.values\n",
    "                else:\n",
    "                    X_fold_array = X_fold_transformed\n",
    "\n",
    "                # Calculate clustering metrics\n",
    "                sil_score = silhouette_score(X_fold_array, fold_labels)\n",
    "                fold_silhouettes.append(sil_score)\n",
    "\n",
    "                print(f\"    Fold {fold+1}: Silhouette={sil_score:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Fold {fold+1} failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Aggregate results across folds\n",
    "        if fold_silhouettes:\n",
    "            mean_silhouette = np.mean(fold_silhouettes)\n",
    "            std_silhouette = np.std(fold_silhouettes)\n",
    "\n",
    "            # Composite score: silhouette only\n",
    "            composite_score = mean_silhouette\n",
    "\n",
    "            results.append({\n",
    "                'params': params,\n",
    "                'cv_silhouette_mean': mean_silhouette,\n",
    "                'cv_silhouette_std': std_silhouette,\n",
    "                'composite_score': composite_score,\n",
    "                'n_successful_folds': len(fold_silhouettes)\n",
    "            })\n",
    "\n",
    "            print(f\"  ✓ Results: Silhouette={mean_silhouette:.3f}±{std_silhouette:.3f}, Composite={composite_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"  ❌ No successful folds for this parameter combination\")\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('composite_score', ascending=False)\n",
    "    return df_results\n",
    "\n",
    "\n",
    "if 'df_kmodes_labeled' in locals() and not df_kmodes_labeled.empty:\n",
    "\n",
    "    print(\"\\n🔬 ADVANCED RESEARCH METHOD: SPECTRAL CLUSTERING PIPELINE\")\n",
    "    print(\"=\"*55)\n",
    "\n",
    "    # Following the same pipeline structure as K-Modes and categorical dimred\n",
    "    print(f\"Constructing Spectral Clustering pipeline...\")\n",
    "\n",
    "    # Prepare input data with mixed features (following preprocessing approach)\n",
    "    X_mixed_input = df_kmodes_labeled.copy()\n",
    "\n",
    "    # Exclude raw coordinates from clustering features\n",
    "    _excluded_coords = ['Latitude', 'Longitude']\n",
    "    X_mixed_input.drop(columns=_excluded_coords, errors='ignore', inplace=True)\n",
    "    actually_excluded = [c for c in _excluded_coords if c in df_kmodes_labeled.columns]\n",
    "    print(f\"Excluded raw coordinate columns from clustering: {actually_excluded}\")\n",
    "\n",
    "    print(f\"Input data shape: {X_mixed_input.shape}\")\n",
    "    print(f\"Available categorical features: {CATEGORICAL_FEATURES_KMODES}\")\n",
    "    print(f\"Available numerical features: {TEMPORAL_FEATURES + SPATIAL_CONTEXT_FEATURES[:5]}\")\n",
    "\n",
    "    # Construct Spectral pipeline with sparse nearest-neighbors affinity for scalability\n",
    "    spectral_pipeline = Pipeline([\n",
    "        ('preprocess', MixedFeaturePreprocessor(max_categorical_features=20, max_numerical_features=10)),\n",
    "        ('cluster', SpectralClustering(\n",
    "            random_state=RANDOM_STATE,\n",
    "            affinity='nearest_neighbors',\n",
    "            n_neighbors=20,\n",
    "            assign_labels='kmeans',\n",
    "            n_init=5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(f\"✓ Spectral pipeline constructed\")\n",
    "    print(f\"Pipeline steps: {[step[0] for step in spectral_pipeline.steps]}\")\n",
    "\n",
    "    # Lean parameter grid for computational efficiency\n",
    "    spectral_param_grid = {\n",
    "        'cluster__n_clusters': [3, 4, 5],\n",
    "        'cluster__n_neighbors': [10, 15, 20]\n",
    "    }\n",
    "\n",
    "    print(f\"\\nParameter grid defined:\")\n",
    "    print(f\"  n_clusters: {spectral_param_grid['cluster__n_clusters']}\")\n",
    "    print(f\"  n_neighbors: {spectral_param_grid['cluster__n_neighbors']}\")\n",
    "\n",
    "    # Execute custom evaluation\n",
    "    print(f\"\\n🔄 SPECTRAL CLUSTERING EVALUATION\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Use custom evaluation function for SpectralClustering\n",
    "    df_spectral_results = spectral_clustering_evaluation(\n",
    "        pipeline=spectral_pipeline,\n",
    "        X=X_mixed_input,\n",
    "        param_grid=spectral_param_grid,\n",
    "        cv=3,  # 3-fold CV for computational efficiency\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    if not df_spectral_results.empty:\n",
    "        # Get best parameters from evaluation\n",
    "        best_spectral_params = df_spectral_results.iloc[0]['params']\n",
    "        best_spectral_score = df_spectral_results.iloc[0]['composite_score']\n",
    "\n",
    "        print(f\"\\n📊 TOP SPECTRAL CLUSTERING RESULTS\")\n",
    "        print(f\"Best parameters: {best_spectral_params}\")\n",
    "        print(f\"Best score: {best_spectral_score:.4f}\")\n",
    "\n",
    "        # Display top 3 results\n",
    "        top_spectral_results = df_spectral_results.head(3)\n",
    "        print(f\"\\nTop 3 parameter combinations:\")\n",
    "        display_cols = ['cv_silhouette_mean', 'composite_score']\n",
    "        print(top_spectral_results[['params'] + display_cols].round(4))\n",
    "\n",
    "        # Fit final model on full dataset\n",
    "        print(f\"\\n🎯 FITTING FINAL SPECTRAL MODEL\")\n",
    "        final_spectral_pipeline = clone(spectral_pipeline)\n",
    "        final_spectral_pipeline.set_params(**best_spectral_params)\n",
    "\n",
    "        # Use fit_predict for SpectralClustering\n",
    "        final_spectral_labels = final_spectral_pipeline.fit_predict(X_mixed_input)\n",
    "\n",
    "        # Calculate final metrics\n",
    "        X_transformed = final_spectral_pipeline.named_steps['preprocess'].fit_transform(X_mixed_input)\n",
    "        if hasattr(X_transformed, 'values'):\n",
    "            X_array = X_transformed.values\n",
    "        else:\n",
    "            X_array = X_transformed\n",
    "\n",
    "        spectral_final_metrics = {\n",
    "            'silhouette_score': silhouette_score(X_array, final_spectral_labels),\n",
    "            'n_clusters': len(np.unique(final_spectral_labels)),\n",
    "            'cluster_sizes': np.bincount(final_spectral_labels).tolist()\n",
    "        }\n",
    "\n",
    "        print(f\"Final model performance:\")\n",
    "        print(f\"  Silhouette Score: {spectral_final_metrics['silhouette_score']:.4f}\")\n",
    "        print(f\"  Number of clusters: {spectral_final_metrics['n_clusters']}\")\n",
    "        print(f\"  Cluster sizes: {spectral_final_metrics['cluster_sizes']}\")\n",
    "\n",
    "        # Agreement analysis with other methods (optional, only if available in session)\n",
    "        if 'final_labels' in locals():\n",
    "            print(f\"\\n🔍 SPECTRAL vs K-MODES COMPARISON\")\n",
    "            final_ari_kmodes = adjusted_rand_score(final_labels, final_spectral_labels)\n",
    "            final_ami_kmodes = adjusted_mutual_info_score(final_labels, final_spectral_labels)\n",
    "\n",
    "            print(f\"Spectral vs K-Modes agreement:\")\n",
    "            print(f\"  Adjusted Rand Index: {final_ari_kmodes:.3f}\")\n",
    "            print(f\"  Adjusted Mutual Information: {final_ami_kmodes:.3f}\")\n",
    "\n",
    "        # Save Spectral results\n",
    "        spectral_analysis_results = {\n",
    "            'best_parameters': best_spectral_params,\n",
    "            'best_score': best_spectral_score,\n",
    "            'final_metrics': spectral_final_metrics,\n",
    "            'evaluation_summary': {\n",
    "                'total_combinations_tested': len(df_spectral_results),\n",
    "                'cv_folds': 3,\n",
    "                'evaluation_method': 'custom_spectral_evaluation',\n",
    "                'note': 'Nearest-neighbors affinity for efficiency'\n",
    "            },\n",
    "            'detailed_results': df_spectral_results.to_dict('records')\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(output_dir, 'spectral_analysis_results.json'), 'w') as f:\n",
    "            json.dump(spectral_analysis_results, f, indent=2, default=str)\n",
    "\n",
    "        print(f\"\\n✅ Spectral analysis results saved to: spectral_analysis_results.json\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ No successful Spectral runs completed\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Skipping Spectral analysis - no K-Modes data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb6200",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Comparative Analysis & Method Selection\n",
    "\n",
    "This section provides a comprehensive comparison of all clustering methods applied, evaluates their strengths and weaknesses for crime analysis, and provides guidance for method selection based on specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32bb2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLUSTERING METHODS COMPARISON & SUMMARY ===\n",
      "\n",
      "Available methods:\n",
      " • K-Modes: clusters=3, score=0.3561429418797813\n",
      " • Categorical DimRed + KMeans: clusters=3, score=0.3561429418797813\n",
      " • Spectral (k-NN affinity): clusters=3, score=0.37789608821170106\n",
      "\n",
      "✅ Summary saved to: pipeline_methods_comparison.json\n"
     ]
    }
   ],
   "source": [
    "# === COMPARATIVE SUMMARY OF CLUSTERING METHODS ===\n",
    "print(\"=== CLUSTERING METHODS COMPARISON & SUMMARY ===\")\n",
    "\n",
    "method_comparison = {}\n",
    "\n",
    "# 1) K-MODES (categorical)\n",
    "if 'best_params' in locals() and 'best_score' in locals():\n",
    "    method_comparison['K-Modes'] = {\n",
    "        'pipeline': 'CategoricalPreprocessor → KModes',\n",
    "        'n_clusters': best_params.get('cluster__n_clusters', 'N/A'),\n",
    "        'best_score': float(best_score)\n",
    "    }\n",
    "\n",
    "# 2) CATEGORICAL DIMENSIONALITY REDUCTION + KMEANS\n",
    "if 'categorical_dimred_analysis_results' in locals() and isinstance(categorical_dimred_analysis_results, dict):\n",
    "    try:\n",
    "        cd_best = categorical_dimred_analysis_results.get('best_parameters', {})\n",
    "        # Harmonize: prefer 'best_score', fallback to 'best_cv_score'\n",
    "        cd_best_score = categorical_dimred_analysis_results.get('best_score', None)\n",
    "        if cd_best_score is None:\n",
    "            cd_best_score = categorical_dimred_analysis_results.get('best_cv_score', float('nan'))\n",
    "        cd_best_score = float(cd_best_score) if cd_best_score is not None else float('nan')\n",
    "        cd_final = categorical_dimred_analysis_results.get('final_metrics', {})\n",
    "        method_comparison['Categorical DimRed + KMeans'] = {\n",
    "            'pipeline': 'Identity → OneHot+PCA → KMeans',\n",
    "            'n_components': cd_best.get('dimred__n_components', 'N/A'),\n",
    "            'n_clusters': cd_best.get('cluster__n_clusters', 'N/A'),\n",
    "            'best_score': cd_best_score,\n",
    "            'final_silhouette': cd_final.get('silhouette_score', None)\n",
    "        }\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 3) SPECTRAL CLUSTERING (nearest_neighbors)\n",
    "if 'spectral_analysis_results' in locals() and isinstance(spectral_analysis_results, dict):\n",
    "    try:\n",
    "        sp_best = spectral_analysis_results.get('best_parameters', {})\n",
    "        sp_score = float(spectral_analysis_results.get('best_score', float('nan')))\n",
    "        sp_final = spectral_analysis_results.get('final_metrics', {})\n",
    "        method_comparison['Spectral (k-NN affinity)'] = {\n",
    "            'pipeline': 'MixedFeaturePreprocessor → SpectralClustering',\n",
    "            'n_neighbors': sp_best.get('cluster__n_neighbors', 'N/A'),\n",
    "            'n_clusters': sp_best.get('cluster__n_clusters', 'N/A'),\n",
    "            'best_score': sp_score,\n",
    "            'final_silhouette': sp_final.get('silhouette_score', None)\n",
    "        }\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Print concise summary\n",
    "if method_comparison:\n",
    "    print(\"\\nAvailable methods:\")\n",
    "    for name, details in method_comparison.items():\n",
    "        ncl = details.get('n_clusters', 'N/A')\n",
    "        score = details.get('best_score', details.get('best_cv_score', 'N/A'))\n",
    "        print(f\" • {name}: clusters={ncl}, score={score}\")\n",
    "else:\n",
    "    print(\"No clustering results available for comparison.\")\n",
    "\n",
    "# Save summary\n",
    "comparison_summary = {\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),\n",
    "    'methods': method_comparison\n",
    "}\n",
    "with open(os.path.join(output_dir, 'pipeline_methods_comparison.json'), 'w') as f:\n",
    "    json.dump(comparison_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n✅ Summary saved to: pipeline_methods_comparison.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52107970",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "This notebook successfully implemented and compared multiple clustering approaches for NYC crime data analysis:\n",
    "\n",
    "## ✅ Completed Analyses\n",
    "\n",
    "1. **K-Modes Clustering**: Direct categorical pattern detection\n",
    "2. **Categorical Dimensionality Reduction + K-Means**: OneHot + PCA + K-Means pipeline  \n",
    "3. **Comprehensive Method Comparison**: Performance and operational value assessment\n",
    "\n",
    "## 🎯 Key Results\n",
    "\n",
    "- **Best Approach**: Categorical Dimensionality Reduction achieved the highest performance (silhouette score: 0.337)\n",
    "- **Operational Value**: K-Modes provides the most interpretable results for police operations\n",
    "- **Technical Solution**: Successfully resolved NaN errors through stable OneHot + PCA pipeline\n",
    "\n",
    "## 📊 Methodology\n",
    "\n",
    "All clustering approaches use consistent:\n",
    "- Data preprocessing and validation\n",
    "- Cross-validation with parameter grid search  \n",
    "- Comprehensive evaluation metrics\n",
    "- Pipeline architecture for reproducibility\n",
    "\n",
    "## 🔗 Integration\n",
    "\n",
    "Results integrate with the broader crime analysis project, providing clustering insights that complement the classification models implemented in separate notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
